{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Handwritten_digits.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/zrZBd7HJpP1oWCA3HjoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyedalirezaabbaspour/Recognize-Persian-handwritten-numbers-with-keras/blob/main/CNN_Handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPg8kM0_7zMk",
        "outputId": "c3f0273f-f691-4544-d9e1-cc8b6455faef"
      },
      "source": [
        "! git clone --recursive [GITHUB LINK REPO]    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: Too many arguments.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --verbose         be more verbose\n",
            "    -q, --quiet           be more quiet\n",
            "    --progress            force progress reporting\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --bare                create a bare repository\n",
            "    --mirror              create a mirror repository (implies bare)\n",
            "    -l, --local           to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    -s, --shared          setup as shared repository\n",
            "    --recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    -j, --jobs <n>        number of submodules cloned in parallel\n",
            "    --template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --reference <repo>    reference repository\n",
            "    --reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --dissociate          use --reference only while cloning\n",
            "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
            "    -b, --branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --depth <depth>       create a shallow clone of that depth\n",
            "    --shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --single-branch       clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --shallow-submodules  any cloned submodules will be shallow\n",
            "    --separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    -c, --config <key=value>\n",
            "                          set config inside the new repository\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --filter <args>       object filtering\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W_kwLhi7_1a",
        "outputId": "3db1c169-039f-4be2-cf27-b1e1f3bc46fd"
      },
      "source": [
        "! git clone --recursive https://github.com/seyedalirezaabbaspour/Recognize-Persian-handwritten-numbers-with-keras.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Recognize-Persian-handwritten-numbers-with-keras'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 79 (delta 32), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T17CecSC8CtA",
        "outputId": "9d9903f6-ad1f-45d6-cfee-8b18909eb58e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juuGgb618Cv2",
        "outputId": "c280fc43-1526-4273-d487-481dff84b73b"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recognize-Persian-handwritten-numbers-with-keras  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPS-a7q98CyU"
      },
      "source": [
        "!mv /content/Recognize-Persian-handwritten-numbers-with-keras/datasets/* /content"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hCCj4VI87BI",
        "outputId": "985d4283-a7b2-4e0c-f3b0-85baf408205e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data_hoda_full.mat  Recognize-Persian-handwritten-numbers-with-keras\n",
            "dataset_hoda.py     sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmqMaF5u8Pgy"
      },
      "source": [
        "# **Convolutional Neural Network**\r\n",
        "\r\n",
        "## Classification With CNN On **Hoda**(Persian Handwritten Digits)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kfQ-xv8VUe"
      },
      "source": [
        "import keras \r\n",
        "from keras import layers\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\r\n",
        "from keras.optimizers import Adam\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from dataset_hoda import load_hoda"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvvRyKHk8Xd2"
      },
      "source": [
        "#load dataset\r\n",
        "X_train_original, y_train_original, X_test_original, y_test_original = load_hoda(training_sample_size=5000,\r\n",
        "                                                                                 test_sample_size=1000,\r\n",
        "                                                                                 size = 28)\r\n",
        "\r\n",
        "#preprocessing\r\n",
        "\r\n",
        "''' input data in numpy array format'''\r\n",
        "X_train = np.array(X_train_original)\r\n",
        "X_test = np.array(X_test_original)\r\n",
        "\r\n",
        "\r\n",
        "''' normalize our data values to the range [0, 1]'''\r\n",
        "X_train = X_train.astype(\"float32\")\r\n",
        "X_test = X_test.astype(\"float32\")\r\n",
        "\r\n",
        "X_train = X_train/ 255.0\r\n",
        "X_test = X_test  / 255.0\r\n",
        "\r\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\r\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\r\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\r\n",
        "\r\n",
        "# preprocessing class labels\r\n",
        "y_train = keras.utils.to_categorical(y_train_original)\r\n",
        "y_test = keras.utils.to_categorical(y_test_original)\r\n",
        "\r\n",
        "\r\n",
        "# test and validation set\r\n",
        "X_validation = X_train[:1000]\r\n",
        "y_validation = y_train[:1000]\r\n",
        "\r\n",
        "X_train = X_train[1000:]\r\n",
        "y_train = y_train[1000:]\r\n",
        "\r\n",
        "\r\n",
        "#preprocessing\r\n",
        "\r\n",
        "''' input data in numpy array format'''\r\n",
        "X_train = np.array(X_train_original)\r\n",
        "X_test = np.array(X_test_original)\r\n",
        "\r\n",
        "\r\n",
        "''' normalize our data values to the range [0, 1]'''\r\n",
        "X_train = X_train.astype(\"float32\")\r\n",
        "X_test = X_test.astype(\"float32\")\r\n",
        "\r\n",
        "X_train = X_train/ 255.0\r\n",
        "X_test = X_test  / 255.0\r\n",
        "\r\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\r\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\r\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\r\n",
        "\r\n",
        "# preprocessing class labels\r\n",
        "y_train = keras.utils.to_categorical(y_train_original)\r\n",
        "y_test = keras.utils.to_categorical(y_test_original)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmrwfxF48ZLV",
        "outputId": "165756de-a3ac-45a4-d830-9337cb3d46f8"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(512, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 9,179,850\n",
            "Trainable params: 9,179,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vv84Jve98av3",
        "outputId": "670eef8b-b00b-43b2-b778-1297c6646a7d"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "25/25 [==============================] - 35s 158ms/step - loss: 2.0355 - acc: 0.2557 - val_loss: 0.7013 - val_acc: 0.7870\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.6820 - acc: 0.7623 - val_loss: 0.2113 - val_acc: 0.9480\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.3201 - acc: 0.8965 - val_loss: 0.1369 - val_acc: 0.9730\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.2399 - acc: 0.9236 - val_loss: 0.0727 - val_acc: 0.9810\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.1650 - acc: 0.9506 - val_loss: 0.0579 - val_acc: 0.9810\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.1310 - acc: 0.9600 - val_loss: 0.0498 - val_acc: 0.9880\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.1118 - acc: 0.9656 - val_loss: 0.0419 - val_acc: 0.9850\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 3s 139ms/step - loss: 0.0894 - acc: 0.9727 - val_loss: 0.0412 - val_acc: 0.9880\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.0908 - acc: 0.9704 - val_loss: 0.0268 - val_acc: 0.9920\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.0906 - acc: 0.9696 - val_loss: 0.0410 - val_acc: 0.9880\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 3s 139ms/step - loss: 0.1001 - acc: 0.9677 - val_loss: 0.0222 - val_acc: 0.9920\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 3s 139ms/step - loss: 0.0772 - acc: 0.9787 - val_loss: 0.0262 - val_acc: 0.9930\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 3s 139ms/step - loss: 0.0601 - acc: 0.9795 - val_loss: 0.0231 - val_acc: 0.9940\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 3s 139ms/step - loss: 0.0712 - acc: 0.9753 - val_loss: 0.0130 - val_acc: 0.9960\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0489 - acc: 0.9871 - val_loss: 0.0127 - val_acc: 0.9970\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0424 - acc: 0.9856 - val_loss: 0.0247 - val_acc: 0.9900\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0654 - acc: 0.9810 - val_loss: 0.0113 - val_acc: 0.9970\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0482 - acc: 0.9856 - val_loss: 0.0083 - val_acc: 0.9980\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 3s 141ms/step - loss: 0.0384 - acc: 0.9876 - val_loss: 0.0074 - val_acc: 0.9990\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 3s 141ms/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.0099 - val_acc: 0.9980\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0431 - acc: 0.9860 - val_loss: 0.0102 - val_acc: 0.9970\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0499 - acc: 0.9821 - val_loss: 0.0077 - val_acc: 0.9980\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0059 - val_acc: 0.9990\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0337 - acc: 0.9905 - val_loss: 0.0063 - val_acc: 0.9980\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0323 - acc: 0.9882 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0031 - val_acc: 0.9990\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0218 - acc: 0.9931 - val_loss: 0.0049 - val_acc: 0.9990\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0253 - acc: 0.9911 - val_loss: 0.0053 - val_acc: 0.9990\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0283 - acc: 0.9892 - val_loss: 0.0075 - val_acc: 0.9960\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0293 - acc: 0.9893 - val_loss: 0.0032 - val_acc: 0.9990\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0272 - acc: 0.9914 - val_loss: 0.0035 - val_acc: 0.9990\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0263 - acc: 0.9923 - val_loss: 0.0024 - val_acc: 0.9990\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0181 - acc: 0.9924 - val_loss: 0.0041 - val_acc: 0.9990\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0264 - acc: 0.9911 - val_loss: 0.0021 - val_acc: 0.9990\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0019 - val_acc: 0.9990\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0260 - acc: 0.9907 - val_loss: 0.0029 - val_acc: 1.0000\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0359 - acc: 0.9881 - val_loss: 0.0027 - val_acc: 0.9980\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0371 - acc: 0.9894 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0021 - val_acc: 0.9990\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0216 - acc: 0.9935 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0195 - acc: 0.9931 - val_loss: 6.3464e-04 - val_acc: 1.0000\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0184 - acc: 0.9939 - val_loss: 6.8403e-04 - val_acc: 1.0000\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0296 - acc: 0.9937 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0016 - val_acc: 0.9990\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0260 - acc: 0.9931 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.0038 - val_acc: 0.9990\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0138 - acc: 0.9954 - val_loss: 4.7088e-04 - val_acc: 1.0000\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0136 - acc: 0.9966 - val_loss: 4.6787e-04 - val_acc: 1.0000\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0114 - acc: 0.9976 - val_loss: 5.4500e-04 - val_acc: 1.0000\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0077 - acc: 0.9976 - val_loss: 2.5108e-04 - val_acc: 1.0000\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0126 - acc: 0.9957 - val_loss: 6.2559e-04 - val_acc: 1.0000\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0145 - acc: 0.9946 - val_loss: 3.0637e-04 - val_acc: 1.0000\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0141 - acc: 0.9940 - val_loss: 0.0013 - val_acc: 0.9990\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0100 - acc: 0.9964 - val_loss: 3.4083e-04 - val_acc: 1.0000\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0123 - acc: 0.9953 - val_loss: 3.0103e-04 - val_acc: 1.0000\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0167 - acc: 0.9951 - val_loss: 5.2742e-04 - val_acc: 1.0000\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0231 - acc: 0.9938 - val_loss: 0.0020 - val_acc: 0.9990\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0392 - acc: 0.9926 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0218 - acc: 0.9953 - val_loss: 4.1383e-04 - val_acc: 1.0000\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 2.3579e-04 - val_acc: 1.0000\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0124 - acc: 0.9966 - val_loss: 1.4571e-04 - val_acc: 1.0000\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 5.7675e-04 - val_acc: 1.0000\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0147 - acc: 0.9938 - val_loss: 2.0016e-04 - val_acc: 1.0000\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0134 - acc: 0.9954 - val_loss: 1.6517e-04 - val_acc: 1.0000\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0152 - acc: 0.9956 - val_loss: 4.1229e-04 - val_acc: 1.0000\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0169 - acc: 0.9947 - val_loss: 3.4884e-04 - val_acc: 1.0000\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0107 - acc: 0.9963 - val_loss: 1.6231e-04 - val_acc: 1.0000\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 2.6113e-04 - val_acc: 1.0000\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0173 - acc: 0.9950 - val_loss: 5.0150e-04 - val_acc: 1.0000\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0162 - acc: 0.9942 - val_loss: 2.7928e-04 - val_acc: 1.0000\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 1.4955e-04 - val_acc: 1.0000\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0149 - acc: 0.9934 - val_loss: 0.0050 - val_acc: 0.9990\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0193 - acc: 0.9937 - val_loss: 1.3666e-04 - val_acc: 1.0000\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0234 - acc: 0.9951 - val_loss: 6.9222e-04 - val_acc: 1.0000\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0223 - acc: 0.9935 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 1.6160e-04 - val_acc: 1.0000\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0139 - acc: 0.9947 - val_loss: 8.7040e-05 - val_acc: 1.0000\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 3.6176e-04 - val_acc: 1.0000\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0252 - acc: 0.9939 - val_loss: 0.0015 - val_acc: 0.9990\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 1.8967e-04 - val_acc: 1.0000\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 4.0359e-05 - val_acc: 1.0000\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 3s 141ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 1.0506e-04 - val_acc: 1.0000\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0173 - acc: 0.9960 - val_loss: 2.6134e-04 - val_acc: 1.0000\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0201 - acc: 0.9941 - val_loss: 3.6718e-04 - val_acc: 1.0000\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0213 - acc: 0.9938 - val_loss: 2.5770e-04 - val_acc: 1.0000\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 3.4662e-04 - val_acc: 1.0000\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0137 - acc: 0.9966 - val_loss: 1.2590e-04 - val_acc: 1.0000\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 1.8594e-04 - val_acc: 1.0000\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0106 - acc: 0.9974 - val_loss: 1.5677e-04 - val_acc: 1.0000\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0166 - acc: 0.9960 - val_loss: 7.4814e-05 - val_acc: 1.0000\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 2.0857e-04 - val_acc: 1.0000\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 1.0203e-04 - val_acc: 1.0000\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0075 - acc: 0.9966 - val_loss: 5.2589e-05 - val_acc: 1.0000\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0112 - acc: 0.9953 - val_loss: 1.4057e-04 - val_acc: 1.0000\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 2.7342e-05 - val_acc: 1.0000\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 2.6756e-04 - val_acc: 1.0000\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 7.4505e-05 - val_acc: 1.0000\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0066 - acc: 0.9979 - val_loss: 2.6551e-05 - val_acc: 1.0000\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0096 - acc: 0.9966 - val_loss: 5.6326e-05 - val_acc: 1.0000\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0055 - acc: 0.9978 - val_loss: 1.7700e-05 - val_acc: 1.0000\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 5.5552e-06 - val_acc: 1.0000\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0078 - acc: 0.9971 - val_loss: 8.8142e-06 - val_acc: 1.0000\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0107 - acc: 0.9970 - val_loss: 5.4434e-05 - val_acc: 1.0000\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0161 - acc: 0.9944 - val_loss: 1.5251e-04 - val_acc: 1.0000\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0165 - acc: 0.9939 - val_loss: 8.0304e-05 - val_acc: 1.0000\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 8.1279e-05 - val_acc: 1.0000\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 1.2858e-04 - val_acc: 1.0000\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 6.7018e-05 - val_acc: 1.0000\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0120 - acc: 0.9951 - val_loss: 4.0032e-04 - val_acc: 1.0000\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0143 - acc: 0.9966 - val_loss: 1.8253e-04 - val_acc: 1.0000\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0072 - acc: 0.9976 - val_loss: 9.3533e-05 - val_acc: 1.0000\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0133 - acc: 0.9962 - val_loss: 2.3101e-04 - val_acc: 1.0000\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0111 - acc: 0.9971 - val_loss: 8.1016e-05 - val_acc: 1.0000\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0066 - acc: 0.9974 - val_loss: 3.0690e-05 - val_acc: 1.0000\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 4s 143ms/step - loss: 0.0221 - acc: 0.9927 - val_loss: 1.2383e-04 - val_acc: 1.0000\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0084 - acc: 0.9976 - val_loss: 6.1119e-05 - val_acc: 1.0000\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0135 - acc: 0.9969 - val_loss: 6.3923e-05 - val_acc: 1.0000\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 9.7317e-05 - val_acc: 1.0000\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0092 - acc: 0.9979 - val_loss: 7.9715e-05 - val_acc: 1.0000\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 9.9164e-06 - val_acc: 1.0000\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0083 - acc: 0.9985 - val_loss: 2.5703e-05 - val_acc: 1.0000\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0086 - acc: 0.9959 - val_loss: 4.9002e-04 - val_acc: 1.0000\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 3.7259e-05 - val_acc: 1.0000\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0148 - acc: 0.9962 - val_loss: 4.4430e-05 - val_acc: 1.0000\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 6.4432e-05 - val_acc: 1.0000\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 1.4237e-04 - val_acc: 1.0000\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 4.7086e-05 - val_acc: 1.0000\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0199 - acc: 0.9947 - val_loss: 2.0609e-04 - val_acc: 1.0000\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 5.9751e-05 - val_acc: 1.0000\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 2.6185e-05 - val_acc: 1.0000\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0094 - acc: 0.9977 - val_loss: 2.2005e-04 - val_acc: 1.0000\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 3.1018e-04 - val_acc: 1.0000\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0138 - acc: 0.9955 - val_loss: 7.2907e-05 - val_acc: 1.0000\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 3.3083e-04 - val_acc: 1.0000\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 5.2277e-05 - val_acc: 1.0000\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 5.4887e-05 - val_acc: 1.0000\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 1.3003e-04 - val_acc: 1.0000\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0175 - acc: 0.9949 - val_loss: 6.5266e-05 - val_acc: 1.0000\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0100 - acc: 0.9977 - val_loss: 3.8712e-05 - val_acc: 1.0000\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 4.7838e-05 - val_acc: 1.0000\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.0086 - acc: 0.9982 - val_loss: 4.5320e-05 - val_acc: 1.0000\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0204 - acc: 0.9958 - val_loss: 3.2968e-05 - val_acc: 1.0000\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 2.1332e-05 - val_acc: 1.0000\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0210 - acc: 0.9948 - val_loss: 4.0036e-05 - val_acc: 1.0000\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0186 - acc: 0.9955 - val_loss: 7.0741e-05 - val_acc: 1.0000\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 3s 141ms/step - loss: 0.0105 - acc: 0.9962 - val_loss: 1.7650e-04 - val_acc: 1.0000\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 3.3018e-04 - val_acc: 1.0000\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 4.1098e-05 - val_acc: 1.0000\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0291 - acc: 0.9920\n",
            "\n",
            "Test Loss : 0.0291 Test Accuracy : 0.9920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJPUTjcU9EEH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}