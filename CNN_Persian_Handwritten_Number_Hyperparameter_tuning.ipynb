{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CNN_Persian_Handwritten_Number.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXt2Yt5vx73W",
        "outputId": "9f869956-5715-495e-d9a6-7425f928a48b"
      },
      "source": [
        "! git clone --recursive [GITHUB LINK REPO]    "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: Too many arguments.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --verbose         be more verbose\n",
            "    -q, --quiet           be more quiet\n",
            "    --progress            force progress reporting\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --bare                create a bare repository\n",
            "    --mirror              create a mirror repository (implies bare)\n",
            "    -l, --local           to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    -s, --shared          setup as shared repository\n",
            "    --recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    -j, --jobs <n>        number of submodules cloned in parallel\n",
            "    --template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --reference <repo>    reference repository\n",
            "    --reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --dissociate          use --reference only while cloning\n",
            "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
            "    -b, --branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --depth <depth>       create a shallow clone of that depth\n",
            "    --shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --single-branch       clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --shallow-submodules  any cloned submodules will be shallow\n",
            "    --separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    -c, --config <key=value>\n",
            "                          set config inside the new repository\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --filter <args>       object filtering\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4z9n01NyBTw",
        "outputId": "b511082a-6f3e-4878-a546-b78418338916"
      },
      "source": [
        "! git clone --recursive https://github.com/seyedalirezaabbaspour/Recognize-Persian-handwritten-numbers-with-keras.git"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Recognize-Persian-handwritten-numbers-with-keras' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbQ648x5yBWk",
        "outputId": "7486771e-4cbb-489d-fd64-d2bae95d4146"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Tu6NcLyBZR",
        "outputId": "c4d90f01-df15-439c-99c3-9bcc07adb417"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN_Persian_Handwritten_Number.ipynb\n",
            "Data_hoda_full.mat\n",
            "dataset_hoda.py\n",
            "datasets\n",
            "__pycache__\n",
            "README.md\n",
            "Recognize-Persian-handwritten-numbers-with-keras\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IW1-wzMyBcf"
      },
      "source": [
        "!ls Recognize-Persian-handwritten-numbers-with-keras"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO2Y84FkyBwI",
        "outputId": "2d562910-1bf5-40f5-ebb7-36ecd513dfa7"
      },
      "source": [
        "! mv /content/Recognize-Persian-handwritten-numbers-with-keras/* /content"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/Recognize-Persian-handwritten-numbers-with-keras/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkgdf7ntyScR",
        "outputId": "731853ff-4c1a-4749-92a3-52e31fba37d2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN_Persian_Handwritten_Number.ipynb\n",
            "Data_hoda_full.mat\n",
            "dataset_hoda.py\n",
            "datasets\n",
            "__pycache__\n",
            "README.md\n",
            "Recognize-Persian-handwritten-numbers-with-keras\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQqt3HChySfD",
        "outputId": "0e3ca59c-146a-4da0-f28a-0a85dddb398c"
      },
      "source": [
        "!mv /content/datasets/* /content"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/datasets/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zoumRyVykkA",
        "outputId": "b3302598-4db8-452a-d5c7-242e11f4a8a6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN_Persian_Handwritten_Number.ipynb\n",
            "Data_hoda_full.mat\n",
            "dataset_hoda.py\n",
            "datasets\n",
            "__pycache__\n",
            "README.md\n",
            "Recognize-Persian-handwritten-numbers-with-keras\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYOJ93WjxG3J"
      },
      "source": [
        "#  Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5cpcLRFxG3a"
      },
      "source": [
        "import keras \n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataset_hoda import load_hoda"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iHoPGNIxG3c"
      },
      "source": [
        "#load dataset\n",
        "X_train_original, y_train_original, X_test_original, y_test_original = load_hoda(training_sample_size=50000,\n",
        "                                                                                 test_sample_size=10000,\n",
        "                                                                                 size = 28)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2cPPxyrxG3e"
      },
      "source": [
        "#preprocessing\n",
        "\n",
        "''' input data in numpy array format'''\n",
        "X_train = np.array(X_train_original)\n",
        "X_test = np.array(X_test_original)\n",
        "\n",
        "\n",
        "''' normalize our data values to the range [0, 1]'''\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "\n",
        "X_train = X_train/ 255.0\n",
        "X_test = X_test  / 255.0\n",
        "\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# preprocessing class labels\n",
        "y_train = keras.utils.to_categorical(y_train_original)\n",
        "y_test = keras.utils.to_categorical(y_test_original)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjxf2bIlxG3f"
      },
      "source": [
        "# test and validation set\n",
        "X_validation = X_train[:10000]\n",
        "y_validation = y_train[:10000]\n",
        "\n",
        "X_train = X_train[10000:]\n",
        "y_train = y_train[10000:]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7PGqoLpxG3g",
        "outputId": "59998b41-31ba-4759-feb8-5c4ca7186c72"
      },
      "source": [
        "# 5. Define model architecture\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (2, 2), activation = \"relu\", padding=\"same\"))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(128, (2, 2), activation=\"relu\", padding= \"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         32896     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 845,546\n",
            "Trainable params: 845,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK6cw68WxG3m"
      },
      "source": [
        "# Compile Model\n",
        "adam = Adam(lr = 0.003)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Ejc-yqxG3n",
        "outputId": "7b8a5b5c-86d0-4880-e78e-77dfb4580a48"
      },
      "source": [
        "# Fit Model on Training Data\n",
        "history = model.fit(X_train, y_train,\n",
        "          validation_data=(X_validation, y_validation),\n",
        "          shuffle=True, \n",
        "          epochs=100, \n",
        "          batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 343ms/step - loss: 1.6225 - acc: 0.4150 - val_loss: 0.4029 - val_acc: 0.8940\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.4482 - acc: 0.8497 - val_loss: 0.1982 - val_acc: 0.9410\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.2799 - acc: 0.9048 - val_loss: 0.1509 - val_acc: 0.9590\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 0.1862 - acc: 0.9367 - val_loss: 0.1080 - val_acc: 0.9690\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.1625 - acc: 0.9455 - val_loss: 0.0972 - val_acc: 0.9740\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.1255 - acc: 0.9588 - val_loss: 0.0882 - val_acc: 0.9790\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 0.1154 - acc: 0.9604 - val_loss: 0.0736 - val_acc: 0.9740\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.0911 - acc: 0.9671 - val_loss: 0.0720 - val_acc: 0.9740\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 0.0806 - acc: 0.9730 - val_loss: 0.0789 - val_acc: 0.9720\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 0.0970 - acc: 0.9630 - val_loss: 0.0657 - val_acc: 0.9800\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.0779 - acc: 0.9764 - val_loss: 0.0695 - val_acc: 0.9790\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.0719 - acc: 0.9746 - val_loss: 0.0641 - val_acc: 0.9790\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 0.0642 - acc: 0.9793 - val_loss: 0.0606 - val_acc: 0.9780\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.0612 - acc: 0.9786 - val_loss: 0.0553 - val_acc: 0.9810\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.0592 - acc: 0.9820 - val_loss: 0.0571 - val_acc: 0.9790\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 0.0433 - acc: 0.9863 - val_loss: 0.0614 - val_acc: 0.9800\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.0483 - acc: 0.9845 - val_loss: 0.0541 - val_acc: 0.9810\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.0409 - acc: 0.9854 - val_loss: 0.0641 - val_acc: 0.9830\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.0689 - acc: 0.9785 - val_loss: 0.0486 - val_acc: 0.9800\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0499 - val_acc: 0.9830\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.0429 - acc: 0.9834 - val_loss: 0.0526 - val_acc: 0.9800\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0494 - val_acc: 0.9830\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.0455 - acc: 0.9835 - val_loss: 0.0510 - val_acc: 0.9850\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 0.0406 - acc: 0.9851 - val_loss: 0.0411 - val_acc: 0.9830\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.0494 - acc: 0.9814 - val_loss: 0.0438 - val_acc: 0.9850\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.0302 - acc: 0.9875 - val_loss: 0.0458 - val_acc: 0.9880\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.0381 - acc: 0.9870 - val_loss: 0.0447 - val_acc: 0.9820\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.0292 - acc: 0.9893 - val_loss: 0.0541 - val_acc: 0.9800\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0554 - val_acc: 0.9800\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.0263 - acc: 0.9908 - val_loss: 0.0654 - val_acc: 0.9810\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.0421 - acc: 0.9882 - val_loss: 0.0535 - val_acc: 0.9850\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.0350 - acc: 0.9855 - val_loss: 0.0569 - val_acc: 0.9800\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 0.0362 - acc: 0.9880 - val_loss: 0.0505 - val_acc: 0.9820\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.0406 - acc: 0.9832 - val_loss: 0.0622 - val_acc: 0.9830\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.0389 - acc: 0.9879 - val_loss: 0.0625 - val_acc: 0.9850\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0633 - val_acc: 0.9800\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.0520 - val_acc: 0.9850\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.0298 - acc: 0.9907 - val_loss: 0.0491 - val_acc: 0.9830\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.0215 - acc: 0.9927 - val_loss: 0.0622 - val_acc: 0.9850\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0624 - val_acc: 0.9830\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.0265 - acc: 0.9887 - val_loss: 0.0747 - val_acc: 0.9820\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.0286 - acc: 0.9890 - val_loss: 0.0574 - val_acc: 0.9810\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.0318 - acc: 0.9890 - val_loss: 0.0582 - val_acc: 0.9840\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.0204 - acc: 0.9928 - val_loss: 0.0506 - val_acc: 0.9850\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.0608 - val_acc: 0.9850\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.0369 - acc: 0.9873 - val_loss: 0.0620 - val_acc: 0.9800\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 0.0229 - acc: 0.9919 - val_loss: 0.0490 - val_acc: 0.9850\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.0586 - val_acc: 0.9840\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0437 - val_acc: 0.9860\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 0.0290 - acc: 0.9881 - val_loss: 0.0520 - val_acc: 0.9820\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 6s 407ms/step - loss: 0.0267 - acc: 0.9904 - val_loss: 0.0465 - val_acc: 0.9860\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 0.0258 - acc: 0.9911 - val_loss: 0.0484 - val_acc: 0.9850\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.0189 - acc: 0.9925 - val_loss: 0.0584 - val_acc: 0.9810\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.0275 - acc: 0.9903 - val_loss: 0.0572 - val_acc: 0.9810\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0485 - val_acc: 0.9820\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0537 - val_acc: 0.9850\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.0140 - acc: 0.9952 - val_loss: 0.0515 - val_acc: 0.9880\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.0209 - acc: 0.9921 - val_loss: 0.0561 - val_acc: 0.9840\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0688 - val_acc: 0.9850\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.0264 - acc: 0.9925 - val_loss: 0.0347 - val_acc: 0.9880\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.0295 - acc: 0.9937 - val_loss: 0.0440 - val_acc: 0.9850\n",
            "Epoch 62/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 6s 364ms/step - loss: 0.0200 - acc: 0.9914 - val_loss: 0.0476 - val_acc: 0.9850\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0487 - val_acc: 0.9870\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0575 - val_acc: 0.9860\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.0164 - acc: 0.9927 - val_loss: 0.0538 - val_acc: 0.9870\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0600 - val_acc: 0.9870\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.0175 - acc: 0.9937 - val_loss: 0.0559 - val_acc: 0.9860\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.0513 - val_acc: 0.9880\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.0196 - acc: 0.9949 - val_loss: 0.0548 - val_acc: 0.9820\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0496 - val_acc: 0.9860\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0497 - val_acc: 0.9860\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.0138 - acc: 0.9946 - val_loss: 0.0468 - val_acc: 0.9850\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0452 - val_acc: 0.9840\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.0140 - acc: 0.9943 - val_loss: 0.0498 - val_acc: 0.9820\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.0172 - acc: 0.9938 - val_loss: 0.0540 - val_acc: 0.9870\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.0123 - acc: 0.9954 - val_loss: 0.0589 - val_acc: 0.9870\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.0205 - acc: 0.9954 - val_loss: 0.0536 - val_acc: 0.9860\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0509 - val_acc: 0.9860\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.0612 - val_acc: 0.9860\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.0153 - acc: 0.9945 - val_loss: 0.0409 - val_acc: 0.9910\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.0183 - acc: 0.9929 - val_loss: 0.0614 - val_acc: 0.9860\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0188 - acc: 0.9924 - val_loss: 0.0623 - val_acc: 0.9860\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0589 - val_acc: 0.9850\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0433 - val_acc: 0.9900\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 0.0268 - acc: 0.9936 - val_loss: 0.0459 - val_acc: 0.9870\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.0201 - acc: 0.9922 - val_loss: 0.0474 - val_acc: 0.9850\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 5s 344ms/step - loss: 0.0166 - acc: 0.9923 - val_loss: 0.0491 - val_acc: 0.9850\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.0182 - acc: 0.9938 - val_loss: 0.0598 - val_acc: 0.9850\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0511 - val_acc: 0.9870\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.0148 - acc: 0.9948 - val_loss: 0.0506 - val_acc: 0.9850\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.0190 - acc: 0.9924 - val_loss: 0.0502 - val_acc: 0.9860\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0414 - val_acc: 0.9880\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.0210 - acc: 0.9939 - val_loss: 0.0329 - val_acc: 0.9900\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.0183 - acc: 0.9955 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0444 - val_acc: 0.9880\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.0182 - acc: 0.9930 - val_loss: 0.0470 - val_acc: 0.9860\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.0355 - val_acc: 0.9890\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0461 - val_acc: 0.9860\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.0218 - acc: 0.9917 - val_loss: 0.0682 - val_acc: 0.9850\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 0.0401 - val_acc: 0.9880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6s10QrbxG3o",
        "outputId": "3edd53fc-09b6-4cdf-940e-968dfe14567c"
      },
      "source": [
        "#Evaluate Model\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0916 - acc: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q7cJYwDxG3p",
        "outputId": "cce4093b-f8ce-45fa-ca31-2151e5f5f625"
      },
      "source": [
        "acc = history.history[\"acc\"]\n",
        "val_acc = history.history[\"val_acc\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eRg7zTKxG3q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwyZqbe5y_hL",
        "outputId": "9db515ac-3171-4869-a87c-45af2281f489"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3, 3),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (3, 3), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(256, (3, 3), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 5, 5, 256)         295168    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               1638656   \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 2,029,066\n",
            "Trainable params: 2,029,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbPtJdDmzFXL"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.003)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnbRTkQzzJBL",
        "outputId": "9991b043-d01b-4198-b134-33dd6351069f"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=100, \r\n",
        "          batch_size=256)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 2.1818 - acc: 0.2025 - val_loss: 0.8799 - val_acc: 0.8020\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.6589 - acc: 0.7790 - val_loss: 0.1834 - val_acc: 0.9440\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2739 - acc: 0.9059 - val_loss: 0.1081 - val_acc: 0.9620\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1715 - acc: 0.9414 - val_loss: 0.0930 - val_acc: 0.9730\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1323 - acc: 0.9536 - val_loss: 0.0847 - val_acc: 0.9740\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1243 - acc: 0.9587 - val_loss: 0.0631 - val_acc: 0.9820\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1030 - acc: 0.9665 - val_loss: 0.0683 - val_acc: 0.9740\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0846 - acc: 0.9754 - val_loss: 0.0903 - val_acc: 0.9770\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0940 - acc: 0.9645 - val_loss: 0.0650 - val_acc: 0.9760\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0511 - acc: 0.9818 - val_loss: 0.0563 - val_acc: 0.9820\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0634 - acc: 0.9801 - val_loss: 0.0502 - val_acc: 0.9830\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0483 - acc: 0.9828 - val_loss: 0.0466 - val_acc: 0.9810\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0443 - acc: 0.9878 - val_loss: 0.0606 - val_acc: 0.9820\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0576 - acc: 0.9794 - val_loss: 0.0514 - val_acc: 0.9830\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0548 - acc: 0.9831 - val_loss: 0.0539 - val_acc: 0.9840\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0400 - acc: 0.9846 - val_loss: 0.0479 - val_acc: 0.9840\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0404 - acc: 0.9866 - val_loss: 0.0508 - val_acc: 0.9850\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0497 - acc: 0.9848 - val_loss: 0.0499 - val_acc: 0.9850\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0509 - val_acc: 0.9850\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0368 - acc: 0.9862 - val_loss: 0.0521 - val_acc: 0.9840\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0406 - acc: 0.9879 - val_loss: 0.0440 - val_acc: 0.9890\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0329 - acc: 0.9887 - val_loss: 0.0425 - val_acc: 0.9880\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0308 - acc: 0.9892 - val_loss: 0.0498 - val_acc: 0.9840\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0318 - acc: 0.9886 - val_loss: 0.0515 - val_acc: 0.9840\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0323 - acc: 0.9905 - val_loss: 0.0457 - val_acc: 0.9870\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0440 - acc: 0.9855 - val_loss: 0.0545 - val_acc: 0.9830\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0467 - acc: 0.9875 - val_loss: 0.0444 - val_acc: 0.9890\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0314 - acc: 0.9880 - val_loss: 0.0311 - val_acc: 0.9920\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0227 - acc: 0.9933 - val_loss: 0.0378 - val_acc: 0.9880\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0259 - acc: 0.9931 - val_loss: 0.0366 - val_acc: 0.9900\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0339 - acc: 0.9904 - val_loss: 0.0321 - val_acc: 0.9890\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0187 - acc: 0.9930 - val_loss: 0.0455 - val_acc: 0.9840\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0376 - acc: 0.9872 - val_loss: 0.0453 - val_acc: 0.9820\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0263 - acc: 0.9926 - val_loss: 0.0371 - val_acc: 0.9890\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0293 - acc: 0.9900 - val_loss: 0.0283 - val_acc: 0.9890\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0261 - val_acc: 0.9930\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0229 - acc: 0.9946 - val_loss: 0.0314 - val_acc: 0.9880\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0375 - val_acc: 0.9890\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0180 - acc: 0.9928 - val_loss: 0.0467 - val_acc: 0.9900\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0337 - val_acc: 0.9870\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0146 - acc: 0.9961 - val_loss: 0.0420 - val_acc: 0.9900\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0347 - val_acc: 0.9920\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0219 - acc: 0.9931 - val_loss: 0.0331 - val_acc: 0.9890\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.0313 - val_acc: 0.9910\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0331 - val_acc: 0.9910\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0230 - acc: 0.9923 - val_loss: 0.0557 - val_acc: 0.9850\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0320 - acc: 0.9900 - val_loss: 0.0385 - val_acc: 0.9870\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0299 - acc: 0.9919 - val_loss: 0.0286 - val_acc: 0.9900\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0194 - acc: 0.9932 - val_loss: 0.0394 - val_acc: 0.9860\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0180 - acc: 0.9919 - val_loss: 0.0517 - val_acc: 0.9880\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.0297 - val_acc: 0.9910\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0159 - acc: 0.9950 - val_loss: 0.0285 - val_acc: 0.9900\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0487 - val_acc: 0.9890\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0207 - acc: 0.9927 - val_loss: 0.0464 - val_acc: 0.9870\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0194 - acc: 0.9946 - val_loss: 0.0320 - val_acc: 0.9920\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0195 - acc: 0.9945 - val_loss: 0.0290 - val_acc: 0.9910\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0428 - val_acc: 0.9920\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0200 - acc: 0.9924 - val_loss: 0.0331 - val_acc: 0.9910\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 0.0237 - val_acc: 0.9920\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0232 - acc: 0.9915 - val_loss: 0.0339 - val_acc: 0.9870\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0149 - acc: 0.9942 - val_loss: 0.0377 - val_acc: 0.9860\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9890\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0196 - val_acc: 0.9930\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.0454 - val_acc: 0.9870\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0337 - val_acc: 0.9910\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0199 - acc: 0.9943 - val_loss: 0.0559 - val_acc: 0.9900\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0261 - acc: 0.9933 - val_loss: 0.0683 - val_acc: 0.9860\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0285 - val_acc: 0.9890\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0590 - val_acc: 0.9860\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0174 - acc: 0.9930 - val_loss: 0.0326 - val_acc: 0.9920\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0371 - val_acc: 0.9900\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0317 - val_acc: 0.9900\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0129 - acc: 0.9966 - val_loss: 0.0324 - val_acc: 0.9910\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0117 - acc: 0.9951 - val_loss: 0.0341 - val_acc: 0.9920\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0362 - acc: 0.9927 - val_loss: 0.0379 - val_acc: 0.9900\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0304 - val_acc: 0.9880\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0435 - val_acc: 0.9870\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0171 - val_acc: 0.9930\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0514 - val_acc: 0.9870\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0250 - val_acc: 0.9910\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0219 - acc: 0.9937 - val_loss: 0.0303 - val_acc: 0.9910\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0453 - val_acc: 0.9870\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.0386 - val_acc: 0.9890\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0309 - val_acc: 0.9910\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.0271 - val_acc: 0.9940\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0176 - acc: 0.9966 - val_loss: 0.0283 - val_acc: 0.9900\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0193 - acc: 0.9938 - val_loss: 0.0402 - val_acc: 0.9910\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0144 - acc: 0.9964 - val_loss: 0.0349 - val_acc: 0.9930\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.0529 - val_acc: 0.9880\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0428 - val_acc: 0.9890\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0480 - val_acc: 0.9890\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0199 - acc: 0.9941 - val_loss: 0.0405 - val_acc: 0.9900\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0429 - val_acc: 0.9890\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0104 - acc: 0.9955 - val_loss: 0.0626 - val_acc: 0.9890\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0496 - val_acc: 0.9910\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0399 - val_acc: 0.9910\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0349 - val_acc: 0.9910\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0304 - val_acc: 0.9930\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0061 - acc: 0.9977 - val_loss: 0.0290 - val_acc: 0.9940\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0450 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFPR_v6zzNSj",
        "outputId": "6080a81f-af77-4319-b9f0-d03c48440ab3"
      },
      "source": [
        "#Evaluate Model\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0835 - acc: 0.9870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "iNuBihSXzULU",
        "outputId": "aab97c39-95fd-4859-a2e6-8bfc6b1e9502"
      },
      "source": [
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuKSkvZR0VxK",
        "outputId": "ebd1e2de-b27d-445b-d5de-e00d3d8e16b5"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (3, 3),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (3, 3), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(1256, (3, 3), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(512, (3, 3), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 1256)        1448168   \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 5, 5, 512)         5788160   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               6554112   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 13,870,066\n",
            "Trainable params: 13,870,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwbVr_Lz0dSq"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.003)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYUak2iP0hcD",
        "outputId": "963d42a0-511d-4aa7-96ba-0a80c1b3c653"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=100, \r\n",
        "          batch_size=256)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 4s 142ms/step - loss: 4.1523 - acc: 0.1065 - val_loss: 2.3084 - val_acc: 0.0890\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.8315 - acc: 0.3561 - val_loss: 2.3875 - val_acc: 0.1860\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 1.1379 - acc: 0.6097 - val_loss: 1.5478 - val_acc: 0.4280\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.7349 - acc: 0.7282 - val_loss: 1.2211 - val_acc: 0.5720\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.4915 - acc: 0.8231 - val_loss: 0.8219 - val_acc: 0.6950\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.3621 - acc: 0.8762 - val_loss: 0.4809 - val_acc: 0.8360\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.2572 - acc: 0.9111 - val_loss: 0.2841 - val_acc: 0.9250\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.2055 - acc: 0.9278 - val_loss: 0.3076 - val_acc: 0.8970\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1725 - acc: 0.9392 - val_loss: 0.1804 - val_acc: 0.9590\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1742 - acc: 0.9385 - val_loss: 0.2092 - val_acc: 0.9380\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1413 - acc: 0.9532 - val_loss: 0.1443 - val_acc: 0.9640\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1150 - acc: 0.9608 - val_loss: 0.1065 - val_acc: 0.9760\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1263 - acc: 0.9592 - val_loss: 0.1481 - val_acc: 0.9640\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1047 - acc: 0.9651 - val_loss: 0.1024 - val_acc: 0.9760\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1112 - acc: 0.9608 - val_loss: 0.0775 - val_acc: 0.9810\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0829 - acc: 0.9714 - val_loss: 0.0719 - val_acc: 0.9790\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0992 - acc: 0.9725 - val_loss: 0.0860 - val_acc: 0.9800\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0679 - acc: 0.9749 - val_loss: 0.0580 - val_acc: 0.9820\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0847 - acc: 0.9669 - val_loss: 0.0564 - val_acc: 0.9820\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0731 - acc: 0.9766 - val_loss: 0.0586 - val_acc: 0.9840\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0694 - acc: 0.9786 - val_loss: 0.0565 - val_acc: 0.9810\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0634 - acc: 0.9776 - val_loss: 0.0650 - val_acc: 0.9800\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0520 - acc: 0.9821 - val_loss: 0.0587 - val_acc: 0.9840\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0575 - acc: 0.9779 - val_loss: 0.0536 - val_acc: 0.9830\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0682 - acc: 0.9758 - val_loss: 0.0568 - val_acc: 0.9820\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0581 - acc: 0.9808 - val_loss: 0.0547 - val_acc: 0.9840\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0528 - acc: 0.9796 - val_loss: 0.0458 - val_acc: 0.9850\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0469 - acc: 0.9839 - val_loss: 0.0415 - val_acc: 0.9860\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0452 - acc: 0.9836 - val_loss: 0.0448 - val_acc: 0.9870\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0619 - acc: 0.9808 - val_loss: 0.0471 - val_acc: 0.9840\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0418 - acc: 0.9859 - val_loss: 0.0491 - val_acc: 0.9860\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0501 - acc: 0.9815 - val_loss: 0.0415 - val_acc: 0.9860\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0397 - val_acc: 0.9880\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0492 - acc: 0.9787 - val_loss: 0.0398 - val_acc: 0.9870\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0452 - acc: 0.9816 - val_loss: 0.0364 - val_acc: 0.9870\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0311 - acc: 0.9899 - val_loss: 0.0372 - val_acc: 0.9880\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0366 - acc: 0.9886 - val_loss: 0.0295 - val_acc: 0.9880\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0395 - acc: 0.9857 - val_loss: 0.0379 - val_acc: 0.9870\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0327 - acc: 0.9863 - val_loss: 0.0424 - val_acc: 0.9870\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0405 - acc: 0.9854 - val_loss: 0.0325 - val_acc: 0.9900\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0388 - acc: 0.9881 - val_loss: 0.0433 - val_acc: 0.9890\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0472 - acc: 0.9827 - val_loss: 0.0394 - val_acc: 0.9870\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0366 - val_acc: 0.9880\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0437 - acc: 0.9876 - val_loss: 0.0409 - val_acc: 0.9880\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0323 - acc: 0.9911 - val_loss: 0.0287 - val_acc: 0.9910\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0385 - acc: 0.9881 - val_loss: 0.0352 - val_acc: 0.9880\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0298 - val_acc: 0.9920\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0253 - acc: 0.9920 - val_loss: 0.0295 - val_acc: 0.9880\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0340 - val_acc: 0.9920\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0230 - acc: 0.9919 - val_loss: 0.0304 - val_acc: 0.9920\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0260 - acc: 0.9928 - val_loss: 0.0361 - val_acc: 0.9900\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0385 - val_acc: 0.9900\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0342 - val_acc: 0.9920\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0298 - acc: 0.9920 - val_loss: 0.0319 - val_acc: 0.9900\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0223 - acc: 0.9914 - val_loss: 0.0255 - val_acc: 0.9930\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0252 - acc: 0.9915 - val_loss: 0.0324 - val_acc: 0.9920\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0367 - val_acc: 0.9900\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0425 - val_acc: 0.9850\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0296 - acc: 0.9893 - val_loss: 0.0265 - val_acc: 0.9900\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0231 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9920\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0204 - acc: 0.9928 - val_loss: 0.0319 - val_acc: 0.9910\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0414 - val_acc: 0.9880\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0233 - acc: 0.9899 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0271 - acc: 0.9889 - val_loss: 0.0336 - val_acc: 0.9910\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0359 - acc: 0.9880 - val_loss: 0.0304 - val_acc: 0.9880\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0246 - acc: 0.9943 - val_loss: 0.0253 - val_acc: 0.9930\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0315 - acc: 0.9885 - val_loss: 0.0366 - val_acc: 0.9900\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0266 - acc: 0.9927 - val_loss: 0.0249 - val_acc: 0.9930\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0201 - acc: 0.9928 - val_loss: 0.0438 - val_acc: 0.9880\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0305 - val_acc: 0.9890\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0202 - acc: 0.9922 - val_loss: 0.0465 - val_acc: 0.9880\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0279 - acc: 0.9915 - val_loss: 0.0393 - val_acc: 0.9900\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0269 - acc: 0.9907 - val_loss: 0.0299 - val_acc: 0.9920\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0202 - acc: 0.9931 - val_loss: 0.0346 - val_acc: 0.9940\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0364 - acc: 0.9886 - val_loss: 0.0397 - val_acc: 0.9890\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0210 - acc: 0.9926 - val_loss: 0.0313 - val_acc: 0.9920\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0281 - acc: 0.9904 - val_loss: 0.0373 - val_acc: 0.9890\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 0.0295 - val_acc: 0.9900\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0347 - val_acc: 0.9890\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0409 - val_acc: 0.9870\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0192 - acc: 0.9933 - val_loss: 0.0434 - val_acc: 0.9900\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0188 - acc: 0.9951 - val_loss: 0.0394 - val_acc: 0.9880\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0311 - acc: 0.9915 - val_loss: 0.0343 - val_acc: 0.9910\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0192 - acc: 0.9954 - val_loss: 0.0366 - val_acc: 0.9900\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0245 - acc: 0.9927 - val_loss: 0.0331 - val_acc: 0.9890\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.0312 - val_acc: 0.9900\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.0401 - val_acc: 0.9870\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0154 - acc: 0.9946 - val_loss: 0.0282 - val_acc: 0.9910\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0165 - acc: 0.9949 - val_loss: 0.0579 - val_acc: 0.9830\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0202 - acc: 0.9954 - val_loss: 0.0399 - val_acc: 0.9890\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0272 - val_acc: 0.9910\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0161 - acc: 0.9951 - val_loss: 0.0414 - val_acc: 0.9890\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.0304 - val_acc: 0.9950\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0142 - acc: 0.9942 - val_loss: 0.0371 - val_acc: 0.9850\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0242 - acc: 0.9925 - val_loss: 0.0282 - val_acc: 0.9910\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0285 - acc: 0.9924 - val_loss: 0.0335 - val_acc: 0.9870\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0246 - acc: 0.9949 - val_loss: 0.0419 - val_acc: 0.9880\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0348 - acc: 0.9920 - val_loss: 0.0380 - val_acc: 0.9860\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0340 - acc: 0.9933 - val_loss: 0.0294 - val_acc: 0.9920\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.0257 - val_acc: 0.9930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ9k6s8v025p",
        "outputId": "205656de-f0b1-4cf0-b6f3-600d968b8dad"
      },
      "source": [
        "#Evaluate Model\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0520 - acc: 0.9840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNzJMAo9ZL-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LAIEzP51LM8",
        "outputId": "bdcf4ade-9e5e-40d8-eaf6-48baa2949373"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3, 3),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (3, 3), activation = \"relu\", padding=\"valid\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Conv2D(256, (3, 3), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,490,634\n",
            "Trainable params: 2,490,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj1YYud6ZDDi"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.003)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N6o-lsKZDGS",
        "outputId": "9f6af616-412a-4a5c-db42-fd29bf5c6575"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=100, \r\n",
        "          batch_size=256)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 34s 55ms/step - loss: 2.1352 - acc: 0.2255 - val_loss: 0.9629 - val_acc: 0.7520\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6823 - acc: 0.7571 - val_loss: 0.2941 - val_acc: 0.9060\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2764 - acc: 0.8960 - val_loss: 0.1872 - val_acc: 0.9570\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1953 - acc: 0.9422 - val_loss: 0.1457 - val_acc: 0.9560\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1818 - acc: 0.9352 - val_loss: 0.0982 - val_acc: 0.9710\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1159 - acc: 0.9566 - val_loss: 0.0909 - val_acc: 0.9750\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1115 - acc: 0.9629 - val_loss: 0.0734 - val_acc: 0.9750\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0941 - acc: 0.9670 - val_loss: 0.0693 - val_acc: 0.9790\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0808 - acc: 0.9684 - val_loss: 0.0682 - val_acc: 0.9790\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0760 - acc: 0.9740 - val_loss: 0.0770 - val_acc: 0.9800\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0734 - acc: 0.9781 - val_loss: 0.0711 - val_acc: 0.9720\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0838 - acc: 0.9718 - val_loss: 0.0611 - val_acc: 0.9820\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0534 - acc: 0.9809 - val_loss: 0.0556 - val_acc: 0.9800\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0614 - acc: 0.9809 - val_loss: 0.0476 - val_acc: 0.9820\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0522 - acc: 0.9821 - val_loss: 0.0549 - val_acc: 0.9810\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0515 - acc: 0.9841 - val_loss: 0.0458 - val_acc: 0.9780\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0352 - acc: 0.9881 - val_loss: 0.0542 - val_acc: 0.9790\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0463 - acc: 0.9839 - val_loss: 0.0545 - val_acc: 0.9770\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0386 - acc: 0.9841 - val_loss: 0.0439 - val_acc: 0.9830\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0401 - acc: 0.9868 - val_loss: 0.0608 - val_acc: 0.9780\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0337 - acc: 0.9882 - val_loss: 0.0515 - val_acc: 0.9840\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0431 - acc: 0.9829 - val_loss: 0.0460 - val_acc: 0.9840\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0356 - acc: 0.9867 - val_loss: 0.0442 - val_acc: 0.9820\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0504 - val_acc: 0.9830\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0609 - val_acc: 0.9830\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0355 - acc: 0.9885 - val_loss: 0.0484 - val_acc: 0.9880\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0295 - acc: 0.9901 - val_loss: 0.0665 - val_acc: 0.9810\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0440 - acc: 0.9852 - val_loss: 0.0393 - val_acc: 0.9850\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0348 - acc: 0.9868 - val_loss: 0.0446 - val_acc: 0.9830\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - acc: 0.9925 - val_loss: 0.0391 - val_acc: 0.9860\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0232 - acc: 0.9942 - val_loss: 0.0381 - val_acc: 0.9890\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0365 - val_acc: 0.9870\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.0316 - val_acc: 0.9870\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0260 - acc: 0.9894 - val_loss: 0.0502 - val_acc: 0.9840\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0170 - acc: 0.9939 - val_loss: 0.0654 - val_acc: 0.9830\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0465 - val_acc: 0.9880\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0180 - acc: 0.9949 - val_loss: 0.0408 - val_acc: 0.9880\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0230 - acc: 0.9921 - val_loss: 0.0495 - val_acc: 0.9870\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0530 - val_acc: 0.9840\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0240 - acc: 0.9916 - val_loss: 0.0380 - val_acc: 0.9890\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0217 - acc: 0.9909 - val_loss: 0.0331 - val_acc: 0.9900\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0891 - val_acc: 0.9820\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0265 - acc: 0.9897 - val_loss: 0.0468 - val_acc: 0.9840\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0245 - acc: 0.9934 - val_loss: 0.0431 - val_acc: 0.9880\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0319 - acc: 0.9926 - val_loss: 0.0436 - val_acc: 0.9830\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0217 - acc: 0.9909 - val_loss: 0.0497 - val_acc: 0.9860\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0189 - acc: 0.9955 - val_loss: 0.0384 - val_acc: 0.9880\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0352 - val_acc: 0.9870\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0479 - val_acc: 0.9890\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0460 - val_acc: 0.9890\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0259 - acc: 0.9907 - val_loss: 0.0499 - val_acc: 0.9840\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0301 - acc: 0.9912 - val_loss: 0.0374 - val_acc: 0.9880\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0418 - acc: 0.9869 - val_loss: 0.0438 - val_acc: 0.9870\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0166 - acc: 0.9925 - val_loss: 0.0375 - val_acc: 0.9880\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0266 - acc: 0.9929 - val_loss: 0.0458 - val_acc: 0.9850\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - acc: 0.9931 - val_loss: 0.0591 - val_acc: 0.9830\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0428 - val_acc: 0.9890\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0119 - acc: 0.9947 - val_loss: 0.0651 - val_acc: 0.9810\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0171 - acc: 0.9931 - val_loss: 0.0312 - val_acc: 0.9920\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0343 - val_acc: 0.9910\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0143 - acc: 0.9959 - val_loss: 0.0316 - val_acc: 0.9910\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0698 - val_acc: 0.9850\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0272 - acc: 0.9900 - val_loss: 0.0449 - val_acc: 0.9860\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0220 - acc: 0.9952 - val_loss: 0.0254 - val_acc: 0.9920\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0235 - acc: 0.9913 - val_loss: 0.0424 - val_acc: 0.9880\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 0.0276 - val_acc: 0.9920\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0147 - acc: 0.9961 - val_loss: 0.0297 - val_acc: 0.9930\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0377 - val_acc: 0.9890\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0496 - val_acc: 0.9890\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0156 - acc: 0.9931 - val_loss: 0.0372 - val_acc: 0.9880\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0147 - acc: 0.9929 - val_loss: 0.0209 - val_acc: 0.9930\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0146 - acc: 0.9948 - val_loss: 0.0509 - val_acc: 0.9870\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0212 - val_acc: 0.9910\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0233 - acc: 0.9943 - val_loss: 0.0374 - val_acc: 0.9900\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0279 - acc: 0.9924 - val_loss: 0.0291 - val_acc: 0.9900\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0413 - acc: 0.9889 - val_loss: 0.0364 - val_acc: 0.9870\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.0445 - val_acc: 0.9860\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.0531 - val_acc: 0.9880\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0235 - acc: 0.9942 - val_loss: 0.0457 - val_acc: 0.9870\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0275 - acc: 0.9906 - val_loss: 0.0356 - val_acc: 0.9880\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0146 - acc: 0.9936 - val_loss: 0.0311 - val_acc: 0.9900\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0449 - acc: 0.9898 - val_loss: 0.0355 - val_acc: 0.9890\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - acc: 0.9959 - val_loss: 0.0304 - val_acc: 0.9910\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0255 - acc: 0.9911 - val_loss: 0.0324 - val_acc: 0.9900\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0240 - acc: 0.9916 - val_loss: 0.0329 - val_acc: 0.9870\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.0485 - val_acc: 0.9870\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0207 - acc: 0.9928 - val_loss: 0.0308 - val_acc: 0.9910\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0253 - acc: 0.9932 - val_loss: 0.0376 - val_acc: 0.9890\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - acc: 0.9952 - val_loss: 0.0560 - val_acc: 0.9900\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.0553 - val_acc: 0.9890\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0193 - acc: 0.9950 - val_loss: 0.0234 - val_acc: 0.9950\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0226 - acc: 0.9941 - val_loss: 0.0449 - val_acc: 0.9890\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0453 - val_acc: 0.9870\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - acc: 0.9972 - val_loss: 0.0350 - val_acc: 0.9920\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0076 - acc: 0.9959 - val_loss: 0.0332 - val_acc: 0.9930\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0353 - val_acc: 0.9930\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0369 - val_acc: 0.9910\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0160 - val_acc: 0.9940\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.0166 - val_acc: 0.9940\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0201 - acc: 0.9948 - val_loss: 0.0432 - val_acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLV_FcY5ZDKW",
        "outputId": "1ef141ed-a0b7-4511-af7b-168eb9427b28"
      },
      "source": [
        "#Evaluate Model\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0621 - acc: 0.9860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytt-z3_qZ-VU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdJsblZSaEwZ",
        "outputId": "932ec61a-90da-4bee-a604-9d816afdc91e"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 28, 28, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 7, 7, 128)         131200    \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,740,522\n",
            "Trainable params: 1,740,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_msymCvjaE2H"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.003)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqwmbUKkaE4-",
        "outputId": "0c3594ba-b90c-4a7a-9cca-c9b1db1de288"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=100, \r\n",
        "          batch_size=256)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 54ms/step - loss: 2.3404 - acc: 0.1440 - val_loss: 1.1596 - val_acc: 0.6610\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.0843 - acc: 0.5965 - val_loss: 0.4580 - val_acc: 0.8670\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.4862 - acc: 0.8363 - val_loss: 0.1830 - val_acc: 0.9430\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2320 - acc: 0.9208 - val_loss: 0.1321 - val_acc: 0.9580\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1663 - acc: 0.9430 - val_loss: 0.1129 - val_acc: 0.9620\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1583 - acc: 0.9506 - val_loss: 0.0755 - val_acc: 0.9770\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0906 - acc: 0.9724 - val_loss: 0.0819 - val_acc: 0.9760\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1229 - acc: 0.9594 - val_loss: 0.0723 - val_acc: 0.9780\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0694 - acc: 0.9772 - val_loss: 0.0754 - val_acc: 0.9790\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0907 - acc: 0.9694 - val_loss: 0.0803 - val_acc: 0.9730\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0763 - acc: 0.9770 - val_loss: 0.0538 - val_acc: 0.9840\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0537 - acc: 0.9830 - val_loss: 0.0612 - val_acc: 0.9820\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0517 - acc: 0.9813 - val_loss: 0.0649 - val_acc: 0.9830\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0534 - acc: 0.9829 - val_loss: 0.0611 - val_acc: 0.9770\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0551 - acc: 0.9824 - val_loss: 0.0540 - val_acc: 0.9880\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0435 - acc: 0.9869 - val_loss: 0.0538 - val_acc: 0.9840\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0339 - acc: 0.9905 - val_loss: 0.0441 - val_acc: 0.9910\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0255 - acc: 0.9901 - val_loss: 0.0437 - val_acc: 0.9890\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0386 - val_acc: 0.9900\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0369 - acc: 0.9878 - val_loss: 0.0412 - val_acc: 0.9890\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0375 - acc: 0.9875 - val_loss: 0.0349 - val_acc: 0.9910\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0443 - acc: 0.9855 - val_loss: 0.0442 - val_acc: 0.9870\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0261 - acc: 0.9936 - val_loss: 0.0512 - val_acc: 0.9850\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0270 - acc: 0.9893 - val_loss: 0.0459 - val_acc: 0.9900\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0234 - acc: 0.9914 - val_loss: 0.0418 - val_acc: 0.9900\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0247 - acc: 0.9906 - val_loss: 0.0358 - val_acc: 0.9920\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0325 - acc: 0.9893 - val_loss: 0.0348 - val_acc: 0.9900\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0295 - acc: 0.9895 - val_loss: 0.0545 - val_acc: 0.9840\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0422 - acc: 0.9885 - val_loss: 0.0561 - val_acc: 0.9870\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0337 - val_acc: 0.9910\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0198 - acc: 0.9937 - val_loss: 0.0382 - val_acc: 0.9900\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0186 - acc: 0.9925 - val_loss: 0.0372 - val_acc: 0.9910\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0346 - val_acc: 0.9910\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0150 - acc: 0.9946 - val_loss: 0.0348 - val_acc: 0.9910\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0126 - acc: 0.9953 - val_loss: 0.0550 - val_acc: 0.9910\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0445 - val_acc: 0.9870\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0194 - acc: 0.9952 - val_loss: 0.0443 - val_acc: 0.9920\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0602 - val_acc: 0.9880\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0152 - acc: 0.9945 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0293 - val_acc: 0.9920\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 0.0373 - val_acc: 0.9930\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0540 - val_acc: 0.9910\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0647 - val_acc: 0.9850\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0277 - acc: 0.9905 - val_loss: 0.0470 - val_acc: 0.9890\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0293 - acc: 0.9924 - val_loss: 0.0460 - val_acc: 0.9900\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0293 - acc: 0.9929 - val_loss: 0.0612 - val_acc: 0.9890\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0626 - val_acc: 0.9840\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9910\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0452 - val_acc: 0.9910\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0298 - val_acc: 0.9910\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0219 - acc: 0.9934 - val_loss: 0.0251 - val_acc: 0.9920\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9900\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0164 - acc: 0.9969 - val_loss: 0.0423 - val_acc: 0.9910\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0294 - acc: 0.9928 - val_loss: 0.0422 - val_acc: 0.9930\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0297 - acc: 0.9920 - val_loss: 0.0357 - val_acc: 0.9930\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.0533 - val_acc: 0.9920\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0243 - acc: 0.9931 - val_loss: 0.0338 - val_acc: 0.9920\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0243 - acc: 0.9902 - val_loss: 0.0374 - val_acc: 0.9930\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0318 - val_acc: 0.9900\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0176 - acc: 0.9952 - val_loss: 0.0328 - val_acc: 0.9940\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0165 - acc: 0.9923 - val_loss: 0.0418 - val_acc: 0.9910\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0211 - acc: 0.9943 - val_loss: 0.0285 - val_acc: 0.9940\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.0263 - val_acc: 0.9930\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0121 - acc: 0.9954 - val_loss: 0.0241 - val_acc: 0.9930\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0209 - acc: 0.9947 - val_loss: 0.0207 - val_acc: 0.9960\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0287 - val_acc: 0.9920\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0157 - acc: 0.9975 - val_loss: 0.0483 - val_acc: 0.9890\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0255 - acc: 0.9929 - val_loss: 0.0434 - val_acc: 0.9930\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.0585 - val_acc: 0.9890\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0335 - val_acc: 0.9920\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0071 - acc: 0.9973 - val_loss: 0.0322 - val_acc: 0.9950\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0301 - val_acc: 0.9940\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0438 - val_acc: 0.9920\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.0439 - val_acc: 0.9900\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0531 - val_acc: 0.9910\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0597 - val_acc: 0.9900\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.0346 - val_acc: 0.9920\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0505 - val_acc: 0.9900\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0210 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9900\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0159 - acc: 0.9946 - val_loss: 0.0308 - val_acc: 0.9950\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0185 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9920\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0423 - val_acc: 0.9940\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0083 - acc: 0.9952 - val_loss: 0.0637 - val_acc: 0.9930\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0217 - acc: 0.9947 - val_loss: 0.0391 - val_acc: 0.9910\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9950\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0275 - acc: 0.9941 - val_loss: 0.0437 - val_acc: 0.9900\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0414 - val_acc: 0.9890\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0281 - acc: 0.9922 - val_loss: 0.0498 - val_acc: 0.9900\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0417 - val_acc: 0.9940\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0141 - acc: 0.9975 - val_loss: 0.0757 - val_acc: 0.9870\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0232 - acc: 0.9919 - val_loss: 0.0746 - val_acc: 0.9880\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0266 - acc: 0.9928 - val_loss: 0.0351 - val_acc: 0.9910\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0182 - acc: 0.9960 - val_loss: 0.0589 - val_acc: 0.9930\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0236 - acc: 0.9946 - val_loss: 0.0524 - val_acc: 0.9910\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0198 - acc: 0.9960 - val_loss: 0.0490 - val_acc: 0.9940\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0233 - acc: 0.9934 - val_loss: 0.0525 - val_acc: 0.9860\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0158 - acc: 0.9956 - val_loss: 0.0376 - val_acc: 0.9930\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0342 - acc: 0.9919 - val_loss: 0.0459 - val_acc: 0.9920\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0187 - acc: 0.9952 - val_loss: 0.0508 - val_acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlA7EkKNaE8A",
        "outputId": "b3816492-f667-4713-d0e4-91dd78cbeacb"
      },
      "source": [
        "#Evaluate Model\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0498 - acc: 0.9880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_IL9KcaE-l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLyz4SExaigp",
        "outputId": "8a08060f-3e8c-4c80-c434-6b157c3b9e17"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 14, 14, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 7, 7, 128)         131200    \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,740,522\n",
            "Trainable params: 1,740,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi5Aus7yaiqM"
      },
      "source": [
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We6EYOFSaivW",
        "outputId": "920065e7-f51c-446c-c28c-ea650b793dfb"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=200, \r\n",
        "          batch_size=512)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 161ms/step - loss: 2.1279 - acc: 0.2065 - val_loss: 1.0756 - val_acc: 0.6860\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1027 - acc: 0.6096 - val_loss: 0.5691 - val_acc: 0.8250\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6355 - acc: 0.7744 - val_loss: 0.3600 - val_acc: 0.8940\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4403 - acc: 0.8450 - val_loss: 0.2165 - val_acc: 0.9360\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.2890 - acc: 0.8966 - val_loss: 0.1701 - val_acc: 0.9490\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2099 - acc: 0.9290 - val_loss: 0.1396 - val_acc: 0.9570\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1924 - acc: 0.9357 - val_loss: 0.1133 - val_acc: 0.9670\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1394 - acc: 0.9476 - val_loss: 0.1022 - val_acc: 0.9710\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1396 - acc: 0.9556 - val_loss: 0.1041 - val_acc: 0.9700\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1153 - acc: 0.9611 - val_loss: 0.0802 - val_acc: 0.9760\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1206 - acc: 0.9615 - val_loss: 0.0752 - val_acc: 0.9810\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0848 - acc: 0.9708 - val_loss: 0.0640 - val_acc: 0.9780\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0804 - acc: 0.9724 - val_loss: 0.0620 - val_acc: 0.9810\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0856 - acc: 0.9715 - val_loss: 0.0583 - val_acc: 0.9820\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0639 - acc: 0.9787 - val_loss: 0.0635 - val_acc: 0.9810\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0676 - acc: 0.9789 - val_loss: 0.0635 - val_acc: 0.9810\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0652 - acc: 0.9806 - val_loss: 0.0623 - val_acc: 0.9780\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0678 - acc: 0.9756 - val_loss: 0.0533 - val_acc: 0.9830\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0501 - acc: 0.9851 - val_loss: 0.0597 - val_acc: 0.9790\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0653 - acc: 0.9792 - val_loss: 0.0497 - val_acc: 0.9840\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0510 - acc: 0.9809 - val_loss: 0.0466 - val_acc: 0.9840\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0495 - acc: 0.9846 - val_loss: 0.0455 - val_acc: 0.9880\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0492 - acc: 0.9827 - val_loss: 0.0517 - val_acc: 0.9850\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0451 - acc: 0.9836 - val_loss: 0.0538 - val_acc: 0.9810\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0385 - acc: 0.9872 - val_loss: 0.0438 - val_acc: 0.9860\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0446 - acc: 0.9846 - val_loss: 0.0474 - val_acc: 0.9830\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0380 - acc: 0.9868 - val_loss: 0.0453 - val_acc: 0.9820\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0363 - acc: 0.9873 - val_loss: 0.0466 - val_acc: 0.9850\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0423 - acc: 0.9872 - val_loss: 0.0411 - val_acc: 0.9840\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0436 - val_acc: 0.9840\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0374 - acc: 0.9864 - val_loss: 0.0439 - val_acc: 0.9870\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0481 - val_acc: 0.9810\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0360 - acc: 0.9867 - val_loss: 0.0417 - val_acc: 0.9870\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0232 - acc: 0.9916 - val_loss: 0.0325 - val_acc: 0.9860\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0245 - acc: 0.9905 - val_loss: 0.0355 - val_acc: 0.9870\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0315 - acc: 0.9900 - val_loss: 0.0352 - val_acc: 0.9880\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0234 - acc: 0.9887 - val_loss: 0.0388 - val_acc: 0.9870\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0366 - val_acc: 0.9890\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0335 - acc: 0.9887 - val_loss: 0.0413 - val_acc: 0.9850\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0247 - acc: 0.9912 - val_loss: 0.0313 - val_acc: 0.9860\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0347 - val_acc: 0.9890\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0355 - val_acc: 0.9890\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.0439 - val_acc: 0.9870\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0249 - acc: 0.9913 - val_loss: 0.0303 - val_acc: 0.9890\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0195 - acc: 0.9932 - val_loss: 0.0347 - val_acc: 0.9890\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0176 - acc: 0.9926 - val_loss: 0.0400 - val_acc: 0.9880\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0170 - acc: 0.9936 - val_loss: 0.0394 - val_acc: 0.9880\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0200 - acc: 0.9924 - val_loss: 0.0413 - val_acc: 0.9860\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0150 - acc: 0.9940 - val_loss: 0.0467 - val_acc: 0.9840\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0153 - acc: 0.9958 - val_loss: 0.0332 - val_acc: 0.9880\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0202 - acc: 0.9925 - val_loss: 0.0400 - val_acc: 0.9850\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0207 - acc: 0.9920 - val_loss: 0.0413 - val_acc: 0.9880\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0361 - val_acc: 0.9880\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0149 - acc: 0.9937 - val_loss: 0.0324 - val_acc: 0.9900\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0163 - acc: 0.9940 - val_loss: 0.0334 - val_acc: 0.9880\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0403 - val_acc: 0.9880\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0371 - val_acc: 0.9880\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0294 - val_acc: 0.9890\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0462 - val_acc: 0.9860\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0307 - val_acc: 0.9890\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0122 - acc: 0.9963 - val_loss: 0.0417 - val_acc: 0.9870\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0393 - val_acc: 0.9830\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0451 - val_acc: 0.9870\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0125 - acc: 0.9955 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0080 - acc: 0.9970 - val_loss: 0.0334 - val_acc: 0.9870\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0378 - val_acc: 0.9880\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.0371 - val_acc: 0.9910\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0321 - val_acc: 0.9890\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0367 - val_acc: 0.9910\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0102 - acc: 0.9962 - val_loss: 0.0478 - val_acc: 0.9870\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0356 - val_acc: 0.9890\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0380 - val_acc: 0.9860\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0099 - acc: 0.9964 - val_loss: 0.0326 - val_acc: 0.9920\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0339 - val_acc: 0.9890\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0101 - acc: 0.9957 - val_loss: 0.0316 - val_acc: 0.9920\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0296 - val_acc: 0.9890\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0398 - val_acc: 0.9880\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0384 - val_acc: 0.9900\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.0330 - val_acc: 0.9900\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.0329 - val_acc: 0.9890\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9880\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0061 - acc: 0.9976 - val_loss: 0.0341 - val_acc: 0.9880\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0421 - val_acc: 0.9880\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0390 - val_acc: 0.9910\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.0423 - val_acc: 0.9890\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.0602 - val_acc: 0.9850\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0133 - acc: 0.9976 - val_loss: 0.0331 - val_acc: 0.9870\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0377 - val_acc: 0.9890\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0345 - val_acc: 0.9880\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0122 - acc: 0.9942 - val_loss: 0.0359 - val_acc: 0.9860\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0351 - val_acc: 0.9870\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0103 - acc: 0.9957 - val_loss: 0.0352 - val_acc: 0.9870\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.0376 - val_acc: 0.9880\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0426 - val_acc: 0.9870\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9890\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0370 - val_acc: 0.9870\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0328 - val_acc: 0.9910\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0068 - acc: 0.9968 - val_loss: 0.0292 - val_acc: 0.9890\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0072 - acc: 0.9971 - val_loss: 0.0354 - val_acc: 0.9890\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0344 - val_acc: 0.9890\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0040 - acc: 0.9979 - val_loss: 0.0309 - val_acc: 0.9900\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0352 - val_acc: 0.9910\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0057 - acc: 0.9976 - val_loss: 0.0331 - val_acc: 0.9920\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0060 - acc: 0.9968 - val_loss: 0.0292 - val_acc: 0.9930\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0059 - acc: 0.9977 - val_loss: 0.0408 - val_acc: 0.9900\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0439 - val_acc: 0.9900\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0035 - acc: 0.9985 - val_loss: 0.0389 - val_acc: 0.9900\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0442 - val_acc: 0.9890\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0489 - val_acc: 0.9890\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0428 - val_acc: 0.9910\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0353 - val_acc: 0.9910\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0409 - val_acc: 0.9920\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0467 - val_acc: 0.9900\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0312 - val_acc: 0.9920\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0256 - val_acc: 0.9920\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0454 - val_acc: 0.9900\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0491 - val_acc: 0.9880\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0086 - acc: 0.9968 - val_loss: 0.0438 - val_acc: 0.9870\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0055 - acc: 0.9979 - val_loss: 0.0324 - val_acc: 0.9900\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0593 - val_acc: 0.9890\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0168 - acc: 0.9956 - val_loss: 0.0496 - val_acc: 0.9890\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0516 - val_acc: 0.9870\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 0.0429 - val_acc: 0.9880\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0042 - acc: 0.9977 - val_loss: 0.0419 - val_acc: 0.9890\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0398 - val_acc: 0.9890\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0341 - val_acc: 0.9900\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0442 - val_acc: 0.9900\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0421 - val_acc: 0.9880\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0361 - val_acc: 0.9910\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.0446 - val_acc: 0.9890\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0390 - val_acc: 0.9890\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0474 - val_acc: 0.9910\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0507 - val_acc: 0.9920\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0295 - val_acc: 0.9950\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0380 - val_acc: 0.9900\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0385 - val_acc: 0.9900\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9890\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0336 - val_acc: 0.9920\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0407 - val_acc: 0.9930\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0034 - acc: 0.9979 - val_loss: 0.0544 - val_acc: 0.9930\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0417 - val_acc: 0.9910\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0389 - val_acc: 0.9920\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0291 - val_acc: 0.9910\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.0428 - val_acc: 0.9910\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0534 - val_acc: 0.9900\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0390 - val_acc: 0.9910\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0356 - val_acc: 0.9930\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0341 - val_acc: 0.9920\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0409 - val_acc: 0.9920\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0045 - acc: 0.9982 - val_loss: 0.0276 - val_acc: 0.9930\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0273 - val_acc: 0.9940\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0310 - val_acc: 0.9930\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0413 - val_acc: 0.9940\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0441 - val_acc: 0.9930\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0317 - val_acc: 0.9920\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 0.0327 - val_acc: 0.9920\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0413 - val_acc: 0.9930\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0412 - val_acc: 0.9950\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0030 - acc: 0.9986 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0345 - val_acc: 0.9920\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0372 - val_acc: 0.9920\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.0238 - val_acc: 0.9940\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0262 - val_acc: 0.9950\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0021 - acc: 0.9988 - val_loss: 0.0262 - val_acc: 0.9940\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0387 - val_acc: 0.9920\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0451 - val_acc: 0.9910\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0408 - val_acc: 0.9930\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0294 - val_acc: 0.9930\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0266 - val_acc: 0.9920\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0391 - val_acc: 0.9940\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0400 - val_acc: 0.9930\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0339 - val_acc: 0.9940\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 0.0337 - val_acc: 0.9940\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0032 - acc: 0.9981 - val_loss: 0.0388 - val_acc: 0.9940\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0438 - val_acc: 0.9930\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0415 - val_acc: 0.9920\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0030 - acc: 0.9984 - val_loss: 0.0568 - val_acc: 0.9910\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0424 - val_acc: 0.9920\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.0412 - val_acc: 0.9940\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 0.0284 - val_acc: 0.9930\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0458 - val_acc: 0.9930\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0332 - val_acc: 0.9940\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0330 - val_acc: 0.9940\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0401 - val_acc: 0.9940\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0380 - val_acc: 0.9940\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 0.0450 - val_acc: 0.9930\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0467 - val_acc: 0.9910\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0028 - acc: 0.9986 - val_loss: 0.0351 - val_acc: 0.9950\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 9.3863e-04 - acc: 0.9997 - val_loss: 0.0520 - val_acc: 0.9890\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0458 - val_acc: 0.9900\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0033 - acc: 0.9986 - val_loss: 0.0460 - val_acc: 0.9930\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.4215e-04 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9930\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0478 - val_acc: 0.9940\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 0.0400 - val_acc: 0.9950\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0404 - val_acc: 0.9950\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0465 - val_acc: 0.9920\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0027 - acc: 0.9989 - val_loss: 0.0550 - val_acc: 0.9930\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0592 - val_acc: 0.9940\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0524 - val_acc: 0.9930\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0020 - acc: 0.9988 - val_loss: 0.0498 - val_acc: 0.9940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdohp1_rai6V",
        "outputId": "bca55849-e8c3-441e-e7af-e317b5be5c4c"
      },
      "source": [
        "#Evaluate Model\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0655 - acc: 0.9850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB55SUV0awsN",
        "outputId": "95af32c5-4c99-4f1a-823b-45d7c4a20766"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 28, 28, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 14, 14, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 7, 7, 128)         131200    \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,740,522\n",
            "Trainable params: 1,740,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ClqfaY4b5VD",
        "outputId": "5ca8c226-42b9-49d6-8bab-37f981518cfe"
      },
      "source": [
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=200, \r\n",
        "          batch_size=128)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 2s 21ms/step - loss: 1.7197 - acc: 0.3596 - val_loss: 0.3914 - val_acc: 0.8700\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.4523 - acc: 0.8376 - val_loss: 0.1789 - val_acc: 0.9550\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2671 - acc: 0.9173 - val_loss: 0.1056 - val_acc: 0.9700\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1628 - acc: 0.9472 - val_loss: 0.0934 - val_acc: 0.9720\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1153 - acc: 0.9596 - val_loss: 0.0777 - val_acc: 0.9760\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1024 - acc: 0.9697 - val_loss: 0.0851 - val_acc: 0.9750\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1252 - acc: 0.9620 - val_loss: 0.0724 - val_acc: 0.9790\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0993 - acc: 0.9654 - val_loss: 0.0567 - val_acc: 0.9820\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0704 - acc: 0.9741 - val_loss: 0.0483 - val_acc: 0.9870\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0641 - acc: 0.9774 - val_loss: 0.0455 - val_acc: 0.9860\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0399 - acc: 0.9872 - val_loss: 0.0489 - val_acc: 0.9840\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0757 - acc: 0.9744 - val_loss: 0.0476 - val_acc: 0.9890\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0628 - acc: 0.9805 - val_loss: 0.0532 - val_acc: 0.9850\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0421 - acc: 0.9878 - val_loss: 0.0396 - val_acc: 0.9900\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0354 - acc: 0.9884 - val_loss: 0.0464 - val_acc: 0.9900\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0395 - acc: 0.9866 - val_loss: 0.0390 - val_acc: 0.9900\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0348 - acc: 0.9868 - val_loss: 0.0412 - val_acc: 0.9860\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0377 - acc: 0.9861 - val_loss: 0.0374 - val_acc: 0.9890\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0355 - acc: 0.9896 - val_loss: 0.0458 - val_acc: 0.9860\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0376 - acc: 0.9882 - val_loss: 0.0384 - val_acc: 0.9880\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0359 - acc: 0.9883 - val_loss: 0.0427 - val_acc: 0.9890\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0353 - acc: 0.9885 - val_loss: 0.0329 - val_acc: 0.9900\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0275 - acc: 0.9907 - val_loss: 0.0366 - val_acc: 0.9910\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0264 - acc: 0.9908 - val_loss: 0.0309 - val_acc: 0.9920\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0271 - acc: 0.9912 - val_loss: 0.0370 - val_acc: 0.9900\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0346 - val_acc: 0.9900\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0298 - acc: 0.9911 - val_loss: 0.0459 - val_acc: 0.9860\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0324 - acc: 0.9909 - val_loss: 0.0320 - val_acc: 0.9930\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0142 - acc: 0.9959 - val_loss: 0.0357 - val_acc: 0.9890\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0254 - val_acc: 0.9920\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0175 - acc: 0.9926 - val_loss: 0.0301 - val_acc: 0.9930\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0171 - acc: 0.9933 - val_loss: 0.0335 - val_acc: 0.9920\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 0.0281 - val_acc: 0.9940\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0206 - acc: 0.9930 - val_loss: 0.0504 - val_acc: 0.9850\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0123 - acc: 0.9952 - val_loss: 0.0580 - val_acc: 0.9910\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0310 - acc: 0.9906 - val_loss: 0.0382 - val_acc: 0.9910\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0146 - acc: 0.9949 - val_loss: 0.0263 - val_acc: 0.9910\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0111 - acc: 0.9953 - val_loss: 0.0326 - val_acc: 0.9900\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0238 - val_acc: 0.9910\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0251 - val_acc: 0.9910\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0261 - val_acc: 0.9930\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0177 - acc: 0.9946 - val_loss: 0.0377 - val_acc: 0.9890\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0109 - acc: 0.9940 - val_loss: 0.0333 - val_acc: 0.9910\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0105 - acc: 0.9955 - val_loss: 0.0358 - val_acc: 0.9930\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.0381 - val_acc: 0.9910\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.0442 - val_acc: 0.9890\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0394 - val_acc: 0.9900\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0383 - val_acc: 0.9930\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0337 - val_acc: 0.9920\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0095 - acc: 0.9961 - val_loss: 0.0290 - val_acc: 0.9910\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0125 - acc: 0.9949 - val_loss: 0.0316 - val_acc: 0.9920\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0707 - val_acc: 0.9860\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0188 - acc: 0.9931 - val_loss: 0.0266 - val_acc: 0.9920\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0271 - val_acc: 0.9900\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0389 - val_acc: 0.9910\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0088 - acc: 0.9961 - val_loss: 0.0271 - val_acc: 0.9910\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0062 - acc: 0.9976 - val_loss: 0.0276 - val_acc: 0.9940\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0146 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9940\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0087 - acc: 0.9947 - val_loss: 0.0330 - val_acc: 0.9940\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9890\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0061 - acc: 0.9989 - val_loss: 0.0509 - val_acc: 0.9920\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0429 - val_acc: 0.9890\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0106 - acc: 0.9959 - val_loss: 0.0538 - val_acc: 0.9920\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 0.0349 - val_acc: 0.9920\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0324 - val_acc: 0.9930\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0371 - val_acc: 0.9900\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0243 - val_acc: 0.9940\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0580 - val_acc: 0.9860\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0161 - acc: 0.9957 - val_loss: 0.0338 - val_acc: 0.9870\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.0288 - val_acc: 0.9950\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9940\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0094 - acc: 0.9965 - val_loss: 0.0370 - val_acc: 0.9930\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0155 - acc: 0.9971 - val_loss: 0.0223 - val_acc: 0.9930\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.0359 - val_acc: 0.9920\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.0281 - val_acc: 0.9940\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0363 - val_acc: 0.9910\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0370 - val_acc: 0.9910\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0208 - val_acc: 0.9950\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 0.0386 - val_acc: 0.9920\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0171 - acc: 0.9954 - val_loss: 0.0402 - val_acc: 0.9920\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0187 - val_acc: 0.9950\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0160 - acc: 0.9952 - val_loss: 0.0275 - val_acc: 0.9930\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0256 - acc: 0.9944 - val_loss: 0.0156 - val_acc: 0.9950\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0514 - val_acc: 0.9880\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0103 - acc: 0.9954 - val_loss: 0.0405 - val_acc: 0.9920\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0186 - acc: 0.9966 - val_loss: 0.0411 - val_acc: 0.9890\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0244 - val_acc: 0.9940\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0347 - val_acc: 0.9910\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.0337 - val_acc: 0.9940\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0396 - val_acc: 0.9910\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0317 - val_acc: 0.9930\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.0365 - val_acc: 0.9940\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0331 - val_acc: 0.9920\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0251 - val_acc: 0.9930\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0281 - val_acc: 0.9930\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0259 - val_acc: 0.9930\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0297 - val_acc: 0.9920\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0279 - val_acc: 0.9940\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0060 - acc: 0.9976 - val_loss: 0.0321 - val_acc: 0.9940\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0203 - val_acc: 0.9930\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0413 - val_acc: 0.9900\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0212 - val_acc: 0.9940\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.0248 - val_acc: 0.9950\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0213 - val_acc: 0.9940\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0372 - val_acc: 0.9880\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0102 - acc: 0.9975 - val_loss: 0.0287 - val_acc: 0.9920\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0289 - val_acc: 0.9930\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0717 - val_acc: 0.9860\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0366 - val_acc: 0.9920\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0369 - val_acc: 0.9890\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0052 - acc: 0.9976 - val_loss: 0.0323 - val_acc: 0.9910\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0376 - val_acc: 0.9930\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0331 - val_acc: 0.9920\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0580 - val_acc: 0.9870\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0226 - val_acc: 0.9950\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0437 - val_acc: 0.9900\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0022 - acc: 0.9990 - val_loss: 0.0281 - val_acc: 0.9910\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0146 - acc: 0.9977 - val_loss: 0.0389 - val_acc: 0.9900\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0379 - val_acc: 0.9920\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0292 - val_acc: 0.9930\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0375 - val_acc: 0.9910\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0544 - val_acc: 0.9890\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0307 - acc: 0.9901 - val_loss: 0.0376 - val_acc: 0.9920\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0254 - val_acc: 0.9930\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0306 - val_acc: 0.9930\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 0.0310 - val_acc: 0.9930\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0232 - val_acc: 0.9940\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0402 - val_acc: 0.9890\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0110 - acc: 0.9976 - val_loss: 0.0349 - val_acc: 0.9930\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0077 - acc: 0.9965 - val_loss: 0.0312 - val_acc: 0.9940\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.0177 - val_acc: 0.9970\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0306 - val_acc: 0.9960\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0379 - val_acc: 0.9940\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0331 - val_acc: 0.9940\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0027 - acc: 0.9983 - val_loss: 0.0372 - val_acc: 0.9920\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0154 - acc: 0.9968 - val_loss: 0.0214 - val_acc: 0.9950\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0244 - val_acc: 0.9920\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0413 - val_acc: 0.9900\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0242 - val_acc: 0.9930\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0454 - val_acc: 0.9930\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0420 - val_acc: 0.9920\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0302 - val_acc: 0.9920\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0365 - val_acc: 0.9910\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - acc: 0.9979 - val_loss: 0.0416 - val_acc: 0.9880\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0360 - val_acc: 0.9920\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0341 - val_acc: 0.9920\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - acc: 0.9977 - val_loss: 0.0170 - val_acc: 0.9950\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0206 - val_acc: 0.9940\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0104 - acc: 0.9973 - val_loss: 0.0206 - val_acc: 0.9950\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0229 - val_acc: 0.9930\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - acc: 0.9976 - val_loss: 0.0224 - val_acc: 0.9940\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0296 - val_acc: 0.9940\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0355 - val_acc: 0.9910\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0199 - val_acc: 0.9940\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0029 - acc: 0.9982 - val_loss: 0.0265 - val_acc: 0.9910\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.0283 - val_acc: 0.9920\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.0180 - val_acc: 0.9940\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0355 - val_acc: 0.9910\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0324 - val_acc: 0.9910\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0041 - acc: 0.9979 - val_loss: 0.0194 - val_acc: 0.9930\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0670 - val_acc: 0.9880\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0591 - val_acc: 0.9910\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0073 - acc: 0.9985 - val_loss: 0.0339 - val_acc: 0.9930\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0295 - acc: 0.9961 - val_loss: 0.0223 - val_acc: 0.9940\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0293 - val_acc: 0.9940\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0145 - acc: 0.9950 - val_loss: 0.0411 - val_acc: 0.9910\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0505 - val_acc: 0.9910\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0352 - val_acc: 0.9900\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0332 - val_acc: 0.9900\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0044 - acc: 0.9979 - val_loss: 0.0320 - val_acc: 0.9920\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.0347 - val_acc: 0.9900\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0196 - val_acc: 0.9950\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0201 - val_acc: 0.9960\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0345 - val_acc: 0.9920\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 6.9100e-04 - acc: 0.9997 - val_loss: 0.0288 - val_acc: 0.9920\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0254 - val_acc: 0.9940\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0277 - val_acc: 0.9940\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0266 - val_acc: 0.9960\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.1001 - val_acc: 0.9900\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0380 - val_acc: 0.9940\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0197 - val_acc: 0.9940\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0302 - val_acc: 0.9940\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0188 - val_acc: 0.9940\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0035 - acc: 0.9981 - val_loss: 0.0180 - val_acc: 0.9950\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0202 - val_acc: 0.9970\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0183 - val_acc: 0.9960\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 7.7429e-04 - acc: 0.9998 - val_loss: 0.0203 - val_acc: 0.9960\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0035 - acc: 0.9984 - val_loss: 0.0283 - val_acc: 0.9950\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0277 - val_acc: 0.9940\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0212 - acc: 0.9958 - val_loss: 0.0274 - val_acc: 0.9950\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0158 - acc: 0.9938 - val_loss: 0.0242 - val_acc: 0.9930\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0307 - val_acc: 0.9950\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0343 - val_acc: 0.9940\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0047 - acc: 0.9977 - val_loss: 0.0261 - val_acc: 0.9960\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0390 - val_acc: 0.9950\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0132 - val_acc: 0.9970\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0241 - val_acc: 0.9930\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0379 - acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "-CGigIxgb_7H",
        "outputId": "9ec83ec8-bc98-43c4-d59e-acd1eef680b0"
      },
      "source": [
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU9bn28e/DooTFhRnc2AYNKhIclhGIuOCWuAXclYDRYFA58Xgwb2KIeJTXhOiJvknkiuacMS5BiLhFD0aiEVExotEBAQFBUbZxQRxlHZFlnvePqh56mu6enqFnerrm/lxXXd1d9auqp3/dc091VXW1uTsiIpL/WuS6ABERyQ4FuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCPaLM7O9mdkW22+aSma0ys9MbYLkvm9mPwvsjzewfmbStx3q6mdkWM2tZ31pF0lGgNyHhH3tsqDKzr+Iej6zLstz9LHf/c7bbNkVmNt7M5iQZX2hm283sW5kuy92nuft3slRXjX9A7r7G3du7+65sLD/J+szMPjSzpQ2xfGn6FOhNSPjH3t7d2wNrgO/FjZsWa2dmrXJXZZM0FTjezHokjL8MeMfdF+egplw4CTgIONzMjmvMFes92TQo0POAmQ01s3Iz+7mZfQo8aGYHmtnfzGy9mX0Z3u8SN0/8boQrzeyfZnZX2HalmZ1Vz7Y9zGyOmW02s1lmdo+ZTU1RdyY1/tLMXguX9w8zK4ybfrmZrTazCjObkKp/3L0cmA1cnjDpB8CU2upIqPlKM/tn3OMzzGyZmW00sz8AFjftCDObHdb3uZlNM7MDwmkPA92AZ8JPWDeaWZGZeSz8zOwwM5thZl+Y2QozGxO37Ilm9piZTQn7ZomZlaTqg9AVwP8CM8P78c+rt5m9EK5rnZndFI5vaWY3mdkH4XrmmVnXxFrDtonvk9fM7HdmVgFMTNcf4Txdzeyv4etQYWZ/MLN9wpr6xLU7yMwqzaxTLc9XEijQ88chQEegO3A1wWv3YPi4G/AV8Ic08w8ClgOFwG+A+83M6tH2L8CbQAEwkT1DNF4mNX4f+CHBluU+wE8BzOwY4I/h8g8L15c0hEN/jq/FzI4C+ob11rWvYssoBP4K3EzQFx8AQ+KbALeH9fUCuhL0Ce5+OTU/Zf0mySqmA+Xh/BcBvzazU+OmDwvbHADMSFezmbUNlzEtHC4zs33CaR2AWcBz4bq+CbwYzvoTYARwNrAfMBqoTNsxuw0CPgQOBial6w8Ljhv8DVgNFAGdgenuvj18jqPiljsCeNHd12dYh8S4u4YmOACrgNPD+0OB7UCbNO37Al/GPX4Z+FF4/0pgRdy0toADh9SlLUEY7gTaxk2fCkzN8Dklq/HmuMf/BjwX3r+F4A8+Nq1d2Aenp1h2W2ATcHz4eBLwv/Xsq3+G938AvBHXzggC+Ecplnse8Hay1zB8XBT2ZSuCsNsFdIibfjvwUHh/IjArbtoxwFdp+nYUsD5cdhtgI3B+OG1EfF0J8y0HhicZX11rmn5aU8vrXd0fwLdj9SVpN4jgn5+Fj8uAS3L595evg7bQ88d6d98We2Bmbc3sf8JdEpuAOcABlvoMik9jd9w9tgXWvo5tDwO+iBsHsDZVwRnW+Gnc/cq4mg6LX7a7bwUqUq0rrOlx4Afhp4mRwJQ61JFMYg0e/9jMDjaz6Wb2UbjcqQRb8pmI9eXmuHGrCbZcYxL7po2l3ld9BfCYu+8M3ydPsnu3S1eCTxfJpJtWmxqvfS390RVY7e47Exfi7v8ieH5Dzexogk8QM+pZU7OmQM8fiZfF/D/AUcAgd9+P4IAYxO3jbQCfAB3Dj/cxXdO035saP4lfdrjOglrm+TNwCXAG0AF4Zi/rSKzBqPl8f03wuvQJlzsqYZnpLmX6MUFfdogb1w34qJaa9hAeDzgVGGVmn1pwnOUi4Oxwt9Fa4PAUs68Fjkgyfmt4G/9aH5LQJvH5peuPtUC3NP+Q/hy2vxx4In7jRTKnQM9fHQj2BW8ws47ArQ29QndfTfBxeGJ4MOvbwPcaqMYngHPN7IRwX/Bt1P5+fRXYAJSye//s3tTxLNDbzC4Ig+h6aoZaB2ALsNHMOgM/S5h/HSmC1N3XAnOB282sjZkdC1xFsFVbV5cD7xH80+obDkcS7B4aQbDv+lAzG2dm+5pZBzMbFM77J+CXZtbTAseaWYEH+68/Ivgn0dLMRpM8+OOl6483Cf5B3mFm7cLnHH88YipwPkGoT6lHHwgK9Hz2e+AbwOfAGwQHvBrDSIL9oRXAr4BHga9TtK13je6+BPgxwUHNT4AvCQIq3TxOEAbdqRkK9arD3T8HLgbuIHi+PYHX4pr8X6A/wf7qZwkOoMa7HbjZzDaY2U+TrGIEwb7qj4GngFvdfVYmtSW4ArjX3T+NH4D/Bq4Id+ucQfDP91PgfeCUcN7fAo8B/yA4BnE/QV8BjCEI5QqgN8E/oHRS9ocH595/j2B3yhqC1/LSuOlrgfkEW/iv1r0LBHYfhBCpFzN7FFjm7g3+CUGizcweAD5295tzXUu+UqBLnVjwhZUvgJXAd4CngW+7+9s5LUzympkVAQuAfu6+MrfV5C/tcpG6OoTg9LUtwGRgrMJc9oaZ/RJYDNypMN872kIXEYkIbaGLiEREzi6oU1hY6EVFRblavYhIXpo3b97n7p70Ojc5C/SioiLKyspytXoRkbxkZqtTTdMuFxGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiYhaA93MHjCzz8ws6e8yhldom2zBT2gtMrP+2S9TomraNCgqghYtgttp02qbo2GXEyXTpkFhIZgFQ2Fh4/dLLl+XxOffsmVw26JF3fok9hzqM2+yOhr0dajtFzAIrh3dH1icYvrZwN8Jrns8GPhXJr+sMWDAAJfaTZ3q3r27u1lwO3VqZm0LCoIh3Xyx9hC0g2Bo0SK4jS0jcXpBQTBvuvWNHZu+lqlTdy87fmjdOn3dif0xdmzy5cQPsecT/xyyNST2RX3Wk9jfiX1WUODerl3NdWbyvNMN7dolf20bq9/qu574vorvk1wP9XkfxOapK6DMPUVep5pQo1Fwic9Ugf4/wIi4x8uBQ2tbZnMJ9MTgqu1FTBV02f7jaUp/DBo0NNehbdu6h3q6QM/GPvTO1PwpqnJq/oxWNTO72szKzKxs/fr8/f3XTD9GTpsGP/whVMT9cFpFBYwatefHt9jHwVGjarbPtqqq4Hbr1vTtRKThVVbChAnZW16jHhR191J3L3H3kk6dkn5ztUmL7QsbNQpWrw7+x65enTqgR42CHTtSL8999/1Y0IpI87JmTfaWlY1A/4iav7PYhXr8LmIupTtoEX9ApLatZwW0iNRVt27ZW1Y2An0G4S+tm9lgYKO7f5KF5Ta4adOgoGDPoI7fLRLbGhcRyba2bWHSpOwtL5PTFh8BXgeOMrNyM7vKzK41s2vDJjOBD4EVwH3Av2WvvIYxfToMGwZjxsAXX+S6Gsmm1q33HNeiGX/boqAApk6FKVOgXbu6zWuWvToOPDDYDdnYCgrggQfgwQdh8mSYM2f3IcmpU6Fjx9qXEXv/dO8ezBObt6CgbnVMnRoMXboEfdu9O5SWwsiR9XtuSaU6WtrQQ2Od5bJsmfvAge5XXeU+frz7oYfm/sh2fYdMTx/bf//Up7wlGzp2TH16ILjvt5/7Qw+5T57s/p3vBO1j87Zr537ggbuXEzuLJn7Z6U6/SzzVq2XL3dPS1d26dc0+qe2UzvpYuNB98+aa4zZtcu/Sxf2449z/9KeafdGypfvtt7tfcIH7U0+5V1Xtnu/GG4M2o0YFj8vK3Fevdt+2zf2WW4Jlxp+umO71ij9t86qrgvnj15XOxo3ukybVXMYdd7h/+mnqed59171Hj+BvZ82azPuvrrZvD/q1bVv3225LXlPiaat33+3+9NPBEGu/dKn7Z59lvt4vv3T/4IP6113XM9n2Fnt72mJDDI0R6Nu3u5eUuLdv7/6Nb+RPIEPwpo4/lzsbgbVpk/shhwQBna1lJrrnniDUhwxxnzs3u8uOqahw37WrYZadiQ0bgvdWzOzZQbDPmZN6nm3bgpDKNBBj/+CShXkubN0aBF9D27LF/YsvGn49+axZBnpVlfvPfx48w+uv33PLMRtD+/ZeY6syXWCnCui1a93vu8/94YezG96p7NjRMMuNqapy//rrhl1HU5Ttfp06NXjPJL6HGnLLT/JDswv0HTvcr702eHa9emX/m26ZBG5dvuEpkozeQ5JMukDP2Y9El5SUeEP8YpE7XHcd3HsvnHsu/O1vdZt/6lT4j//YfdZLixbBKYjduwdHo7N6AENEpI7MbJ67lySblrOfoMu2v/wFrrkGtm8Phv32g9dfr9syuncPAluhLSL5KBKB/sor8IMfBFvSsQ8cmzbVbRnZPh9URKSx5fUZul9/DT//OZxxRnBeZ133HsXOi22Q80FFRBpZXgf6fffBb34D3/8+7NyZ2TxmMHZsEP47dwa3q1YpzEUk/+V1oL/8crB1fcYZmX8L7eGHgwOmIiJRk7eB7g6vvQadO8PVV8OuXbXPEzvoKSISRXl7UHTlSvj00+CMlsrK2tvroKeIRF3ebqHPnRvcZnJxrYICHfQUkejL20B/7bXgXPN01xKOXR3t888V5iISfXkd6IMHw69/HexOide2bRDkOntFRJqTvA30lSuhV68gsEtLg63xBrvGsIhIHsjLQHcPDoS2bx/86tCECcHv8nXrpuutiEjzlZdnuWzfHnzN//334Xe/232Wy+rVwSmMoFAXkeYnL7fQt24Nbl94Yc9TFisrgy12EZHmJi8DPRbiX36ZfPqaNY1Xi4hIU5GXgR7bQi8sTD493amMIiJRlZeBHttCHzUq+SmL+kaoiDRHeR3oZ5+tUxZFRGLy8iyX2C6Xtm31C0MiIjF5vYWeuLtFRKQ5y8tAj22ht2uX2zpERJqSvAz02Bb6qadCixZQVBR8Y1REpDnLy33oc+YEtx99FNzqG6IiInm6hf63v+05Tt8QFZHmLi8DfcOG5OP1DVERac7yMtA7dEg+Xt8QFZHmLC8DvaRkz3H6hqiINHd5GeiHHQYHHaRviIqIxMvLs1wqK4NAf+edXFciItJ05OUWemWlvlQkIpIoLwN961Z97V9EJFFGgW5mZ5rZcjNbYWbjk0zvbmYvmtkiM3vZzLpkv9TdKisV6CIiiWoNdDNrCdwDnAUcA4wws2MSmt0FTHH3Y4HbgNuzXWi8rVu1y0VEJFEmW+gDgRXu/qG7bwemA8MT2hwDzA7vv5RkelZpC11EZE+ZBHpnYG3c4/JwXLyFwAXh/fOBDmZWkLggM7vazMrMrGz9+vX1qRfQFrqISDLZOij6U+BkM3sbOBn4CNiV2MjdS929xN1LOnXqVO+VaQtdRGRPmZyH/hHQNe5xl3BcNXf/mHAL3czaAxe6e4orruydqirYtk2BLiKSKJMt9LeAnmbWw8z2AS4DZsQ3MLNCM4st6xfAA9ktc7fYtdC1y0VEpKZaA93ddwLXAc8D7wKPufsSM7vNzIaFzYYCy83sPeBgoMGuqqKfnxMRSS6jr/67+0xgZsK4W+LuPwE8kd3SktPPz4mIJJd33xTVFrqISHIKdBGRiMi7QNcuFxGR5PIu0LWFLiKSXN4FurbQRUSSy7tA1xa6iEhyeRfosS10BbqISE15F+ixLfSBA6FFCygqgmnTclqSiEiTkHe/Kbp1K7RuDWvD6z+uXg1XXx3c149Ei0hzlndb6A8+CDt21BxXWQkTJuSmHhGRpiLvAn3NmrqNFxFpLvIu0Lt1q9t4EZHmIu8CfdKkPc9wads2GC8i0pzlXaCPHAmlpdC9O5gFt6WlOiAqIpJ3Z7lAEN4KcBGRmvJuC11ERJJToIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiYiMAt3MzjSz5Wa2wszGJ5nezcxeMrO3zWyRmZ2d/VJFRCSdWgPdzFoC9wBnAccAI8zsmIRmNwOPuXs/4DLg3mwXKiIi6WWyhT4QWOHuH7r7dmA6MDyhjQP7hff3Bz7OXokiIpKJTAK9M7A27nF5OC7eRGCUmZUDM4F/T7YgM7vazMrMrGz9+vX1KFdERFLJ1kHREcBD7t4FOBt42Mz2WLa7l7p7ibuXdOrUKUurFhERyCzQPwK6xj3uEo6LdxXwGIC7vw60AQqzUaCIiGQmk0B/C+hpZj3MbB+Cg54zEtqsAU4DMLNeBIGufSoiIo2o1kB3953AdcDzwLsEZ7MsMbPbzGxY2Oz/AGPMbCHwCHClu3tDFS0iIntqlUkjd59JcLAzftwtcfeXAkOyW5qIiNSFvikqIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiERERoFuZmea2XIzW2Fm45NM/52ZLQiH98xsQ/ZLFRGRdFrV1sDMWgL3AGcA5cBbZjbD3ZfG2rj7DXHt/x3o1wC1iohIGplsoQ8EVrj7h+6+HZgODE/TfgTwSDaKExGRzGUS6J2BtXGPy8NxezCz7kAPYHaK6VebWZmZla1fv76utYqISBrZPih6GfCEu+9KNtHdS929xN1LOnXqlOVVi4g0b5kE+kdA17jHXcJxyVyGdreIiOREJoH+FtDTzHqY2T4EoT0jsZGZHQ0cCLye3RJFRCQTtQa6u+8ErgOeB94FHnP3JWZ2m5kNi2t6GTDd3b1hShURkXRqPW0RwN1nAjMTxt2S8Hhi9soSEZG60jdFRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYmIVrkuQKS527FjB+Xl5Wzbti3XpUgT0qZNG7p06ULr1q0znkeBLpJj5eXldOjQgaKiIsws1+VIE+DuVFRUUF5eTo8ePTKeT7tcRHJs27ZtFBQUKMylmplRUFBQ509tCnSRJkBhLonq857IKNDN7EwzW25mK8xsfIo2l5jZUjNbYmZ/qXMlIiKyV2oNdDNrCdwDnAUcA4wws2MS2vQEfgEMcffewLgGqFVEgGnToKgIWrQIbqdN27vlVVRU0LdvX/r27cshhxxC586dqx9v37497bxlZWVcf/31ta7j+OOP37siE4wbN47OnTtTVVWV1eXmu0wOig4EVrj7hwBmNh0YDiyNazMGuMfdvwRw98+yXaiIBOF99dVQWRk8Xr06eAwwcmT9lllQUMCCBQsAmDhxIu3bt+enP/1p9fSdO3fSqlXyqCgpKaGkpKTWdcydO7d+xSVRVVXFU089RdeuXXnllVc45ZRTsrbseOmed1OVyS6XzsDauMfl4bh4RwJHmtlrZvaGmZ2ZbEFmdrWZlZlZ2fr16+tXsUgzNmHC7jCPqawMxmfTlVdeybXXXsugQYO48cYbefPNN/n2t79Nv379OP7441m+fDkAL7/8Mueeey4Q/DMYPXo0Q4cO5fDDD2fy5MnVy2vfvn11+6FDh3LRRRdx9NFHM3LkSNwdgJkzZ3L00UczYMAArr/++urlJnr55Zfp3bs3Y8eO5ZFHHqkev27dOs4//3yKi4spLi6u/icyZcoUjj32WIqLi7n88surn98TTzyRtL4TTzyRYcOGccwxwY6I8847jwEDBtC7d29KS0ur53nuuefo378/xcXFnHbaaVRVVdGzZ09i2VZVVcU3v/lNGjPrsvXvpxXQExgKdAHmmFkfd98Q38jdS4FSgJKSEs/SukWajTVr6jZ+b5SXlzN37lxatmzJpk2bePXVV2nVqhWzZs3ipptu4sknn9xjnmXLlvHSSy+xefNmjjrqKMaOHbvHedRvv/02S5Ys4bDDDmPIkCG89tprlJSUcM011zBnzhx69OjBiBEjUtb1yCOPMGLECIYPH85NN93Ejh07aN26Nddffz0nn3wyTz31FLt27WLLli0sWbKEX/3qV8ydO5fCwkK++OKLWp/3/PnzWbx4cfXpgg888AAdO3bkq6++4rjjjuPCCy+kqqqKMWPGVNf7xRdf0KJFC0aNGsW0adMYN24cs2bNori4mE6dOtWx5+svky30j4CucY+7hOPilQMz3H2Hu68E3iMIeBHJom7d6jZ+b1x88cW0bNkSgI0bN3LxxRfzrW99ixtuuIElS5Ykneecc85h3333pbCwkIMOOoh169bt0WbgwIF06dKFFi1a0LdvX1atWsWyZcs4/PDDq0M0VaBv376dmTNnct5557HffvsxaNAgnn/+eQBmz57N2LFjAWjZsiX7778/s2fP5uKLL6awsBCAjh071vq8Bw4cWOPc78mTJ1NcXMzgwYNZu3Yt77//Pm+88QYnnXRSdbvYckePHs2UKVOA4B/BD3/4w1rXl02ZBPpbQE8z62Fm+wCXATMS2jxNsHWOmRUS7IL5MIt1iggwaRK0bVtzXNu2wfhsa9euXfX9//zP/+SUU05h8eLFPPPMMynPj953332r77ds2ZKdO3fWq00qzz//PBs2bKBPnz4UFRXxz3/+s8Zul0y1atWq+oBqVVVVjYO/8c/75ZdfZtasWbz++ussXLiQfv36pT03vGvXrhx88MHMnj2bN998k7POOqvOte2NWgPd3XcC1wHPA+8Cj7n7EjO7zcyGhc2eByrMbCnwEvAzd69oqKJFmquRI6G0FLp3B7PgtrS0/gdEM7Vx40Y6dw4OnT300ENZX/5RRx3Fhx9+yKpVqwB49NFHk7Z75JFH+NOf/sSqVatYtWoVK1eu5IUXXqCyspLTTjuNP/7xjwDs2rWLjRs3cuqpp/L4449TURHEUWyXS1FREfPmzQNgxowZ7NixI+n6Nm7cyIEHHkjbtm1ZtmwZb7zxBgCDBw9mzpw5rFy5ssZyAX70ox8xatSoGp9wGktG56G7+0x3P9Ldj3D3SeG4W9x9Rnjf3f0n7n6Mu/dx9+kNWbRIczZyJKxaBVVVwW1DhznAjTfeyC9+8Qv69etXpy3qTH3jG9/g3nvv5cwzz2TAgAF06NCB/fffv0abyspKnnvuOc4555zqce3ateOEE07gmWee4e677+all16iT58+DBgwgKVLl9K7d28mTJjAySefTHFxMT/5yU8AGDNmDK+88grFxcW8/vrrNbbK45155pns3LmTXr16MX78eAYPHgxAp06dKC0t5YILLqC4uJhLL720ep5hw4axZcuWRt/dAmCxI8yNraSkxMvKynKybpGm5N1336VXr165LiPntmzZQvv27XF3fvzjH9OzZ09uuOGGXJdVZ2VlZdxwww28+uqre72sZO8NM5vn7knPFdVX/0WkSbjvvvvo27cvvXv3ZuPGjVxzzTW5LqnO7rjjDi688EJuv/32nKxfW+giOaYtdElFW+giIs2UAl1EJCIU6CIiEaFAFxGJCAW6SDN3yimnVH99Pub3v/999dfokxk6dCixkxrOPvtsNmzYsEebiRMnctddd6Vd99NPP83Spbsv3HrLLbcwa9asupSfVnO7zK4CXaSZGzFiBNOn1/wu4PTp09NeICvezJkzOeCAA+q17sRAv+222zj99NPrtaxEiZfZbSgN8UWr+lKgizQh48bB0KHZHcbV8nMzF110Ec8++2z19UxWrVrFxx9/zIknnsjYsWMpKSmhd+/e3HrrrUnnLyoq4vPPPwdg0qRJHHnkkZxwwgnVl9iF4Bzz4447juLiYi688EIqKyuZO3cuM2bM4Gc/+xl9+/blgw8+qHFZ2xdffJF+/frRp08fRo8ezddff129vltvvZX+/fvTp08fli1blrSu5niZXQW6SDPXsWNHBg4cyN///ncg2Dq/5JJLMDMmTZpEWVkZixYt4pVXXmHRokUplzNv3jymT5/OggULmDlzJm+99Vb1tAsuuIC33nqLhQsX0qtXL+6//36OP/54hg0bxp133smCBQs44ogjqttv27aNK6+8kkcffZR33nmHnTt3Vl+nBaCwsJD58+czduzYlLt1YpfZPf/883n22Werr9cSu8zuwoULmT9/Pr17966+zO7s2bNZuHAhd999d639Nn/+fO6++27ee+89ILi64rx58ygrK2Py5MlUVFSwfv16xowZw5NPPsnChQt5/PHHa1xmF8jqZXbz6+c4RCLu97/PzXpju12GDx/O9OnTuf/++wF47LHHKC0tZefOnXzyyScsXbqUY489NukyXn31Vc4//3zahpeDHDZsWPW0xYsXc/PNN7Nhwwa2bNnCd7/73bT1LF++nB49enDkkUcCcMUVV3DPPfcwLvy4ccEFFwAwYMAA/vrXv+4xf+wyu7/97W/p0KFD9WV2zz33XGbPnl19idvYZXanTJmSlcvsPvXUUwDVl9ldv359ysvsDh8+nHHjxmX1Mrt5tYWe7d9SFJHA8OHDefHFF5k/fz6VlZUMGDCAlStXctddd/Hiiy+yaNEizjnnnLSXjk3nyiuv5A9/+APvvPMOt956a72XExO7BG+qy+8218vs5k2gx35LcfVqcN/9W4oKdZG91759e0455RRGjx5dfTB006ZNtGvXjv33359169ZV75JJ5aSTTuLpp5/mq6++YvPmzTzzzDPV0zZv3syhhx7Kjh07qnc1AHTo0IHNmzfvsayjjjqKVatWsWLFCgAefvhhTj755IyfT3O9zG7eBHpj/ZaiSHM1YvxkbeYAAAXpSURBVMQIFi5cWB3oxcXF9OvXj6OPPprvf//7DBkyJO38/fv359JLL6W4uJizzjqL4447rnraL3/5SwYNGsSQIUM4+uijq8dfdtll3HnnnfTr148PPvigenybNm148MEHufjii+nTpw8tWrTg2muvzeh5NOfL7ObNxblatAi2zBOZBdeFFslXujhX85TJZXYje3GuxvwtRRGRhtRQl9nNm0BvzN9SFBFpSOPHj2f16tWccMIJWV1u3gR6rn5LUaQx5GrXpzRd9XlP5NV56CNHKsAletq0aUNFRQUFBQWYWa7LkSbA3amoqKBNmzZ1mi+vAl0kirp06UJ5eXlWvvot0dGmTRu6dOlSp3kU6CI51rp16xrfOBSpr7zZhy4iIukp0EVEIkKBLiISETn7pqiZrQdW13P2QuDzLJaTTU21NtVVN6qr7ppqbVGrq7u7J73Wbs4CfW+YWVmqr77mWlOtTXXVjeqqu6ZaW3OqS7tcREQiQoEuIhIR+RropbU3yZmmWpvqqhvVVXdNtbZmU1de7kMXEZE95esWuoiIJFCgi4hERN4FupmdaWbLzWyFmY3PYR1dzewlM1tqZkvM7D/C8RPN7CMzWxAOZ+egtlVm9k64/rJwXEcze8HM3g9vD2zkmo6K65MFZrbJzMblqr/M7AEz+8zMFseNS9pHFpgcvucWmVn/Rq7rTjNbFq77KTM7IBxfZGZfxfXdfzdyXSlfOzP7Rdhfy83suw1VV5raHo2ra5WZLQjHN0qfpcmHhn2PuXveDEBL4APgcGAfYCFwTI5qORToH97vALwHHANMBH6a435aBRQmjPsNMD68Px74rxy/jp8C3XPVX8BJQH9gcW19BJwN/B0wYDDwr0au6ztAq/D+f8XVVRTfLgf9lfS1C/8OFgL7Aj3Cv9mWjVlbwvT/B9zSmH2WJh8a9D2Wb1voA4EV7v6hu28HpgPDc1GIu3/i7vPD+5uBd4HOuaglQ8OBP4f3/wycl8NaTgM+cPf6flN4r7n7HOCLhNGp+mg4MMUDbwAHmNmhjVWXu//D3XeGD98A6nZN1QaqK43hwHR3/9rdVwIrCP52G702Cy4wfwnwSEOtP0VNqfKhQd9j+RbonYG1cY/LaQIhamZFQD/gX+Go68KPTQ809q6NkAP/MLN5ZnZ1OO5gd/8kvP8pcHAO6oq5jJp/YLnur5hUfdSU3nejCbbkYnqY2dtm9oqZnZiDepK9dk2pv04E1rn7+3HjGrXPEvKhQd9j+RboTY6ZtQeeBMa5+ybgj8ARQF/gE4KPe43tBHfvD5wF/NjMToqf6MFnvJycr2pm+wDDgMfDUU2hv/aQyz5KxcwmADuBaeGoT4Bu7t4P+AnwFzPbrxFLapKvXYIR1Nx4aNQ+S5IP1RriPZZvgf4R0DXucZdwXE6YWWuCF2uau/8VwN3Xufsud68C7qMBP2qm4u4fhbefAU+FNayLfYQLbz9r7LpCZwHz3X1dWGPO+ytOqj7K+fvOzK4EzgVGhkFAuEujIrw/j2Bf9ZGNVVOa1y7n/QVgZq2AC4BHY+Mas8+S5QMN/B7Lt0B/C+hpZj3CLb3LgBm5KCTcN3c/8K67/zZufPx+r/OBxYnzNnBd7cysQ+w+wQG1xQT9dEXY7Argfxuzrjg1tphy3V8JUvXRDOAH4ZkIg4GNcR+bG5yZnQncCAxz98q48Z3MrGV4/3CgJ/BhI9aV6rWbAVxmZvuaWY+wrjcbq644pwPL3L08NqKx+ixVPtDQ77GGPtqb7YHgaPB7BP9ZJ+SwjhMIPi4tAhaEw9nAw8A74fgZwKGNXNfhBGcYLASWxPoIKABeBN4HZgEdc9Bn7YAKYP+4cTnpL4J/Kp8AOwj2V16Vqo8Izjy4J3zPvQOUNHJdKwj2r8beZ/8dtr0wfI0XAPOB7zVyXSlfO2BC2F/LgbMa+7UMxz8EXJvQtlH6LE0+NOh7TF/9FxGJiHzb5SIiIiko0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEfH/Aef/Fdv+KdHQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Ba3UTecfX2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d2dFLcDKcRtc",
        "outputId": "1dc2cef2-48d2-42d3-f565-73017a3b94a3"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(64, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=200, \r\n",
        "          batch_size=64)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.2f} Test Accuracy : {acc:.2f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_34 (Conv2D)           (None, 28, 28, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 14, 14, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 7, 7, 128)         131200    \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,740,522\n",
            "Trainable params: 1,740,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1.6710 - acc: 0.3843 - val_loss: 0.2603 - val_acc: 0.9130\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.3489 - acc: 0.8785 - val_loss: 0.1272 - val_acc: 0.9530\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.2000 - acc: 0.9290 - val_loss: 0.0869 - val_acc: 0.9740\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1352 - acc: 0.9544 - val_loss: 0.0806 - val_acc: 0.9740\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1307 - acc: 0.9605 - val_loss: 0.0808 - val_acc: 0.9750\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0770 - acc: 0.9749 - val_loss: 0.0730 - val_acc: 0.9800\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0695 - val_acc: 0.9810\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0738 - acc: 0.9769 - val_loss: 0.0586 - val_acc: 0.9800\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0507 - acc: 0.9816 - val_loss: 0.0548 - val_acc: 0.9830\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0524 - acc: 0.9835 - val_loss: 0.0616 - val_acc: 0.9820\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0497 - acc: 0.9847 - val_loss: 0.0696 - val_acc: 0.9840\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0518 - acc: 0.9841 - val_loss: 0.0422 - val_acc: 0.9860\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0386 - acc: 0.9877 - val_loss: 0.0594 - val_acc: 0.9840\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0408 - acc: 0.9840 - val_loss: 0.0447 - val_acc: 0.9830\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0424 - val_acc: 0.9870\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.0447 - val_acc: 0.9870\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0451 - acc: 0.9864 - val_loss: 0.0461 - val_acc: 0.9880\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0264 - acc: 0.9874 - val_loss: 0.0482 - val_acc: 0.9880\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0300 - acc: 0.9924 - val_loss: 0.0564 - val_acc: 0.9830\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0314 - acc: 0.9885 - val_loss: 0.0363 - val_acc: 0.9870\n",
            "Epoch 21/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0386 - val_acc: 0.9890\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0300 - acc: 0.9899 - val_loss: 0.0375 - val_acc: 0.9900\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0288 - acc: 0.9928 - val_loss: 0.0238 - val_acc: 0.9920\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0257 - acc: 0.9927 - val_loss: 0.0399 - val_acc: 0.9910\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0174 - acc: 0.9966 - val_loss: 0.0412 - val_acc: 0.9890\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9913 - val_loss: 0.0346 - val_acc: 0.9900\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0203 - acc: 0.9928 - val_loss: 0.0272 - val_acc: 0.9900\n",
            "Epoch 28/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0212 - acc: 0.9947 - val_loss: 0.0348 - val_acc: 0.9890\n",
            "Epoch 29/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9914 - val_loss: 0.0317 - val_acc: 0.9870\n",
            "Epoch 30/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0300 - val_acc: 0.9900\n",
            "Epoch 31/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0532 - val_acc: 0.9860\n",
            "Epoch 32/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0224 - acc: 0.9943 - val_loss: 0.0321 - val_acc: 0.9900\n",
            "Epoch 33/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0537 - val_acc: 0.9860\n",
            "Epoch 34/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0122 - acc: 0.9969 - val_loss: 0.0380 - val_acc: 0.9850\n",
            "Epoch 35/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0143 - acc: 0.9972 - val_loss: 0.0255 - val_acc: 0.9930\n",
            "Epoch 36/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0203 - acc: 0.9934 - val_loss: 0.0359 - val_acc: 0.9900\n",
            "Epoch 37/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0211 - acc: 0.9944 - val_loss: 0.0453 - val_acc: 0.9840\n",
            "Epoch 38/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0219 - acc: 0.9914 - val_loss: 0.0426 - val_acc: 0.9860\n",
            "Epoch 39/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.0280 - val_acc: 0.9910\n",
            "Epoch 40/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9965 - val_loss: 0.0501 - val_acc: 0.9900\n",
            "Epoch 41/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0647 - val_acc: 0.9820\n",
            "Epoch 42/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0263 - acc: 0.9911 - val_loss: 0.0380 - val_acc: 0.9890\n",
            "Epoch 43/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0273 - acc: 0.9912 - val_loss: 0.0448 - val_acc: 0.9890\n",
            "Epoch 44/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.0570 - val_acc: 0.9890\n",
            "Epoch 45/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0204 - val_acc: 0.9930\n",
            "Epoch 46/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0291 - val_acc: 0.9900\n",
            "Epoch 47/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0161 - acc: 0.9932 - val_loss: 0.0270 - val_acc: 0.9920\n",
            "Epoch 48/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9900\n",
            "Epoch 49/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0107 - acc: 0.9954 - val_loss: 0.0451 - val_acc: 0.9920\n",
            "Epoch 50/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0131 - acc: 0.9970 - val_loss: 0.0273 - val_acc: 0.9900\n",
            "Epoch 51/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0333 - val_acc: 0.9900\n",
            "Epoch 52/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9930\n",
            "Epoch 53/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0169 - acc: 0.9954 - val_loss: 0.0304 - val_acc: 0.9900\n",
            "Epoch 54/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0187 - acc: 0.9956 - val_loss: 0.0255 - val_acc: 0.9910\n",
            "Epoch 55/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0312 - val_acc: 0.9900\n",
            "Epoch 56/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0101 - acc: 0.9946 - val_loss: 0.0504 - val_acc: 0.9870\n",
            "Epoch 57/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0155 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 58/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0131 - acc: 0.9965 - val_loss: 0.0205 - val_acc: 0.9890\n",
            "Epoch 59/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0161 - acc: 0.9923 - val_loss: 0.0185 - val_acc: 0.9920\n",
            "Epoch 60/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9956 - val_loss: 0.0635 - val_acc: 0.9900\n",
            "Epoch 61/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0461 - val_acc: 0.9870\n",
            "Epoch 62/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0453 - val_acc: 0.9890\n",
            "Epoch 63/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0118 - acc: 0.9956 - val_loss: 0.0408 - val_acc: 0.9900\n",
            "Epoch 64/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0416 - val_acc: 0.9890\n",
            "Epoch 65/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0199 - acc: 0.9953 - val_loss: 0.0163 - val_acc: 0.9940\n",
            "Epoch 66/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 0.0132 - val_acc: 0.9960\n",
            "Epoch 67/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9920\n",
            "Epoch 68/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0119 - acc: 0.9977 - val_loss: 0.0414 - val_acc: 0.9920\n",
            "Epoch 69/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0476 - val_acc: 0.9910\n",
            "Epoch 70/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0240 - val_acc: 0.9920\n",
            "Epoch 71/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0250 - val_acc: 0.9950\n",
            "Epoch 72/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9999 - val_loss: 0.0206 - val_acc: 0.9940\n",
            "Epoch 73/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0139 - acc: 0.9977 - val_loss: 0.0475 - val_acc: 0.9880\n",
            "Epoch 74/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9860\n",
            "Epoch 75/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0140 - acc: 0.9937 - val_loss: 0.0495 - val_acc: 0.9920\n",
            "Epoch 76/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0304 - val_acc: 0.9910\n",
            "Epoch 77/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0035 - acc: 0.9984 - val_loss: 0.0199 - val_acc: 0.9940\n",
            "Epoch 78/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0560 - val_acc: 0.9910\n",
            "Epoch 79/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0232 - val_acc: 0.9950\n",
            "Epoch 80/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 0.0310 - val_acc: 0.9930\n",
            "Epoch 81/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0391 - val_acc: 0.9870\n",
            "Epoch 82/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0195 - acc: 0.9962 - val_loss: 0.0896 - val_acc: 0.9850\n",
            "Epoch 83/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.0374 - val_acc: 0.9900\n",
            "Epoch 84/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0323 - val_acc: 0.9920\n",
            "Epoch 85/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0674 - val_acc: 0.9860\n",
            "Epoch 86/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0197 - val_acc: 0.9940\n",
            "Epoch 87/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0192 - val_acc: 0.9930\n",
            "Epoch 88/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0163 - acc: 0.9968 - val_loss: 0.0383 - val_acc: 0.9910\n",
            "Epoch 89/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0278 - val_acc: 0.9940\n",
            "Epoch 90/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0129 - acc: 0.9965 - val_loss: 0.0326 - val_acc: 0.9910\n",
            "Epoch 91/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0345 - val_acc: 0.9940\n",
            "Epoch 92/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0274 - val_acc: 0.9940\n",
            "Epoch 93/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0172 - acc: 0.9971 - val_loss: 0.0306 - val_acc: 0.9910\n",
            "Epoch 94/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0528 - val_acc: 0.9910\n",
            "Epoch 95/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.0384 - val_acc: 0.9890\n",
            "Epoch 96/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0431 - val_acc: 0.9890\n",
            "Epoch 97/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0690 - val_acc: 0.9890\n",
            "Epoch 98/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0071 - acc: 0.9971 - val_loss: 0.0439 - val_acc: 0.9900\n",
            "Epoch 99/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0389 - val_acc: 0.9910\n",
            "Epoch 100/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0255 - acc: 0.9954 - val_loss: 0.0516 - val_acc: 0.9890\n",
            "Epoch 101/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0160 - acc: 0.9958 - val_loss: 0.0359 - val_acc: 0.9920\n",
            "Epoch 102/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0486 - val_acc: 0.9900\n",
            "Epoch 103/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0286 - val_acc: 0.9900\n",
            "Epoch 104/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0340 - acc: 0.9950 - val_loss: 0.0385 - val_acc: 0.9930\n",
            "Epoch 105/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.0526 - val_acc: 0.9890\n",
            "Epoch 106/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0114 - acc: 0.9954 - val_loss: 0.0559 - val_acc: 0.9900\n",
            "Epoch 107/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0503 - val_acc: 0.9890\n",
            "Epoch 108/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0450 - val_acc: 0.9910\n",
            "Epoch 109/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9989 - val_loss: 0.0212 - val_acc: 0.9950\n",
            "Epoch 110/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 0.0309 - val_acc: 0.9910\n",
            "Epoch 111/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.0505 - val_acc: 0.9910\n",
            "Epoch 112/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.0132 - val_acc: 0.9960\n",
            "Epoch 113/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0240 - acc: 0.9965 - val_loss: 0.0241 - val_acc: 0.9940\n",
            "Epoch 114/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0427 - val_acc: 0.9910\n",
            "Epoch 115/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0270 - val_acc: 0.9940\n",
            "Epoch 116/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0392 - val_acc: 0.9930\n",
            "Epoch 117/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0418 - val_acc: 0.9930\n",
            "Epoch 118/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 0.0464 - val_acc: 0.9890\n",
            "Epoch 119/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0054 - acc: 0.9976 - val_loss: 0.0162 - val_acc: 0.9960\n",
            "Epoch 120/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0407 - val_acc: 0.9940\n",
            "Epoch 121/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0222 - val_acc: 0.9940\n",
            "Epoch 122/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0316 - val_acc: 0.9960\n",
            "Epoch 123/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.0273 - val_acc: 0.9950\n",
            "Epoch 124/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0255 - val_acc: 0.9940\n",
            "Epoch 125/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0324 - val_acc: 0.9930\n",
            "Epoch 126/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0116 - acc: 0.9969 - val_loss: 0.0530 - val_acc: 0.9890\n",
            "Epoch 127/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0209 - val_acc: 0.9940\n",
            "Epoch 128/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0113 - acc: 0.9979 - val_loss: 0.0244 - val_acc: 0.9950\n",
            "Epoch 129/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0226 - val_acc: 0.9960\n",
            "Epoch 130/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0013 - acc: 0.9993 - val_loss: 0.0381 - val_acc: 0.9930\n",
            "Epoch 131/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0571 - val_acc: 0.9920\n",
            "Epoch 132/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0975 - val_acc: 0.9900\n",
            "Epoch 133/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0248 - acc: 0.9959 - val_loss: 0.0300 - val_acc: 0.9940\n",
            "Epoch 134/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0816 - val_acc: 0.9900\n",
            "Epoch 135/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0589 - val_acc: 0.9940\n",
            "Epoch 136/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0185 - acc: 0.9972 - val_loss: 0.0457 - val_acc: 0.9920\n",
            "Epoch 137/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0172 - acc: 0.9973 - val_loss: 0.0348 - val_acc: 0.9950\n",
            "Epoch 138/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0073 - acc: 0.9986 - val_loss: 0.0316 - val_acc: 0.9950\n",
            "Epoch 139/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0161 - acc: 0.9978 - val_loss: 0.0367 - val_acc: 0.9940\n",
            "Epoch 140/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0080 - acc: 0.9967 - val_loss: 0.0376 - val_acc: 0.9900\n",
            "Epoch 141/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0416 - acc: 0.9950 - val_loss: 0.0344 - val_acc: 0.9920\n",
            "Epoch 142/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0079 - acc: 0.9985 - val_loss: 0.0331 - val_acc: 0.9950\n",
            "Epoch 143/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0502 - val_acc: 0.9910\n",
            "Epoch 144/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0496 - val_acc: 0.9920\n",
            "Epoch 145/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0327 - val_acc: 0.9940\n",
            "Epoch 146/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0353 - val_acc: 0.9940\n",
            "Epoch 147/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0285 - val_acc: 0.9940\n",
            "Epoch 148/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0201 - acc: 0.9988 - val_loss: 0.0336 - val_acc: 0.9940\n",
            "Epoch 149/200\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6.2292e-04 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9930\n",
            "Epoch 150/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0313 - val_acc: 0.9940\n",
            "Epoch 151/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0194 - val_acc: 0.9950\n",
            "Epoch 152/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0072 - acc: 0.9972 - val_loss: 0.0721 - val_acc: 0.9900\n",
            "Epoch 153/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0106 - acc: 0.9979 - val_loss: 0.0447 - val_acc: 0.9920\n",
            "Epoch 154/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0173 - acc: 0.9975 - val_loss: 0.0354 - val_acc: 0.9910\n",
            "Epoch 155/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0146 - acc: 0.9979 - val_loss: 0.0468 - val_acc: 0.9920\n",
            "Epoch 156/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0149 - acc: 0.9978 - val_loss: 0.0461 - val_acc: 0.9900\n",
            "Epoch 157/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0596 - val_acc: 0.9880\n",
            "Epoch 158/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9989 - val_loss: 0.0336 - val_acc: 0.9930\n",
            "Epoch 159/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9993 - val_loss: 0.0492 - val_acc: 0.9890\n",
            "Epoch 160/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0438 - val_acc: 0.9910\n",
            "Epoch 161/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0358 - val_acc: 0.9930\n",
            "Epoch 162/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0422 - val_acc: 0.9930\n",
            "Epoch 163/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9986 - val_loss: 0.0416 - val_acc: 0.9920\n",
            "Epoch 164/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0614 - val_acc: 0.9910\n",
            "Epoch 165/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0442 - val_acc: 0.9910\n",
            "Epoch 166/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9995 - val_loss: 0.0446 - val_acc: 0.9930\n",
            "Epoch 167/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0350 - val_acc: 0.9940\n",
            "Epoch 168/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.0361 - val_acc: 0.9950\n",
            "Epoch 169/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0603 - val_acc: 0.9920\n",
            "Epoch 170/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0096 - acc: 0.9961 - val_loss: 0.1012 - val_acc: 0.9870\n",
            "Epoch 171/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0613 - val_acc: 0.9920\n",
            "Epoch 172/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.1012 - val_acc: 0.9930\n",
            "Epoch 173/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0159 - acc: 0.9962 - val_loss: 0.0732 - val_acc: 0.9930\n",
            "Epoch 174/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0749 - val_acc: 0.9920\n",
            "Epoch 175/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0911 - val_acc: 0.9870\n",
            "Epoch 176/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0264 - acc: 0.9951 - val_loss: 0.0397 - val_acc: 0.9930\n",
            "Epoch 177/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0763 - val_acc: 0.9910\n",
            "Epoch 178/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9989 - val_loss: 0.0450 - val_acc: 0.9910\n",
            "Epoch 179/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0434 - val_acc: 0.9940\n",
            "Epoch 180/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0100 - acc: 0.9987 - val_loss: 0.0548 - val_acc: 0.9900\n",
            "Epoch 181/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0141 - acc: 0.9983 - val_loss: 0.0361 - val_acc: 0.9930\n",
            "Epoch 182/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9980 - val_loss: 0.0375 - val_acc: 0.9950\n",
            "Epoch 183/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0615 - val_acc: 0.9950\n",
            "Epoch 184/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0497 - val_acc: 0.9950\n",
            "Epoch 185/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2.8946e-04 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9950\n",
            "Epoch 186/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0552 - val_acc: 0.9950\n",
            "Epoch 187/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0314 - val_acc: 0.9930\n",
            "Epoch 188/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0559 - val_acc: 0.9930\n",
            "Epoch 189/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9992 - val_loss: 0.0302 - val_acc: 0.9930\n",
            "Epoch 190/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0391 - val_acc: 0.9950\n",
            "Epoch 191/200\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0410 - val_acc: 0.9960\n",
            "Epoch 192/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0163 - acc: 0.9979 - val_loss: 0.0485 - val_acc: 0.9930\n",
            "Epoch 193/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0571 - val_acc: 0.9950\n",
            "Epoch 194/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0080 - acc: 0.9989 - val_loss: 0.0391 - val_acc: 0.9930\n",
            "Epoch 195/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0104 - acc: 0.9979 - val_loss: 0.0691 - val_acc: 0.9890\n",
            "Epoch 196/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0120 - acc: 0.9985 - val_loss: 0.0438 - val_acc: 0.9930\n",
            "Epoch 197/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0735 - val_acc: 0.9930\n",
            "Epoch 198/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0058 - acc: 0.9989 - val_loss: 0.0303 - val_acc: 0.9960\n",
            "Epoch 199/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.0634 - val_acc: 0.9920\n",
            "Epoch 200/200\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0130 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9910\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1127 - acc: 0.9870\n",
            "\n",
            "Test Loss : 0.11268378049135208 Test Accuracy : 0.9869999885559082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIhUGdoVc1Ko"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ISvz86radc0Y",
        "outputId": "3b07217d-ba0e-4848-a21c-6cac312e6c1d"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Conv2D(512, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_42 (Conv2D)           (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 14, 14, 128)       131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 7, 7, 256)         524544    \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 4,854,474\n",
            "Trainable params: 4,854,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 2s 51ms/step - loss: 1.8120 - acc: 0.3476 - val_loss: 0.4428 - val_acc: 0.8620\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.4253 - acc: 0.8536 - val_loss: 0.1394 - val_acc: 0.9510\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.2037 - acc: 0.9273 - val_loss: 0.1052 - val_acc: 0.9690\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.1358 - acc: 0.9531 - val_loss: 0.0943 - val_acc: 0.9710\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.1007 - acc: 0.9715 - val_loss: 0.0831 - val_acc: 0.9760\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0873 - acc: 0.9694 - val_loss: 0.0686 - val_acc: 0.9800\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0772 - acc: 0.9723 - val_loss: 0.0723 - val_acc: 0.9740\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0678 - acc: 0.9794 - val_loss: 0.0664 - val_acc: 0.9820\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0667 - acc: 0.9793 - val_loss: 0.0553 - val_acc: 0.9840\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0451 - acc: 0.9874 - val_loss: 0.0542 - val_acc: 0.9870\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0456 - acc: 0.9835 - val_loss: 0.0603 - val_acc: 0.9830\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 0.0648 - val_acc: 0.9840\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0477 - acc: 0.9852 - val_loss: 0.0536 - val_acc: 0.9820\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0491 - acc: 0.9843 - val_loss: 0.0666 - val_acc: 0.9850\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0288 - acc: 0.9889 - val_loss: 0.0597 - val_acc: 0.9850\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0308 - acc: 0.9888 - val_loss: 0.0597 - val_acc: 0.9850\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0298 - acc: 0.9889 - val_loss: 0.0494 - val_acc: 0.9840\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0240 - acc: 0.9927 - val_loss: 0.0474 - val_acc: 0.9860\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0193 - acc: 0.9928 - val_loss: 0.0568 - val_acc: 0.9860\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0675 - val_acc: 0.9820\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0217 - acc: 0.9931 - val_loss: 0.0580 - val_acc: 0.9820\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.0475 - val_acc: 0.9870\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0160 - acc: 0.9949 - val_loss: 0.0382 - val_acc: 0.9880\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0326 - val_acc: 0.9920\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0383 - val_acc: 0.9880\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0441 - val_acc: 0.9900\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.0533 - val_acc: 0.9890\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.0520 - val_acc: 0.9860\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0182 - acc: 0.9938 - val_loss: 0.0412 - val_acc: 0.9890\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0583 - val_acc: 0.9860\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0215 - acc: 0.9924 - val_loss: 0.0352 - val_acc: 0.9870\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0217 - val_acc: 0.9950\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0356 - val_acc: 0.9890\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0446 - val_acc: 0.9890\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0123 - acc: 0.9968 - val_loss: 0.0562 - val_acc: 0.9890\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0147 - acc: 0.9945 - val_loss: 0.0448 - val_acc: 0.9920\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0253 - acc: 0.9922 - val_loss: 0.0430 - val_acc: 0.9890\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0513 - val_acc: 0.9900\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0400 - val_acc: 0.9910\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0454 - val_acc: 0.9920\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.0515 - val_acc: 0.9920\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0409 - val_acc: 0.9890\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0458 - val_acc: 0.9890\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0084 - acc: 0.9956 - val_loss: 0.0414 - val_acc: 0.9900\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0463 - val_acc: 0.9870\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0357 - val_acc: 0.9900\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0276 - val_acc: 0.9930\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0249 - val_acc: 0.9940\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 0.0195 - val_acc: 0.9950\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 7.3756e-04 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9970\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0017 - acc: 0.9987 - val_loss: 0.0276 - val_acc: 0.9950\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0423 - val_acc: 0.9920\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0282 - val_acc: 0.9950\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.0291 - val_acc: 0.9920\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0045 - acc: 0.9978 - val_loss: 0.0346 - val_acc: 0.9920\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0034 - acc: 0.9979 - val_loss: 0.0349 - val_acc: 0.9910\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0478 - val_acc: 0.9890\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.0346 - val_acc: 0.9900\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0379 - val_acc: 0.9900\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.0283 - val_acc: 0.9940\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0263 - val_acc: 0.9920\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0400 - val_acc: 0.9900\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0484 - val_acc: 0.9910\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0321 - val_acc: 0.9910\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0436 - val_acc: 0.9900\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0213 - val_acc: 0.9950\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0233 - val_acc: 0.9950\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0270 - val_acc: 0.9910\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0074 - acc: 0.9972 - val_loss: 0.0308 - val_acc: 0.9920\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0268 - val_acc: 0.9940\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0385 - val_acc: 0.9920\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0419 - val_acc: 0.9900\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0202 - val_acc: 0.9960\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0034 - acc: 0.9984 - val_loss: 0.0326 - val_acc: 0.9910\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0742 - val_acc: 0.9900\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0311 - val_acc: 0.9920\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0379 - val_acc: 0.9950\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0362 - val_acc: 0.9930\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0162 - val_acc: 0.9950\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 6.4238e-04 - acc: 0.9999 - val_loss: 0.0196 - val_acc: 0.9940\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0231 - val_acc: 0.9950\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0414 - val_acc: 0.9920\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9950\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0206 - val_acc: 0.9950\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0255 - val_acc: 0.9930\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0431 - val_acc: 0.9910\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0178 - val_acc: 0.9950\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0325 - val_acc: 0.9940\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9940\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 3.8174e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9950\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0254 - val_acc: 0.9950\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0203 - val_acc: 0.9970\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0220 - val_acc: 0.9950\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 4.9143e-04 - acc: 0.9999 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 9.1141e-04 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9960\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 5.8437e-04 - acc: 0.9997 - val_loss: 0.0175 - val_acc: 0.9950\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 3.9901e-04 - acc: 0.9997 - val_loss: 0.0359 - val_acc: 0.9940\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 2.9260e-04 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9960\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0352 - val_acc: 0.9930\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0083 - acc: 0.9988 - val_loss: 0.0321 - val_acc: 0.9950\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0149 - acc: 0.9957 - val_loss: 0.0466 - val_acc: 0.9880\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0323 - val_acc: 0.9940\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0027 - acc: 0.9988 - val_loss: 0.0288 - val_acc: 0.9950\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0287 - val_acc: 0.9960\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0017 - acc: 0.9989 - val_loss: 0.0418 - val_acc: 0.9930\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0271 - val_acc: 0.9960\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0363 - val_acc: 0.9930\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0510 - val_acc: 0.9910\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0281 - val_acc: 0.9930\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0256 - val_acc: 0.9960\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0049 - acc: 0.9982 - val_loss: 0.0292 - val_acc: 0.9960\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0203 - val_acc: 0.9960\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 0.0308 - val_acc: 0.9950\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 0.0819 - val_acc: 0.9860\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0148 - acc: 0.9948 - val_loss: 0.0411 - val_acc: 0.9930\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0104 - acc: 0.9973 - val_loss: 0.0528 - val_acc: 0.9910\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0202 - val_acc: 0.9960\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0214 - val_acc: 0.9950\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0245 - val_acc: 0.9940\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 8.3055e-04 - acc: 0.9999 - val_loss: 0.0348 - val_acc: 0.9950\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0050 - acc: 0.9990 - val_loss: 0.0563 - val_acc: 0.9930\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0597 - val_acc: 0.9930\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0045 - acc: 0.9982 - val_loss: 0.0464 - val_acc: 0.9910\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0132 - acc: 0.9980 - val_loss: 0.0464 - val_acc: 0.9910\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0125 - acc: 0.9976 - val_loss: 0.0260 - val_acc: 0.9950\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0203 - val_acc: 0.9970\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0329 - val_acc: 0.9960\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0191 - val_acc: 0.9940\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0310 - val_acc: 0.9930\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0290 - val_acc: 0.9950\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0280 - val_acc: 0.9940\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0180 - val_acc: 0.9960\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 6.8627e-04 - acc: 0.9999 - val_loss: 0.0365 - val_acc: 0.9920\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0076 - acc: 0.9960 - val_loss: 0.0226 - val_acc: 0.9950\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 0.0304 - val_acc: 0.9930\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0079 - acc: 0.9966 - val_loss: 0.0384 - val_acc: 0.9930\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 1s 48ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0280 - val_acc: 0.9930\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0208 - val_acc: 0.9940\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0097 - val_acc: 0.9970\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0480 - val_acc: 0.9900\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0485 - val_acc: 0.9910\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0040 - acc: 0.9977 - val_loss: 0.0479 - val_acc: 0.9920\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.0609 - val_acc: 0.9890\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0306 - val_acc: 0.9930\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0310 - val_acc: 0.9940\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0404 - val_acc: 0.9890\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0288 - val_acc: 0.9940\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0194 - val_acc: 0.9940\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0026 - acc: 0.9986 - val_loss: 0.0261 - val_acc: 0.9920\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0325 - val_acc: 0.9910\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0488 - acc: 0.9920\n",
            "\n",
            "Test Loss : 0.05 Test Accuracy : 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU5dX38e8BBpABZRWVnQQwKPuAawJEo7hBXDDwjAsaRY1beOIajBqVaBKf18TE3ShRiIiaGIyoiUbFaFwGV0AwgCyDGxBFFFFhzvvHXc30zHTP9DA99HTN73NddXXXfvrurlN33VVdZe6OiIjkvya5DkBERLJDCV1EJCaU0EVEYkIJXUQkJpTQRURiQgldRCQmlNClAjN7zMxOzva0uWRmK8zs4HpY7jNmdlr0vtjM/p7JtNuxnu5m9pmZNd3eWKVxUEKPgWhjT3RlZvZFUn9xbZbl7oe5+x+zPW1DZGaXmNm8FMM7mtlXZrZ3psty95nufkiW4qqwA3L3Ve7e2t23ZmP5ldblZvbNbC9XckMJPQaijb21u7cGVgFHJQ2bmZjOzJrlLsoGaQawv5n1qjR8AvCWuy/IQUwi200JPcbMbJSZlZrZxWb2AXC3mbUzs7+Z2Voz+zh63zVpnuRmhElm9i8zuz6a9l0zO2w7p+1lZvPMbKOZPWlmN5nZjDRxZxLj1Wb2fLS8v5tZx6TxJ5rZSjNbb2ZT05WPu5cC/wROrDTqJOCemuKoFPMkM/tXUv/3zGyxmW0ws98DljTuG2b2zyi+dWY208zaRuPuBboDj0RHWBeZWc+oJt0smmYPM5tjZv81s6VmdnrSsq80s9lmdk9UNgvNrChdGaRjZrtEy1gbleVlZtYkGvdNM3s2+mzrzOz+aLiZ2Q1m9pGZfWpmb9XmKEfqTgk9/nYD2gM9gMmE7/zuqL878AXw+2rm3wdYAnQEfgX8wcxsO6b9E/Ay0AG4kqpJNFkmMf4PcAqwK9AcuADAzPoDt0TL3yNaX8okHPljcixm1g8YHMVb27JKLKMj8GfgMkJZLAMOSJ4EuDaK71tAN0KZ4O4nUvEo61cpVjELKI3mPw74hZl9N2n82GiatsCcTGJO4XfALkBvYCRhJ3dKNO5q4O9AO0LZ/i4afgjwHaBvNO/xwPrtWLdsL3dXF6MOWAEcHL0fBXwFtKxm+sHAx0n9zwCnRe8nAUuTxrUCHNitNtMSkuEWoFXS+BnAjAw/U6oYL0vq/xHwePT+cmBW0rjCqAwOTrPsVsCnwP5R/zTgr9tZVv+K3p8EvJg0nRES8Glplvt94LVU32HU3zMqy2aE5L8VaJM0/lpgevT+SuDJpHH9gS+qKVsHvllpWNOozPonDTsDeCZ6fw9wO9C10nzfBd4B9gWa5HpbaIydaujxt9bdNyd6zKyVmd0WHUZ/CswD2lr6Kyg+SLxx903R29a1nHYP4L9JwwBWpws4wxg/SHq/KSmmPZKX7e6fU00tMYrpAeCk6GiimJCwtqesEirH4Mn9ZtbZzGaZ2ZpouTMINflMJMpyY9KwlUCXpP7KZdPSanf+pCNQEC031TouIuykXo6adE4FcPd/Eo4GbgI+MrPbzWznWqxX6kgJPf4q307zJ0A/YB9335lwiAxJbbz14H2gvZm1ShrWrZrp6xLj+8nLjtbZoYZ5/khoHvge0AZ4pI5xVI7BqPh5f0H4XgZEyz2h0jKruwXqe4SybJM0rDuwpoaYamMd8DWhqanKOtz9A3c/3d33INTcb7boShl3v9HdhxGODPoCF2YxLqmBEnrj04bQFvyJmbUHrqjvFbr7SqAEuNLMmpvZfsBR9RTjg8CRZnagmTUHrqLm3/lzwCeEZoRZ7v5VHeN4FNjLzI6JasbnEZqeEtoAnwEbzKwLVZPeh4S26yrcfTXwAnCtmbU0s4HADwm1/O3VPFpWSzNrGQ2bDUwzszZm1gP438Q6zGx80snhjwk7oDIzG25m+5hZAfA5sBkoq0NcUktK6I3Pb4CdCLWwF4HHd9B6i4H9CM0f1wD3A1+mmXa7Y3T3hcDZhJOa7xMSTmkN8zihmaVH9FqnONx9HTAeuI7wefsAzydN8nNgKLCBkPz/XGkR1wKXmdknZnZBilVMJLSrvwf8BbjC3Z/MJLY0FhJ2XInuFOBcQlJeDvyLUJ53RdMPB14ys88IJ13Pd/flwM7AHYQyX0n47L+uQ1xSSxadzBDZoaJL3Ra7e70fIYg0Fqqhyw4RHY5/w8yamNkYYBzwcK7jEokT/XNQdpTdCE0LHQhNIGe5+2u5DUkkXtTkIiISE2pyERGJiZw1uXTs2NF79uyZq9WLiOSl+fPnr3P3TqnG5Syh9+zZk5KSklytXkQkL5nZynTj1OQiIhITSugiIjGhhC4iEhO6Dl0k5r7++mtKS0vZvHlzzRNLg9GyZUu6du1KQUFBxvMooYvEXGlpKW3atKFnz56kfzaJNCTuzvr16yktLaVXr8pPSEwvr5pcZs6Enj2hSZPwOnNmTXOIyObNm+nQoYOSeR4xMzp06FDro6q8qaHPnAmTJ8Om6BEJK1eGfoDiWj3XXqTxUTLPP9vzneVNDX3q1PJknrBpUxguIiJ5lNBXrardcBFpGNavX8/gwYMZPHgwu+22G126dNnW/9VXX1U7b0lJCeedd16N69h///2zEuszzzzDkUcemZVl5ULeJPTu3Ws3XES2T7bPVXXo0IHXX3+d119/nTPPPJMpU6Zs62/evDlbtmxJO29RURE33nhjjet44YUX6hZkTORNQp82DVq1qjisVaswXESyI3GuauVKcC8/V5XtCxAmTZrEmWeeyT777MNFF13Eyy+/zH777ceQIUPYf//9WbJkCVCxxnzllVdy6qmnMmrUKHr37l0h0bdu3Xrb9KNGjeK4445jzz33pLi4mMQdZefOncuee+7JsGHDOO+882pVE7/vvvsYMGAAe++9NxdffDEAW7duZdKkSey9994MGDCAG264AYAbb7yR/v37M3DgQCZMmFD3wqqFvDkpmjjxOXVqaGbp3j0kc50QFcme6s5VZXtbKy0t5YUXXqBp06Z8+umnPPfcczRr1ownn3ySn/70pzz00ENV5lm8eDFPP/00GzdupF+/fpx11llVrtN+7bXXWLhwIXvssQcHHHAAzz//PEVFRZxxxhnMmzePXr16MXHixIzjfO+997j44ouZP38+7dq145BDDuHhhx+mW7durFmzhgULFgDwySefAHDdddfx7rvv0qJFi23DdpS8qaFD+EGtWAFlZeFVyVwku3bkuarx48fTtGlTADZs2MD48ePZe++9mTJlCgsXLkw5zxFHHEGLFi3o2LEju+66Kx9++GGVaUaMGEHXrl1p0qQJgwcPZsWKFSxevJjevXtvu6a7Ngn9lVdeYdSoUXTq1IlmzZpRXFzMvHnz6N27N8uXL+fcc8/l8ccfZ+eddwZg4MCBFBcXM2PGDJo127F15rxK6CJSv3bkuarCwsJt73/2s58xevRoFixYwCOPPJL2+usWLVpse9+0adOU7e+ZTJMN7dq144033mDUqFHceuutnHbaaQA8+uijnH322bz66qsMHz683tafihK6iGyTq3NVGzZsoEuXLgBMnz4968vv168fy5cvZ8WKFQDcf//9Gc87YsQInn32WdatW8fWrVu57777GDlyJOvWraOsrIxjjz2Wa665hldffZWysjJWr17N6NGj+eUvf8mGDRv47LPPsv550smbNnQRqX+5Old10UUXcfLJJ3PNNddwxBFHZH35O+20EzfffDNjxoyhsLCQ4cOHp532qaeeomvXrtv6H3jgAa677jpGjx6Nu3PEEUcwbtw43njjDU455RTKysoAuPbaa9m6dSsnnHACGzZswN0577zzaNu2bdY/Tzo5e6ZoUVGR6wEXIvXv7bff5lvf+lauw8i5zz77jNatW+PunH322fTp04cpU6bkOqxqpfruzGy+uxelml5NLiLSKNxxxx0MHjyYvfbaiw0bNnDGGWfkOqSsU5OLiDQKU6ZMafA18rpSDV1EJCaU0EVEYkIJXUQkJpTQRURiQgldROrV6NGjeeKJJyoM+81vfsNZZ52Vdp5Ro0aRuKz58MMPT3lPlCuvvJLrr7++2nU//PDDLFq0aFv/5ZdfzpNPPlmb8FNqqLfZrTGhm9ldZvaRmS1IM77YzN40s7fM7AUzG5T9MEUkX02cOJFZs2ZVGDZr1qyM76cyd+7c7f5zTuWEftVVV3HwwQdv17LyQSY19OnAmGrGvwuMdPcBwNXA7VmIS0Ri4rjjjuPRRx/d9jCLFStW8N577/Htb3+bs846i6KiIvbaay+uuOKKlPP37NmTdevWATBt2jT69u3LgQceuO0WuxCuMR8+fDiDBg3i2GOPZdOmTbzwwgvMmTOHCy+8kMGDB7Ns2TImTZrEgw8+CIR/hA4ZMoQBAwZw6qmn8uWXX25b3xVXXMHQoUMZMGAAixcvzviz5vo2uzVeh+7u88ysZzXjk+8s/yLQNd20IpJbP/4xvP56dpc5eDD85jfpx7dv354RI0bw2GOPMW7cOGbNmsXxxx+PmTFt2jTat2/P1q1bOeigg3jzzTcZOHBgyuXMnz+fWbNm8frrr7NlyxaGDh3KsGHDADjmmGM4/fTTAbjsssv4wx/+wLnnnsvYsWM58sgjOe644yosa/PmzUyaNImnnnqKvn37ctJJJ3HLLbfw4x//GICOHTvy6quvcvPNN3P99ddz55131lgODeE2u9luQ/8h8Fi6kWY22cxKzKxk7dq1WV61iDRUyc0uyc0ts2fPZujQoQwZMoSFCxdWaB6p7LnnnuPoo4+mVatW7LzzzowdO3bbuAULFvDtb3+bAQMGMHPmzLS3301YsmQJvXr1om/fvgCcfPLJzJs3b9v4Y445BoBhw4Ztu6FXTRrCbXaz9k9RMxtNSOgHppvG3W8napIpKirKzU1kRBqx6mrS9WncuHFMmTKFV199lU2bNjFs2DDeffddrr/+el555RXatWvHpEmT0t42tyaTJk3i4YcfZtCgQUyfPp1nnnmmTvEmbsGbjdvvJm6z+8QTT3Drrbcye/Zs7rrrLh599FHmzZvHI488wrRp03jrrbfqnNizUkM3s4HAncA4d1+fjWWKSHy0bt2a0aNHc+qpp26rnX/66acUFhayyy678OGHH/LYY2kP7gH4zne+w8MPP8wXX3zBxo0beeSRR7aN27hxI7vvvjtff/01M5Oel9emTRs2btxYZVn9+vVjxYoVLF26FIB7772XkSNH1ukzNoTb7Na5hm5m3YE/Aye6+zt1jkhEYmnixIkcffTR25peBg0axJAhQ9hzzz3p1q0bBxxwQLXzDx06lB/84AcMGjSIXXfdtcItcK+++mr22WcfOnXqxD777LMtiU+YMIHTTz+dG2+8cdvJUICWLVty9913M378eLZs2cLw4cM588wza/V5GuJtdmu8fa6Z3QeMAjoCHwJXAAUA7n6rmd0JHAusjGbZku7Wjsl0+1yRHUO3z81ftb19biZXuVR7sai7nwacVpsgRUQk+/RPURGRmFBCF2kEcvVkMtl+2/OdKaGLxFzLli1Zv369knoecXfWr19Py5YtazWfnlgkEnNdu3altLQU/Zkvv7Rs2bLCVTSZUEIXibmCggJ69eqV6zBkB1CTi4hITCihi4jEhBK6iEhMKKGLiMSEErqISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMSEErqISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMREjQndzO4ys4/MbEGa8WZmN5rZUjN708yGZj9MERGpSSY19OnAmGrGHwb0ibrJwC11D0tERGqrxoTu7vOA/1YzyTjgHg9eBNqa2e7ZClBERDKTjTb0LsDqpP7SaFgVZjbZzErMrEQPrBURya4delLU3W939yJ3L+rUqdOOXLWISOxlI6GvAbol9XeNhomIyA6UjYQ+BzgputplX2CDu7+fheWKiEgtNKtpAjO7DxgFdDSzUuAKoADA3W8F5gKHA0uBTcAp9RWsiIikV2NCd/eJNYx34OysRSQiIttF/xQVEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiYmMErqZjTGzJWa21MwuSTG+u5k9bWavmdmbZnZ49kMVEZHq1JjQzawpcBNwGNAfmGhm/StNdhkw292HABOAm7MdqIiIVC+TGvoIYKm7L3f3r4BZwLhK0ziwc/R+F+C97IUoIiKZyCShdwFWJ/WXRsOSXQmcYGalwFzg3FQLMrPJZlZiZiVr167djnBFRCSdbJ0UnQhMd/euwOHAvWZWZdnufru7F7l7UadOnbK0ahERgcwS+hqgW1J/12hYsh8CswHc/d9AS6BjNgIUEZHMZJLQXwH6mFkvM2tOOOk5p9I0q4CDAMzsW4SErjYVEZEdqMaE7u5bgHOAJ4C3CVezLDSzq8xsbDTZT4DTzewN4D5gkrt7fQUtIiJVNctkInefSzjZmTzs8qT3i4ADshuaiIjUhv4pKiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITGSV0MxtjZkvMbKmZXZJmmuPNbJGZLTSzP2U3TBERqUmzmiYws6bATcD3gFLgFTOb4+6LkqbpA1wKHODuH5vZrvUVsIiIpJZJDX0EsNTdl7v7V8AsYFylaU4HbnL3jwHc/aPshikiIjXJJKF3AVYn9ZdGw5L1Bfqa2fNm9qKZjUm1IDObbGYlZlaydu3a7YtYRERSytZJ0WZAH2AUMBG4w8zaVp7I3W939yJ3L+rUqVOWVi0iIpBZQl8DdEvq7xoNS1YKzHH3r939XeAdQoIXEZEdJJOE/grQx8x6mVlzYAIwp9I0DxNq55hZR0ITzPIsxikiIjWoMaG7+xbgHOAJ4G1gtrsvNLOrzGxsNNkTwHozWwQ8DVzo7uvrK2gREanK3D0nKy4qKvKSkpKcrFtEJF+Z2Xx3L0o1Tv8UFRGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZjIu4T+wgtw7LGwpvJTTUVEGrm8S+gffgh//jOsXZvrSEREGpa8S+itW4fXzz/PbRwiIg1N3ib0zz7LbRwiIg1NRgndzMaY2RIzW2pml1Qz3bFm5maW8gGm2VBYGF5VQxcRqajGhG5mTYGbgMOA/sBEM+ufYro2wPnAS9kOMplq6CIiqWVSQx8BLHX35e7+FTALGJdiuquBXwKbsxhfFaqhi4iklklC7wKsTuovjYZtY2ZDgW7u/mh1CzKzyWZWYmYla7fzMhXV0EVEUqvzSVEzawL8P+AnNU3r7re7e5G7F3Xq1Gm71rfTTuFVCV1EpKJMEvoaoFtSf9doWEIbYG/gGTNbAewLzKmvE6NNmoRmFzW5iIhUlElCfwXoY2a9zKw5MAGYkxjp7hvcvaO793T3nsCLwFh3L6mXiAnNLqqhi4hUVGNCd/ctwDnAE8DbwGx3X2hmV5nZ2PoOMHVMMGNGqK337AkzZ+YiChGRhqVZJhO5+1xgbqVhl6eZdlTdw0pv5szwt3/30L9yJUyeHN4XF9fnmkVEGra8+6fo1KnlyTxh06YwXESkMcu7hL5qVe2Gi4g0FnmX0Lt3r91wEZHGIu8S+rRp0LRpxWGtWoXhIiKNWd4l9OJiGDkyXOFiBj16wO2364SoiEhGV7k0NEOGwEsv6Vp0EZFkeVdDh/DHos8/h7KyXEciItJw5GVCT9xxcdOm3MYhItKQ5GVC12PoRESqysuEnqihqw1dRKRcXiZ01dBFRKrKy4SuGrqISFV5mdBVQxcRqSqvE7pq6CIi5fIyoavJRUSkqrxM6GpyERGpKi8TumroIiJV5WVCb9UqvKqGLiJSLi8TetOmsNNOqqGLiCTLy4QOoR1dCV1EpFxeJ3Q1uYiIlMsooZvZGDNbYmZLzeySFOP/18wWmdmbZvaUmfXIfqgVFRaqhi4ikqzGhG5mTYGbgMOA/sBEM+tfabLXgCJ3Hwg8CPwq24FWlqihz5wJPXuGJxj17Bn6RUQao0xq6COApe6+3N2/AmYB45IncPen3T1xd/IXga7ZDbOqwkJ4912YPBlWrgT38Dp5spK6iDROmST0LsDqpP7SaFg6PwQeSzXCzCabWYmZlaxduzbzKFNo3RpWrKj6kItNm2Dq1DotWkQkL2X1pKiZnQAUAb9ONd7db3f3Incv6tSpU53WVVgIX3+detyqVXVatIhIXsrkIdFrgG5J/V2jYRWY2cHAVGCku3+ZnfDSa906tJuneq5o9+71vXYRkYYnkxr6K0AfM+tlZs2BCcCc5AnMbAhwGzDW3T/KfphVtW4NzZuX/2s0oVUrmDZtR0QgItKw1JjQ3X0LcA7wBPA2MNvdF5rZVWY2Nprs10Br4AEze93M5qRZXNYUFsKXX8Jtt0GPHmAWXm+/HYqL63vtIiINT0Zt6O4+1937uvs33H1aNOxyd58TvT/Y3Tu7++CoG1v9EuuudetwZcsxx4STo/feG4afeKIuXxSRximTNvQGKfmOi3/5S7hcMXHFS+LyRVBtXUQaj7z+6z+EPxdNnarLF0VE8jahJ9fQ012mqMsXRaQxyduE3i26kHL+/PSXKeryRRFpTPI2oY8YAXvuGa5ymTZNly+KiORtQjcLJz5ffBEGDAiXK/aI7vHYtGl5G7qudhGRxiJvEzrAySdDixbl154naupbt4bxulmXiDQmeZ3Q27eH8ePDNegbN+pqFxFp3PI6oQOcc05I5iNHhhp5KrraRUQag7xP6PvsA488AsuWhZt1peIe2tz1D1IRibO8T+gARxwBL78MnTtXP53a1EUkzmKR0AH69YO334YhQ6qfbtOmcDJVj6wTya4//Qn22y/9cwqk/sUmoQPssguUlNQ83datemSdVPXxx3DUUfDOO7mOJD9Nnx4uI3766VxH0njFKqFDqHnX5h+iiRr7H/4Q2uL/858w3B3+7//g5z8PG3pN3OGGG2Ds2NCeL/nngQfgb3+DO+7IdST5Z/NmeO658H727NzG0qi5e066YcOGeX2ZMcN9p53cQ5qtXdesmXvHjhWH7byz+/jx7scf737dde5ff11xfRs2uB97bJi2oMC9dWv3u+92Lyur2+coK3P/61/D8mvy+efuW7bUbX2N3cEHh++wd++6f3eNzT/+Ecqua1f3du3cv/qqdvMvWeL++9+7n3uu++LF9RNjNj33nPuYMe4rV+74dQMlniavxjKhu4ek3qPH9iX1yl3z5u677eb+jW+E/pEj3VesCOt59ln3Xr3cmzZ1v/768AV/5zthuuOPd//vf2uO9bXX3IuL3U891f2KK9w/+CAMv+66sJzi4urnf+65sBMaNsy9tLTiuBdfdJ8/v+KwsjL3f/3Lfd68DAqykVi7NnyHPXuGMn/jjVxHlHvLlpX/zmty8cWhMvOnP4Xye+yx8Lu75pqaKxpz57qbhfmaNnXfdVf3t96qe/z15YknyiuM55yz49ffKBN6smwl9iZNqvabhUT//PPl69uyxf0Xvwi1/W7d3J95JnVcGzeGBN6smXvbtu577BGWucce7r/+dVj2bruFdT37bNX5y8rcp08PO5zevcORwe67u995p/tTT7mfcEL5Uccdd7h/9pn7bbe5DxxY/hnOOScks7vvdr/yyrADeP9999/+NmykmeyQKsvkSOGDD9y/9z33q6/OrDb81lvuo0e7f/e77ps2hWEbN7qvWVP7+FK5445QHo8/Hsr9iiuys9yEL78M5b+jffqp+1lnhZ1+bZSUuLdpE2rcmcQ9dGioyGzeHI5ohw0rT3pz5qSfb+NG9+7d3fv3DzuQxYvD7799+3DU+z//475wYe1iz6anngrbYGFh2M522SXsdAYOdB83zr1VK/f163dsTI0+oc+YEQo+G0k9VZdcu0h+Td4BHHlkSJzu4Ud73nnhh5+ogSd+FK+/Hmr84D5ggPtHH4Uf/MCBFZt63nvP/fvfD9ONHh3mf+utkNgT6ywocL/0UvdDDw39hYXhddCgkMCmTKn5c/XqVbWGX525c0Mi+NWv0k+zcqV7377l5fa//xuOLB54wH3RoorTlpW5T5sWdkrt2oV5fvAD9wULwmdt2zaURSY+/ND9ggtCstlll5C0Eg49tLyp5dvfDmX/xRfu993n/tBD4XtJt+PZvNn9qKPcf/nL1OM//9x98GD3vfaqfVNEJv7zn7Duo44KR3WrVpWvd+TI8u/+hReqzrtqVfg9nHqq+9atYdiiReGIL1GZuOSS6te/dm34Xq6+OvSfdFKYb9993bt0cT/kkPTznn9+mDe5QrR0qfuoUaG82rQJyf6LLzIujpQ+/zx10+WLL7rPnJn+u/3+9907dAi/0YsvDvFedFHY3t58M3zOadPKp3/55bCtP/ZY3eKtTqNP6O7lTTBm4Qtq3rz+Enx1XSJZFxSE2keqjWz9+lBDTLTPnX9++fzdu7tfe23Y4Fq2DIkzkehnzAjjk3cmPXq4//GPIbGfcEJoakn+8f71r2GD/fe/w3rvuSdsmAsWhB97166hrH7605pravPmhVpZYsdxww0h2S1b5n7VVe59+oREWlAQdmbPPRfaTJPLp6AgfKatW0OcU6eG4RMmuK9bV94M1ayZe+fO7i1auE+cWDWWsrJQs3vkEfePPw6fp0ePsPyRI8Nh/eDBoexKS8PyLr44zHvDDWEdnTtXjO3CC1N/7sRnaNHCffXqqnGceGL5Mm65JQz/xz/CUdzHH1dfpjV56KHyHWOiuQjcv/Wt8PnMwtHWN78ZyhHfVGEAAAqGSURBVP53vwsJ+5NPwmuPHuXbwo9+5H7vvWHH2blz2FGcdFIos+R27S+/DF3CrFlh/n//O/QvWxY+26ZN4bcEoY28crnceWeI70c/Sv/5HnsszH/RRRXX/7Ofuf/97+XDSkrCb3nRonBUkvwb/+KLUBa77lpeYSgtLT+ChZC4K38X69eHspkyJX18hx4aymrGjPD7aNo0bHtNmoSyrmz16rA9P/po+mXWRAk9hRkzQmLPRVKvXKPv0KE8lsq1/MS0lbsmTcprhDV9loKCMN4sbMAzZqQvk0TzVKqjjJ13DofB111X9WTQk0+G8f36hRpz4iRxcnfQQSH5XXhheRvpvfeWx155XYMGhfennVZeeywrC81EBx4YapdXXhmmmTs31OzOOad8h5LomjYNO5rddnN/5ZWwnAcfDOPOPz/UzFu1Kt/YV60Kyxg1KiTe+fNDYjNzf/rp8s9cVhZq8BB2KgUF7mecUT5+/fryHdLPfx5i7tw5JJ5EEm3bNuygEzvLZ54JzW3vvFO+jkTy3LQpNI2dcUYov2XLQpIePrz8+1i6NCzviCNCU+Dpp5d/pwUFVb+T9u1DMrzggvJh++0XzgdVbqrcaadw5NKqVZjvnntC+XTqFMq28sUC7qFpraAglLN72MH/+9+hMpP4TXz6ac2/R3A/5ZRwNJA44iwoCDvsG2+sup00bx5qyu+/H5qcIOyodtstVG5atQo74EsvDeWdaB6dPr28yfC228J8V19dXhmsvP38858V13viiSFpH3VU6D/hhLCjWLo0/I4LCsLv8Re/SP2ZM6GEXo1cJvZcdonkWdOOo7puwICwU7nmmrCc/v1DbTCxESaWWXkH1qNH2MgyLffKsSbmr+25keSjljPPLG/jNStv/qq8I0usq1u38vGnnBISUrt2VZcNYdk/+EFIEolh3bu7H3101ZgSMXTuHHYgyeN69QrnRSA0PSTeN2sWEkOPHiGhL19eu991YWGI//rrKybu7fkNJHeVKyPV/bbMwlHbli2pKxI1xVJ5/Lhx4ag28ZkT4xPfywUXhN9q5fNgqSouqfrT/ZY6dAg75eq2qcS5thYtwtHIu+/WLWfVOaEDY4AlwFLgkhTjWwD3R+NfAnrWtMyGktATkptkaptw1KnLVld5J1j5NZE0Ev2tW1c9uqtrYt5RXWFh1aOpOHepKjbpjparU6eEDjQFlgG9gebAG0D/StP8CLg1ej8BuL+m5Ta0hJ7O9tQe1KlTpy6TrlWr2if16hJ6Jv8UHQEsdffl7v4VMAsYV2maccAfo/cPAgeZmWX876YGrLgYVqwIxb9lS3gtK4MZMyo+ISnVazxKQETqS7af15BJQu8CrE7qL42GpZzG3bcAG4AOlRdkZpPNrMTMStauXbt9ETcQqRJ95ddE4u9QpSRERIJsPq9hh97Lxd1vd/cidy/q1KnTjlx1zhQXw7p11dfoO3QoT/rpavs9esBZZ9W8c+jQIaxrxoyqD86ujcS95XWUIVK/anPvqZpkktDXAN2S+rtGw1JOY2bNgF2A9dkIMC6qq9GvWxe66mr7K1bAzTen3zn06BGGr1sX1lVcXP7gbLPyHUJNzUSJ5STuSFm5eak2CT6xU6ipCSqxE3KvfseXbv7K60n3WdPNX1hYdYcapx1Zhw6ZVQZSlWMm30umr5mUaV2/y0xVXk9Nr+niqK4ylkmMrVqFZyFnTbrG9UQHNAOWA70oPym6V6VpzqbiSdHZNS03X06KSlWV/6RV+SqLTK51r+ma+EzWXd/zp7ryqfIJ8uRlpDqBnjxf5XWmmr62r9X9hyHV50sX4/ZcbbE9Uv126vpd1vb72FGfNV0M9XmVi4Xx1TOzw4HfEK54ucvdp5nZVdGC55hZS+BeYAjwX2CCuy+vbplFRUVeksnNy0VEZBszm+/uRanGNctkAe4+F5hbadjlSe83A+PrEqSIiNRN7B5wISLSWCmhi4jEhBK6iEhMKKGLiMRERle51MuKzdYCK7dz9o7AuiyGUx8UY3YoxuxQjHXXUOLr4e4p/5mZs4ReF2ZWku6ynYZCMWaHYswOxVh3DT0+UJOLiEhsKKGLiMREvib023MdQAYUY3YoxuxQjHXX0OPLzzZ0ERGpKl9r6CIiUokSuohITORdQjezMWa2xMyWmtkluY4HwMy6mdnTZrbIzBaa2fnR8PZm9g8z+0/02i7HcTY1s9fM7G9Rfy8zeykqy/vNrHmO42trZg+a2WIze9vM9muAZTgl+o4XmNl9ZtYy1+VoZneZ2UdmtiBpWMpys+DGKNY3zWxoDmP8dfRdv2lmfzGztknjLo1iXGJmh+YqxqRxPzEzN7OOUX9OyrEmeZXQzawpcBNwGNAfmGhm/XMbFQBbgJ+4e39gX+DsKK5LgKfcvQ/wVNSfS+cDbyf1/xK4wd2/CXwM/DAnUZX7LfC4u+8JDCLE2mDK0My6AOcBRe6+N+F20hPIfTlOB8ZUGpau3A4D+kTdZOCWHMb4D2Bvdx8IvANcChBtOxOAvaJ5bo62/VzEiJl1Aw4Bkh8Wl6tyrF66G6U3xA7YD3giqf9S4NJcx5Uizr8C3wOWALtHw3YHluQwpq6EDfu7wN8AI/zrrVmqss1BfLsA7xKdqE8a3pDKMPHs3PaEW0//DTi0IZQj0BNYUFO5AbcBE1NNt6NjrDTuaGBm9L7Cdg08AeyXqxgJD74fBKwAOua6HKvr8qqGTmYPrM4pM+tJeNDHS0Bnd38/GvUB0DlHYUF4QMlFQFnU3wH4xMNDvSH3ZdkLWAvcHTUL3WlmhTSgMnT3NcD1hJra+4SHoc+nYZVjQrpya6jb0KnAY9H7BhOjmY0D1rj7G5VGNZgYk+VbQm/QzKw18BDwY3f/NHmch914Tq4RNbMjgY/cfX4u1p+hZsBQ4BZ3HwJ8TqXmlVyWIUDUDj2OsPPZAygkxSF6Q5PrcquJmU0lNFvOzHUsycysFfBT4PKapm0o8i2hZ/LA6pwwswJCMp/p7n+OBn9oZrtH43cHPspReAcAY81sBTCL0OzyW6Bt9FBvyH1ZlgKl7v5S1P8gIcE3lDIEOBh4193XuvvXwJ8JZduQyjEhXbk1qG3IzCYBRwLF0Y4HGk6M3yDsvN+Itp2uwKtmthsNJ8YK8i2hvwL0ia4qaE44cTInxzFhZgb8AXjb3f9f0qg5wMnR+5MJbes7nLtf6u5d3b0nocz+6e7FwNPAcbmOD8DdPwBWm1m/aNBBwCIaSBlGVgH7mlmr6DtPxNhgyjFJunKbA5wUXaWxL7AhqWlmhzKzMYRmwLHuvilp1Bxggpm1MLNehBOPL+/o+Nz9LXff1d17RttOKTA0+q02mHKsINeN+Ntx0uJwwhnxZcDUXMcTxXQg4ZD2TeD1qDuc0E79FPAf4EmgfQOIdRTwt+h9b8KGshR4AGiR49gGAyVROT4MtGtoZQj8HFgMLCA8GL1FrssRuI/Qpv81Ien8MF25EU6G3xRtP28RrtjJVYxLCe3QiW3m1qTpp0YxLgEOy1WMlcavoPykaE7KsaZOf/0XEYmJfGtyERGRNJTQRURiQgldRCQmlNBFRGJCCV1EJCaU0EVEYkIJXUQkJv4/XuaxoH1Py0EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNe_3o_SdmKi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7JAGmSYMfNPh",
        "outputId": "6e548299-4b98-4da1-e27e-95ba2b291ef4"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(512, (4, 4), activation=\"relu\", padding= \"valid\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 14, 14, 128)       131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 7, 7, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 4,854,474\n",
            "Trainable params: 4,854,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 2s 54ms/step - loss: 2.1715 - acc: 0.1858 - val_loss: 1.0238 - val_acc: 0.7420\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.9279 - acc: 0.6681 - val_loss: 0.3982 - val_acc: 0.8870\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.4781 - acc: 0.8394 - val_loss: 0.1690 - val_acc: 0.9460\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.2732 - acc: 0.9134 - val_loss: 0.1281 - val_acc: 0.9570\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.1925 - acc: 0.9374 - val_loss: 0.1045 - val_acc: 0.9650\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.1649 - acc: 0.9454 - val_loss: 0.0934 - val_acc: 0.9720\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.1441 - acc: 0.9525 - val_loss: 0.0832 - val_acc: 0.9760\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.1248 - acc: 0.9630 - val_loss: 0.0679 - val_acc: 0.9790\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.1156 - acc: 0.9637 - val_loss: 0.0664 - val_acc: 0.9790\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.1243 - acc: 0.9629 - val_loss: 0.0625 - val_acc: 0.9810\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0753 - acc: 0.9763 - val_loss: 0.0482 - val_acc: 0.9860\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0666 - acc: 0.9786 - val_loss: 0.0461 - val_acc: 0.9850\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0773 - acc: 0.9760 - val_loss: 0.0442 - val_acc: 0.9850\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0691 - acc: 0.9746 - val_loss: 0.0500 - val_acc: 0.9840\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0741 - acc: 0.9787 - val_loss: 0.0519 - val_acc: 0.9840\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0673 - acc: 0.9792 - val_loss: 0.0437 - val_acc: 0.9860\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0522 - acc: 0.9823 - val_loss: 0.0544 - val_acc: 0.9810\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0558 - acc: 0.9813 - val_loss: 0.0491 - val_acc: 0.9870\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0532 - acc: 0.9832 - val_loss: 0.0324 - val_acc: 0.9900\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0376 - acc: 0.9874 - val_loss: 0.0312 - val_acc: 0.9890\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0357 - acc: 0.9889 - val_loss: 0.0453 - val_acc: 0.9870\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0421 - acc: 0.9876 - val_loss: 0.0324 - val_acc: 0.9900\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0522 - acc: 0.9844 - val_loss: 0.0307 - val_acc: 0.9910\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0353 - acc: 0.9866 - val_loss: 0.0353 - val_acc: 0.9870\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0339 - acc: 0.9879 - val_loss: 0.0288 - val_acc: 0.9910\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0352 - acc: 0.9900 - val_loss: 0.0282 - val_acc: 0.9930\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0307 - acc: 0.9906 - val_loss: 0.0407 - val_acc: 0.9860\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0336 - val_acc: 0.9900\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0400 - acc: 0.9886 - val_loss: 0.0239 - val_acc: 0.9910\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0412 - acc: 0.9848 - val_loss: 0.0280 - val_acc: 0.9930\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0322 - acc: 0.9921 - val_loss: 0.0310 - val_acc: 0.9900\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0338 - acc: 0.9879 - val_loss: 0.0211 - val_acc: 0.9950\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0171 - val_acc: 0.9950\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0257 - acc: 0.9921 - val_loss: 0.0228 - val_acc: 0.9930\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0186 - acc: 0.9931 - val_loss: 0.0259 - val_acc: 0.9940\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0244 - acc: 0.9918 - val_loss: 0.0212 - val_acc: 0.9940\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0283 - acc: 0.9921 - val_loss: 0.0178 - val_acc: 0.9930\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0193 - val_acc: 0.9950\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0206 - val_acc: 0.9920\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0227 - acc: 0.9932 - val_loss: 0.0277 - val_acc: 0.9920\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0363 - acc: 0.9876 - val_loss: 0.0187 - val_acc: 0.9950\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0158 - acc: 0.9927 - val_loss: 0.0178 - val_acc: 0.9950\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0261 - acc: 0.9930 - val_loss: 0.0187 - val_acc: 0.9950\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0213 - val_acc: 0.9910\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0228 - acc: 0.9905 - val_loss: 0.0339 - val_acc: 0.9910\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.0166 - val_acc: 0.9950\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0188 - acc: 0.9910 - val_loss: 0.0195 - val_acc: 0.9930\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0121 - acc: 0.9954 - val_loss: 0.0309 - val_acc: 0.9900\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0183 - val_acc: 0.9950\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0247 - acc: 0.9896 - val_loss: 0.0216 - val_acc: 0.9930\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0217 - acc: 0.9951 - val_loss: 0.0197 - val_acc: 0.9940\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0171 - val_acc: 0.9930\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0181 - val_acc: 0.9950\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0100 - val_acc: 0.9970\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0182 - val_acc: 0.9930\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0163 - val_acc: 0.9950\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0117 - acc: 0.9946 - val_loss: 0.0129 - val_acc: 0.9960\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0110 - acc: 0.9952 - val_loss: 0.0138 - val_acc: 0.9970\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0154 - acc: 0.9956 - val_loss: 0.0088 - val_acc: 0.9970\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0144 - val_acc: 0.9950\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0138 - val_acc: 0.9970\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 0.0135 - val_acc: 0.9960\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0116 - acc: 0.9959 - val_loss: 0.0145 - val_acc: 0.9970\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0131 - acc: 0.9947 - val_loss: 0.0177 - val_acc: 0.9950\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0117 - val_acc: 0.9970\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0114 - val_acc: 0.9970\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 0.0241 - val_acc: 0.9920\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0115 - val_acc: 0.9960\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0203 - val_acc: 0.9940\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0150 - val_acc: 0.9950\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9910\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0182 - val_acc: 0.9930\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0198 - acc: 0.9951 - val_loss: 0.0219 - val_acc: 0.9950\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0259 - acc: 0.9952 - val_loss: 0.0200 - val_acc: 0.9950\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 1s 46ms/step - loss: 0.0106 - acc: 0.9958 - val_loss: 0.0229 - val_acc: 0.9950\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0291 - val_acc: 0.9940\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0142 - val_acc: 0.9940\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0074 - acc: 0.9970 - val_loss: 0.0236 - val_acc: 0.9940\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0136 - acc: 0.9953 - val_loss: 0.0098 - val_acc: 0.9940\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0233 - val_acc: 0.9930\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0266 - val_acc: 0.9930\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0257 - acc: 0.9960 - val_loss: 0.0301 - val_acc: 0.9930\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0150 - acc: 0.9957 - val_loss: 0.0161 - val_acc: 0.9940\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0101 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 0.9930\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0133 - acc: 0.9969 - val_loss: 0.0144 - val_acc: 0.9950\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.0222 - val_acc: 0.9910\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0179 - val_acc: 0.9930\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0278 - val_acc: 0.9930\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0102 - val_acc: 0.9960\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0148 - acc: 0.9964 - val_loss: 0.0111 - val_acc: 0.9970\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0178 - val_acc: 0.9930\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0205 - val_acc: 0.9940\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0279 - val_acc: 0.9940\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0167 - val_acc: 0.9950\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.0170 - val_acc: 0.9960\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0129 - val_acc: 0.9940\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.0175 - val_acc: 0.9960\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0053 - acc: 0.9976 - val_loss: 0.0226 - val_acc: 0.9940\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0162 - acc: 0.9958 - val_loss: 0.0142 - val_acc: 0.9940\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0083 - acc: 0.9959 - val_loss: 0.0128 - val_acc: 0.9960\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0234 - val_acc: 0.9950\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0153 - acc: 0.9970 - val_loss: 0.0216 - val_acc: 0.9950\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0032 - acc: 0.9984 - val_loss: 0.0119 - val_acc: 0.9970\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 1s 46ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0099 - val_acc: 0.9980\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0158 - acc: 0.9972 - val_loss: 0.0114 - val_acc: 0.9980\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0157 - val_acc: 0.9960\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0111 - val_acc: 0.9970\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0106 - val_acc: 0.9970\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0134 - acc: 0.9967 - val_loss: 0.0141 - val_acc: 0.9950\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0089 - acc: 0.9979 - val_loss: 0.0095 - val_acc: 0.9980\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0128 - val_acc: 0.9970\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0141 - acc: 0.9967 - val_loss: 0.0094 - val_acc: 0.9970\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0266 - val_acc: 0.9960\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0116 - val_acc: 0.9970\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0074 - val_acc: 0.9950\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0165 - val_acc: 0.9940\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0200 - val_acc: 0.9940\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0180 - val_acc: 0.9960\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0189 - val_acc: 0.9940\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0221 - val_acc: 0.9950\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0132 - acc: 0.9975 - val_loss: 0.0120 - val_acc: 0.9950\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0213 - val_acc: 0.9960\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0265 - val_acc: 0.9930\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0292 - val_acc: 0.9920\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0177 - acc: 0.9958 - val_loss: 0.0112 - val_acc: 0.9950\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0069 - val_acc: 0.9960\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9940\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0094 - acc: 0.9957 - val_loss: 0.0163 - val_acc: 0.9940\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 1s 46ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0232 - val_acc: 0.9950\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 1s 46ms/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0166 - val_acc: 0.9930\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0041 - acc: 0.9982 - val_loss: 0.0141 - val_acc: 0.9930\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0283 - val_acc: 0.9920\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0164 - acc: 0.9958 - val_loss: 0.0230 - val_acc: 0.9940\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0199 - val_acc: 0.9950\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0164 - acc: 0.9959 - val_loss: 0.0175 - val_acc: 0.9940\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0133 - acc: 0.9968 - val_loss: 0.0388 - val_acc: 0.9900\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0121 - acc: 0.9977 - val_loss: 0.0254 - val_acc: 0.9910\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 1s 46ms/step - loss: 0.0176 - acc: 0.9955 - val_loss: 0.0208 - val_acc: 0.9970\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0064 - acc: 0.9968 - val_loss: 0.0176 - val_acc: 0.9950\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0039 - val_acc: 0.9990\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0096 - acc: 0.9977 - val_loss: 0.0172 - val_acc: 0.9930\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0062 - acc: 0.9977 - val_loss: 0.0134 - val_acc: 0.9970\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0284 - val_acc: 0.9940\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0067 - acc: 0.9968 - val_loss: 0.0179 - val_acc: 0.9960\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0146 - acc: 0.9978 - val_loss: 0.0159 - val_acc: 0.9960\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0235 - acc: 0.9955 - val_loss: 0.0191 - val_acc: 0.9930\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0157 - acc: 0.9959 - val_loss: 0.0126 - val_acc: 0.9950\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0210 - val_acc: 0.9960\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0064 - acc: 0.9989 - val_loss: 0.0078 - val_acc: 0.9970\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0106 - val_acc: 0.9970\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0256 - acc: 0.9910\n",
            "\n",
            "Test Loss : 0.0256 Test Accuracy : 0.9910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQoWRldkfXNP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r0sQ-EpygKhX",
        "outputId": "16d68c6f-c2b5-4004-8344-6e36ac5318a0"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(3, 3))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(3, 3))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(512, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_70 (Conv2D)           (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 9, 9, 128)         131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 3, 3, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 3, 3, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 3,936,970\n",
            "Trainable params: 3,936,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 2s 32ms/step - loss: 2.2955 - acc: 0.1146 - val_loss: 1.9804 - val_acc: 0.5270\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.7722 - acc: 0.3417 - val_loss: 0.7725 - val_acc: 0.7780\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.8917 - acc: 0.6842 - val_loss: 0.3239 - val_acc: 0.8920\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.5188 - acc: 0.8209 - val_loss: 0.2183 - val_acc: 0.9250\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.3551 - acc: 0.8811 - val_loss: 0.1214 - val_acc: 0.9570\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.2349 - acc: 0.9233 - val_loss: 0.1131 - val_acc: 0.9670\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.2033 - acc: 0.9315 - val_loss: 0.0940 - val_acc: 0.9730\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.2072 - acc: 0.9377 - val_loss: 0.0835 - val_acc: 0.9760\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1583 - acc: 0.9471 - val_loss: 0.0676 - val_acc: 0.9810\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1666 - acc: 0.9485 - val_loss: 0.0644 - val_acc: 0.9780\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1229 - acc: 0.9616 - val_loss: 0.0546 - val_acc: 0.9840\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1265 - acc: 0.9601 - val_loss: 0.0533 - val_acc: 0.9810\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1124 - acc: 0.9656 - val_loss: 0.0493 - val_acc: 0.9830\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1074 - acc: 0.9639 - val_loss: 0.0491 - val_acc: 0.9850\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1057 - acc: 0.9666 - val_loss: 0.0557 - val_acc: 0.9820\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.1040 - acc: 0.9768 - val_loss: 0.0475 - val_acc: 0.9840\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0924 - acc: 0.9718 - val_loss: 0.0436 - val_acc: 0.9860\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0877 - acc: 0.9732 - val_loss: 0.0673 - val_acc: 0.9750\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0873 - acc: 0.9719 - val_loss: 0.0558 - val_acc: 0.9850\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0891 - acc: 0.9732 - val_loss: 0.0470 - val_acc: 0.9860\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0796 - acc: 0.9751 - val_loss: 0.0413 - val_acc: 0.9850\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0769 - acc: 0.9776 - val_loss: 0.0318 - val_acc: 0.9890\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0748 - acc: 0.9780 - val_loss: 0.0415 - val_acc: 0.9830\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0664 - acc: 0.9792 - val_loss: 0.0393 - val_acc: 0.9890\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0680 - acc: 0.9784 - val_loss: 0.0337 - val_acc: 0.9890\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0635 - acc: 0.9795 - val_loss: 0.0281 - val_acc: 0.9930\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0508 - acc: 0.9832 - val_loss: 0.0360 - val_acc: 0.9890\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0573 - acc: 0.9780 - val_loss: 0.0302 - val_acc: 0.9920\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0676 - acc: 0.9819 - val_loss: 0.0408 - val_acc: 0.9880\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0592 - acc: 0.9839 - val_loss: 0.0294 - val_acc: 0.9940\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0442 - acc: 0.9878 - val_loss: 0.0291 - val_acc: 0.9930\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0392 - acc: 0.9876 - val_loss: 0.0307 - val_acc: 0.9930\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0533 - acc: 0.9850 - val_loss: 0.0315 - val_acc: 0.9920\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0373 - acc: 0.9876 - val_loss: 0.0359 - val_acc: 0.9920\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0559 - acc: 0.9841 - val_loss: 0.0340 - val_acc: 0.9880\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0517 - acc: 0.9817 - val_loss: 0.0272 - val_acc: 0.9930\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0333 - val_acc: 0.9900\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0456 - acc: 0.9861 - val_loss: 0.0323 - val_acc: 0.9910\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0355 - acc: 0.9896 - val_loss: 0.0291 - val_acc: 0.9920\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0495 - acc: 0.9872 - val_loss: 0.0311 - val_acc: 0.9900\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0425 - acc: 0.9879 - val_loss: 0.0351 - val_acc: 0.9920\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0458 - acc: 0.9820 - val_loss: 0.0272 - val_acc: 0.9920\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0440 - acc: 0.9871 - val_loss: 0.0363 - val_acc: 0.9910\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0442 - acc: 0.9853 - val_loss: 0.0224 - val_acc: 0.9920\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0422 - acc: 0.9877 - val_loss: 0.0249 - val_acc: 0.9920\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0236 - val_acc: 0.9950\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0334 - acc: 0.9890 - val_loss: 0.0309 - val_acc: 0.9920\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0372 - acc: 0.9900 - val_loss: 0.0235 - val_acc: 0.9940\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0366 - acc: 0.9891 - val_loss: 0.0266 - val_acc: 0.9920\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0361 - acc: 0.9885 - val_loss: 0.0289 - val_acc: 0.9930\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0364 - acc: 0.9870 - val_loss: 0.0308 - val_acc: 0.9900\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0338 - acc: 0.9918 - val_loss: 0.0226 - val_acc: 0.9940\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0400 - acc: 0.9865 - val_loss: 0.0260 - val_acc: 0.9940\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0481 - acc: 0.9858 - val_loss: 0.0351 - val_acc: 0.9930\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.0290 - val_acc: 0.9910\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0455 - acc: 0.9854 - val_loss: 0.0348 - val_acc: 0.9900\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0344 - acc: 0.9910 - val_loss: 0.0308 - val_acc: 0.9920\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0313 - val_acc: 0.9930\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0296 - acc: 0.9916 - val_loss: 0.0196 - val_acc: 0.9940\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0417 - acc: 0.9877 - val_loss: 0.0246 - val_acc: 0.9940\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0306 - acc: 0.9911 - val_loss: 0.0248 - val_acc: 0.9920\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0366 - acc: 0.9899 - val_loss: 0.0202 - val_acc: 0.9940\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0245 - acc: 0.9909 - val_loss: 0.0178 - val_acc: 0.9950\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0243 - acc: 0.9914 - val_loss: 0.0251 - val_acc: 0.9940\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0229 - acc: 0.9943 - val_loss: 0.0244 - val_acc: 0.9940\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0269 - val_acc: 0.9920\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0233 - acc: 0.9917 - val_loss: 0.0267 - val_acc: 0.9920\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0390 - acc: 0.9918 - val_loss: 0.0215 - val_acc: 0.9950\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0261 - acc: 0.9915 - val_loss: 0.0240 - val_acc: 0.9930\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0283 - acc: 0.9925 - val_loss: 0.0179 - val_acc: 0.9940\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0254 - val_acc: 0.9940\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0176 - val_acc: 0.9960\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0279 - acc: 0.9903 - val_loss: 0.0279 - val_acc: 0.9940\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0219 - acc: 0.9939 - val_loss: 0.0185 - val_acc: 0.9950\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0341 - acc: 0.9905 - val_loss: 0.0173 - val_acc: 0.9950\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0296 - acc: 0.9888 - val_loss: 0.0165 - val_acc: 0.9940\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0303 - acc: 0.9910 - val_loss: 0.0171 - val_acc: 0.9950\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0163 - acc: 0.9960 - val_loss: 0.0181 - val_acc: 0.9930\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0275 - val_acc: 0.9940\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0134 - acc: 0.9949 - val_loss: 0.0236 - val_acc: 0.9940\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0446 - acc: 0.9896 - val_loss: 0.0284 - val_acc: 0.9940\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0225 - acc: 0.9927 - val_loss: 0.0275 - val_acc: 0.9920\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0349 - acc: 0.9907 - val_loss: 0.0249 - val_acc: 0.9940\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0236 - acc: 0.9917 - val_loss: 0.0291 - val_acc: 0.9930\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0304 - val_acc: 0.9940\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0196 - acc: 0.9936 - val_loss: 0.0216 - val_acc: 0.9950\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0256 - acc: 0.9925 - val_loss: 0.0184 - val_acc: 0.9940\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0269 - val_acc: 0.9920\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0292 - acc: 0.9915 - val_loss: 0.0218 - val_acc: 0.9950\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0226 - acc: 0.9924 - val_loss: 0.0151 - val_acc: 0.9960\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0220 - val_acc: 0.9930\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0201 - acc: 0.9919 - val_loss: 0.0295 - val_acc: 0.9910\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0263 - acc: 0.9891 - val_loss: 0.0262 - val_acc: 0.9940\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0292 - acc: 0.9924 - val_loss: 0.0220 - val_acc: 0.9930\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0296 - acc: 0.9902 - val_loss: 0.0187 - val_acc: 0.9950\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0131 - val_acc: 0.9960\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0153 - acc: 0.9938 - val_loss: 0.0289 - val_acc: 0.9920\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0266 - val_acc: 0.9930\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0189 - acc: 0.9931 - val_loss: 0.0242 - val_acc: 0.9940\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0244 - acc: 0.9935 - val_loss: 0.0299 - val_acc: 0.9920\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0168 - acc: 0.9940 - val_loss: 0.0264 - val_acc: 0.9940\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0156 - val_acc: 0.9940\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0269 - acc: 0.9924 - val_loss: 0.0240 - val_acc: 0.9920\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.0201 - val_acc: 0.9930\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0209 - val_acc: 0.9930\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0150 - acc: 0.9947 - val_loss: 0.0278 - val_acc: 0.9910\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0301 - acc: 0.9929 - val_loss: 0.0133 - val_acc: 0.9960\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0215 - val_acc: 0.9930\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0220 - acc: 0.9949 - val_loss: 0.0257 - val_acc: 0.9920\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0398 - acc: 0.9906 - val_loss: 0.0201 - val_acc: 0.9920\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0175 - val_acc: 0.9950\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0279 - val_acc: 0.9920\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0147 - acc: 0.9941 - val_loss: 0.0247 - val_acc: 0.9950\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0183 - val_acc: 0.9940\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0174 - acc: 0.9956 - val_loss: 0.0202 - val_acc: 0.9920\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0281 - val_acc: 0.9920\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0131 - acc: 0.9948 - val_loss: 0.0219 - val_acc: 0.9920\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0148 - acc: 0.9965 - val_loss: 0.0141 - val_acc: 0.9960\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0201 - val_acc: 0.9930\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0342 - val_acc: 0.9920\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0190 - acc: 0.9951 - val_loss: 0.0180 - val_acc: 0.9920\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0193 - acc: 0.9933 - val_loss: 0.0238 - val_acc: 0.9940\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.0217 - val_acc: 0.9940\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0128 - acc: 0.9951 - val_loss: 0.0239 - val_acc: 0.9920\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0216 - acc: 0.9927 - val_loss: 0.0152 - val_acc: 0.9950\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0225 - acc: 0.9908 - val_loss: 0.0267 - val_acc: 0.9920\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0292 - acc: 0.9904 - val_loss: 0.0182 - val_acc: 0.9930\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0289 - val_acc: 0.9910\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0223 - acc: 0.9949 - val_loss: 0.0430 - val_acc: 0.9900\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0284 - acc: 0.9934 - val_loss: 0.0301 - val_acc: 0.9930\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0199 - acc: 0.9919 - val_loss: 0.0326 - val_acc: 0.9930\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0183 - acc: 0.9952 - val_loss: 0.0180 - val_acc: 0.9950\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0268 - acc: 0.9934 - val_loss: 0.0147 - val_acc: 0.9940\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0237 - acc: 0.9921 - val_loss: 0.0211 - val_acc: 0.9930\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0145 - acc: 0.9946 - val_loss: 0.0131 - val_acc: 0.9970\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.0247 - val_acc: 0.9920\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0124 - acc: 0.9967 - val_loss: 0.0202 - val_acc: 0.9920\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0240 - acc: 0.9913 - val_loss: 0.0187 - val_acc: 0.9940\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0264 - acc: 0.9940 - val_loss: 0.0151 - val_acc: 0.9940\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0244 - acc: 0.9935 - val_loss: 0.0211 - val_acc: 0.9940\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0147 - acc: 0.9963 - val_loss: 0.0223 - val_acc: 0.9930\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0150 - acc: 0.9947 - val_loss: 0.0191 - val_acc: 0.9950\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0231 - val_acc: 0.9940\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.0173 - acc: 0.9940 - val_loss: 0.0216 - val_acc: 0.9940\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0168 - acc: 0.9954 - val_loss: 0.0248 - val_acc: 0.9930\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0268 - acc: 0.9924 - val_loss: 0.0291 - val_acc: 0.9910\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0274 - acc: 0.9935 - val_loss: 0.0296 - val_acc: 0.9920\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0252 - acc: 0.9931 - val_loss: 0.0320 - val_acc: 0.9930\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.0149 - acc: 0.9942 - val_loss: 0.0266 - val_acc: 0.9940\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0242 - acc: 0.9920\n",
            "\n",
            "Test Loss : 0.0242 Test Accuracy : 0.9920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGR32E0ghAJP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sFdGD8AljQRx",
        "outputId": "f47df52e-46a0-4c48-89c3-8b271010ff70"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(512, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 128)       131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 7, 7, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 9,179,850\n",
            "Trainable params: 9,179,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 3s 73ms/step - loss: 2.2896 - acc: 0.1514 - val_loss: 1.2944 - val_acc: 0.6890\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 1.1365 - acc: 0.5994 - val_loss: 0.3793 - val_acc: 0.8780\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.5266 - acc: 0.8135 - val_loss: 0.1924 - val_acc: 0.9440\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.2843 - acc: 0.9075 - val_loss: 0.1152 - val_acc: 0.9670\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.2037 - acc: 0.9361 - val_loss: 0.0911 - val_acc: 0.9700\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.1694 - acc: 0.9487 - val_loss: 0.0725 - val_acc: 0.9800\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.1292 - acc: 0.9580 - val_loss: 0.0608 - val_acc: 0.9790\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 0.1164 - acc: 0.9612 - val_loss: 0.0613 - val_acc: 0.9880\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.1136 - acc: 0.9669 - val_loss: 0.0579 - val_acc: 0.9830\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.1014 - acc: 0.9674 - val_loss: 0.0443 - val_acc: 0.9870\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0863 - acc: 0.9735 - val_loss: 0.0466 - val_acc: 0.9860\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0769 - acc: 0.9735 - val_loss: 0.0494 - val_acc: 0.9880\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0719 - acc: 0.9767 - val_loss: 0.0396 - val_acc: 0.9870\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0748 - acc: 0.9750 - val_loss: 0.0426 - val_acc: 0.9820\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0797 - acc: 0.9730 - val_loss: 0.0488 - val_acc: 0.9840\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0625 - acc: 0.9773 - val_loss: 0.0358 - val_acc: 0.9860\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0491 - acc: 0.9870 - val_loss: 0.0377 - val_acc: 0.9840\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0313 - val_acc: 0.9870\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0556 - acc: 0.9802 - val_loss: 0.0313 - val_acc: 0.9890\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0502 - acc: 0.9829 - val_loss: 0.0344 - val_acc: 0.9890\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0396 - acc: 0.9864 - val_loss: 0.0450 - val_acc: 0.9870\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0509 - acc: 0.9826 - val_loss: 0.0372 - val_acc: 0.9840\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0476 - acc: 0.9837 - val_loss: 0.0505 - val_acc: 0.9850\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0428 - acc: 0.9837 - val_loss: 0.0359 - val_acc: 0.9880\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0465 - acc: 0.9842 - val_loss: 0.0370 - val_acc: 0.9870\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0464 - acc: 0.9840 - val_loss: 0.0326 - val_acc: 0.9890\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0346 - acc: 0.9883 - val_loss: 0.0259 - val_acc: 0.9900\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0357 - acc: 0.9896 - val_loss: 0.0313 - val_acc: 0.9900\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0265 - acc: 0.9877 - val_loss: 0.0239 - val_acc: 0.9930\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0313 - acc: 0.9898 - val_loss: 0.0297 - val_acc: 0.9900\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0271 - acc: 0.9927 - val_loss: 0.0273 - val_acc: 0.9910\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0287 - acc: 0.9902 - val_loss: 0.0285 - val_acc: 0.9900\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0316 - acc: 0.9888 - val_loss: 0.0411 - val_acc: 0.9890\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0284 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9920\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0255 - acc: 0.9910 - val_loss: 0.0316 - val_acc: 0.9920\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.0401 - val_acc: 0.9890\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0299 - acc: 0.9902 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0272 - acc: 0.9927 - val_loss: 0.0274 - val_acc: 0.9930\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0283 - acc: 0.9892 - val_loss: 0.0299 - val_acc: 0.9900\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0264 - val_acc: 0.9930\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0213 - acc: 0.9926 - val_loss: 0.0333 - val_acc: 0.9910\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0198 - acc: 0.9923 - val_loss: 0.0329 - val_acc: 0.9920\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0235 - acc: 0.9946 - val_loss: 0.0384 - val_acc: 0.9900\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0245 - acc: 0.9899 - val_loss: 0.0385 - val_acc: 0.9910\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0324 - acc: 0.9882 - val_loss: 0.0279 - val_acc: 0.9930\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0207 - acc: 0.9939 - val_loss: 0.0262 - val_acc: 0.9940\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0269 - acc: 0.9903 - val_loss: 0.0265 - val_acc: 0.9950\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0234 - acc: 0.9942 - val_loss: 0.0296 - val_acc: 0.9900\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0243 - val_acc: 0.9930\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0187 - acc: 0.9922 - val_loss: 0.0287 - val_acc: 0.9930\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0451 - val_acc: 0.9890\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.0250 - val_acc: 0.9930\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0306 - acc: 0.9895 - val_loss: 0.0235 - val_acc: 0.9930\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0197 - val_acc: 0.9940\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0194 - acc: 0.9950 - val_loss: 0.0221 - val_acc: 0.9950\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9960\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0227 - acc: 0.9918 - val_loss: 0.0165 - val_acc: 0.9960\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0186 - val_acc: 0.9960\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0240 - val_acc: 0.9950\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0295 - val_acc: 0.9900\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0175 - acc: 0.9936 - val_loss: 0.0189 - val_acc: 0.9970\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.0277 - val_acc: 0.9930\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0162 - acc: 0.9932 - val_loss: 0.0238 - val_acc: 0.9930\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0360 - val_acc: 0.9920\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0152 - acc: 0.9957 - val_loss: 0.0260 - val_acc: 0.9930\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0276 - val_acc: 0.9950\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0112 - acc: 0.9952 - val_loss: 0.0188 - val_acc: 0.9950\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0141 - acc: 0.9939 - val_loss: 0.0338 - val_acc: 0.9920\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0193 - val_acc: 0.9940\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0101 - acc: 0.9971 - val_loss: 0.0299 - val_acc: 0.9950\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.0223 - val_acc: 0.9950\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0333 - val_acc: 0.9900\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0250 - acc: 0.9920 - val_loss: 0.0349 - val_acc: 0.9950\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0199 - acc: 0.9947 - val_loss: 0.0165 - val_acc: 0.9960\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0120 - acc: 0.9957 - val_loss: 0.0091 - val_acc: 0.9970\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0225 - val_acc: 0.9950\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0286 - acc: 0.9934 - val_loss: 0.0206 - val_acc: 0.9940\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0116 - acc: 0.9947 - val_loss: 0.0302 - val_acc: 0.9960\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0262 - val_acc: 0.9940\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0333 - val_acc: 0.9940\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0208 - val_acc: 0.9940\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0237 - val_acc: 0.9950\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0136 - acc: 0.9951 - val_loss: 0.0245 - val_acc: 0.9950\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0207 - val_acc: 0.9960\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0233 - val_acc: 0.9970\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0103 - acc: 0.9946 - val_loss: 0.0283 - val_acc: 0.9960\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0105 - acc: 0.9972 - val_loss: 0.0352 - val_acc: 0.9920\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0240 - val_acc: 0.9950\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0264 - val_acc: 0.9960\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0252 - val_acc: 0.9910\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0225 - acc: 0.9938 - val_loss: 0.0197 - val_acc: 0.9960\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0114 - acc: 0.9975 - val_loss: 0.0187 - val_acc: 0.9950\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0301 - val_acc: 0.9910\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0269 - val_acc: 0.9960\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.0275 - val_acc: 0.9960\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0153 - acc: 0.9956 - val_loss: 0.0132 - val_acc: 0.9960\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0134 - acc: 0.9939 - val_loss: 0.0159 - val_acc: 0.9950\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0192 - val_acc: 0.9950\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0162 - val_acc: 0.9960\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0161 - val_acc: 0.9980\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0137 - acc: 0.9930 - val_loss: 0.0232 - val_acc: 0.9960\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0061 - acc: 0.9975 - val_loss: 0.0373 - val_acc: 0.9940\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0211 - val_acc: 0.9930\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0185 - val_acc: 0.9970\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0168 - val_acc: 0.9960\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0172 - val_acc: 0.9970\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0240 - val_acc: 0.9960\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0139 - acc: 0.9961 - val_loss: 0.0221 - val_acc: 0.9950\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0193 - val_acc: 0.9960\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0185 - acc: 0.9958 - val_loss: 0.0411 - val_acc: 0.9940\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0121 - val_acc: 0.9980\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0138 - val_acc: 0.9960\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0219 - acc: 0.9945 - val_loss: 0.0267 - val_acc: 0.9930\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0153 - acc: 0.9945 - val_loss: 0.0111 - val_acc: 0.9970\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0251 - acc: 0.9949 - val_loss: 0.0238 - val_acc: 0.9910\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0207 - acc: 0.9958 - val_loss: 0.0178 - val_acc: 0.9950\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0219 - val_acc: 0.9970\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0135 - val_acc: 0.9960\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0115 - val_acc: 0.9980\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0172 - val_acc: 0.9950\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0112 - acc: 0.9976 - val_loss: 0.0178 - val_acc: 0.9960\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0119 - val_acc: 0.9950\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0194 - acc: 0.9962 - val_loss: 0.0262 - val_acc: 0.9950\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0093 - acc: 0.9963 - val_loss: 0.0119 - val_acc: 0.9960\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.0281 - val_acc: 0.9930\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0263 - val_acc: 0.9950\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0160 - val_acc: 0.9950\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0087 - val_acc: 0.9970\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0113 - acc: 0.9946 - val_loss: 0.0164 - val_acc: 0.9960\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 0.0087 - acc: 0.9969 - val_loss: 0.0175 - val_acc: 0.9960\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0037 - acc: 0.9983 - val_loss: 0.0212 - val_acc: 0.9960\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0225 - acc: 0.9956 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9960\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0253 - val_acc: 0.9960\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0091 - acc: 0.9962 - val_loss: 0.0323 - val_acc: 0.9950\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0223 - acc: 0.9942 - val_loss: 0.0169 - val_acc: 0.9960\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0119 - acc: 0.9955 - val_loss: 0.0155 - val_acc: 0.9960\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0164 - val_acc: 0.9950\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0195 - val_acc: 0.9950\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0264 - acc: 0.9934 - val_loss: 0.0253 - val_acc: 0.9950\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0237 - val_acc: 0.9940\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 0.0209 - acc: 0.9942 - val_loss: 0.0184 - val_acc: 0.9960\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0319 - val_acc: 0.9950\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0274 - val_acc: 0.9950\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0385 - val_acc: 0.9940\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0148 - acc: 0.9970 - val_loss: 0.0286 - val_acc: 0.9950\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0244 - val_acc: 0.9950\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0300 - val_acc: 0.9920\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0104 - acc: 0.9952 - val_loss: 0.0131 - val_acc: 0.9950\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0227 - val_acc: 0.9950\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0229 - acc: 0.9960\n",
            "\n",
            "Test Loss : 0.0229 Test Accuracy : 0.9960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sa3_imtBjZIy",
        "outputId": "8ef0e31c-d707-40d6-dcc1-e4c885fd4029"
      },
      "source": [
        "# 5. Define model architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, (4, 4),activation = \"relu\", padding = \"same\" , input_shape = (28, 28, 1)))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(128, (4, 4), activation = \"relu\", padding=\"same\"))\r\n",
        "model.add(MaxPool2D(2, 2))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(256, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Conv2D(300, (4, 4), activation=\"relu\", padding= \"same\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation=\"relu\"))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "adam = Adam(lr = 0.001)\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\r\n",
        "\r\n",
        "\r\n",
        "# Fit Model on Training Data\r\n",
        "history = model.fit(X_train, y_train,\r\n",
        "          validation_data=(X_validation, y_validation),\r\n",
        "          shuffle=True, \r\n",
        "          epochs=150, \r\n",
        "          batch_size=200)\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print(f\"\\nTest Loss : {loss:.4f} Test Accuracy : {acc:.4f}\")\r\n",
        "\r\n",
        "acc = history.history[\"acc\"]\r\n",
        "val_acc = history.history[\"val_acc\"]\r\n",
        "\r\n",
        "loss = history.history[\"loss\"]\r\n",
        "val_loss = history.history[\"val_loss\"]\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, \"bo\", label = \"Training Accuracy\")\r\n",
        "plt.plot(epochs, val_acc, \"b\", label = \"Validation Accuracy\")\r\n",
        "plt.title(\"Training and Validation Accuracy\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\r\n",
        "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\r\n",
        "plt.title(\"Training and Validation Loss\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 14, 14, 128)       131200    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 7, 7, 256)         524544    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 300)         1229100   \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 7, 7, 300)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 14700)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               1881728   \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,768,950\n",
            "Trainable params: 3,768,950\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "200/200 [==============================] - 11s 51ms/step - loss: 1.0720 - acc: 0.6182 - val_loss: 0.0858 - val_acc: 0.9720\n",
            "Epoch 2/150\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.1427 - acc: 0.9582 - val_loss: 0.0424 - val_acc: 0.9874\n",
            "Epoch 3/150\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0964 - acc: 0.9735 - val_loss: 0.0298 - val_acc: 0.9906\n",
            "Epoch 4/150\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0757 - acc: 0.9794 - val_loss: 0.0302 - val_acc: 0.9906\n",
            "Epoch 5/150\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0587 - acc: 0.9835 - val_loss: 0.0203 - val_acc: 0.9942\n",
            "Epoch 6/150\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0474 - acc: 0.9876 - val_loss: 0.0191 - val_acc: 0.9947\n",
            "Epoch 7/150\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0460 - acc: 0.9875 - val_loss: 0.0170 - val_acc: 0.9946\n",
            "Epoch 8/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0427 - acc: 0.9877 - val_loss: 0.0142 - val_acc: 0.9958\n",
            "Epoch 9/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0349 - acc: 0.9896 - val_loss: 0.0131 - val_acc: 0.9950\n",
            "Epoch 10/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0341 - acc: 0.9905 - val_loss: 0.0123 - val_acc: 0.9965\n",
            "Epoch 11/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0346 - acc: 0.9904 - val_loss: 0.0120 - val_acc: 0.9965\n",
            "Epoch 12/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0284 - acc: 0.9926 - val_loss: 0.0101 - val_acc: 0.9975\n",
            "Epoch 13/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0093 - val_acc: 0.9969\n",
            "Epoch 14/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.0127 - val_acc: 0.9964\n",
            "Epoch 15/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0244 - acc: 0.9933 - val_loss: 0.0121 - val_acc: 0.9971\n",
            "Epoch 16/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0255 - acc: 0.9930 - val_loss: 0.0085 - val_acc: 0.9976\n",
            "Epoch 17/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.0121 - val_acc: 0.9967\n",
            "Epoch 18/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0233 - acc: 0.9933 - val_loss: 0.0102 - val_acc: 0.9971\n",
            "Epoch 19/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.0102 - val_acc: 0.9973\n",
            "Epoch 20/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0263 - acc: 0.9934 - val_loss: 0.0095 - val_acc: 0.9975\n",
            "Epoch 21/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0090 - val_acc: 0.9974\n",
            "Epoch 22/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0222 - acc: 0.9943 - val_loss: 0.0095 - val_acc: 0.9979\n",
            "Epoch 23/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0122 - val_acc: 0.9963\n",
            "Epoch 24/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0088 - val_acc: 0.9977\n",
            "Epoch 25/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0186 - acc: 0.9958 - val_loss: 0.0083 - val_acc: 0.9981\n",
            "Epoch 26/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.0102 - val_acc: 0.9968\n",
            "Epoch 27/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0203 - acc: 0.9942 - val_loss: 0.0079 - val_acc: 0.9978\n",
            "Epoch 28/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0205 - acc: 0.9945 - val_loss: 0.0096 - val_acc: 0.9978\n",
            "Epoch 29/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0224 - acc: 0.9939 - val_loss: 0.0082 - val_acc: 0.9973\n",
            "Epoch 30/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0080 - val_acc: 0.9977\n",
            "Epoch 31/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.0071 - val_acc: 0.9980\n",
            "Epoch 32/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0077 - val_acc: 0.9979\n",
            "Epoch 33/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0086 - val_acc: 0.9981\n",
            "Epoch 34/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0218 - acc: 0.9941 - val_loss: 0.0085 - val_acc: 0.9972\n",
            "Epoch 35/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0203 - acc: 0.9944 - val_loss: 0.0108 - val_acc: 0.9975\n",
            "Epoch 36/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0195 - acc: 0.9951 - val_loss: 0.0091 - val_acc: 0.9979\n",
            "Epoch 37/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0217 - acc: 0.9947 - val_loss: 0.0066 - val_acc: 0.9980\n",
            "Epoch 38/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0084 - val_acc: 0.9981\n",
            "Epoch 39/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.0090 - val_acc: 0.9974\n",
            "Epoch 40/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.0083 - val_acc: 0.9979\n",
            "Epoch 41/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.0061 - val_acc: 0.9980\n",
            "Epoch 42/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0177 - acc: 0.9948 - val_loss: 0.0082 - val_acc: 0.9975\n",
            "Epoch 43/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0115 - val_acc: 0.9971\n",
            "Epoch 44/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0192 - acc: 0.9949 - val_loss: 0.0070 - val_acc: 0.9984\n",
            "Epoch 45/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.0060 - val_acc: 0.9982\n",
            "Epoch 46/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0183 - acc: 0.9953 - val_loss: 0.0114 - val_acc: 0.9967\n",
            "Epoch 47/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0182 - acc: 0.9951 - val_loss: 0.0054 - val_acc: 0.9982\n",
            "Epoch 48/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0258 - acc: 0.9944 - val_loss: 0.0082 - val_acc: 0.9974\n",
            "Epoch 49/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0178 - acc: 0.9954 - val_loss: 0.0085 - val_acc: 0.9975\n",
            "Epoch 50/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0091 - val_acc: 0.9975\n",
            "Epoch 51/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0164 - acc: 0.9953 - val_loss: 0.0083 - val_acc: 0.9982\n",
            "Epoch 52/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0180 - acc: 0.9951 - val_loss: 0.0078 - val_acc: 0.9983\n",
            "Epoch 53/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0216 - acc: 0.9948 - val_loss: 0.0080 - val_acc: 0.9974\n",
            "Epoch 54/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0161 - acc: 0.9957 - val_loss: 0.0086 - val_acc: 0.9980\n",
            "Epoch 55/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0167 - acc: 0.9957 - val_loss: 0.0061 - val_acc: 0.9981\n",
            "Epoch 56/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0204 - acc: 0.9957 - val_loss: 0.0094 - val_acc: 0.9976\n",
            "Epoch 57/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.0109 - val_acc: 0.9972\n",
            "Epoch 58/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0103 - val_acc: 0.9974\n",
            "Epoch 59/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0173 - acc: 0.9950 - val_loss: 0.0098 - val_acc: 0.9973\n",
            "Epoch 60/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0153 - val_acc: 0.9972\n",
            "Epoch 61/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0081 - val_acc: 0.9975\n",
            "Epoch 62/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0154 - acc: 0.9959 - val_loss: 0.0071 - val_acc: 0.9979\n",
            "Epoch 63/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0228 - acc: 0.9941 - val_loss: 0.0095 - val_acc: 0.9975\n",
            "Epoch 64/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0195 - acc: 0.9947 - val_loss: 0.0104 - val_acc: 0.9976\n",
            "Epoch 65/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0151 - acc: 0.9961 - val_loss: 0.0069 - val_acc: 0.9983\n",
            "Epoch 66/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.0070 - val_acc: 0.9978\n",
            "Epoch 67/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.0063 - val_acc: 0.9983\n",
            "Epoch 68/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0196 - acc: 0.9954 - val_loss: 0.0066 - val_acc: 0.9983\n",
            "Epoch 69/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0194 - acc: 0.9951 - val_loss: 0.0078 - val_acc: 0.9975\n",
            "Epoch 70/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.0055 - val_acc: 0.9984\n",
            "Epoch 71/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0171 - acc: 0.9955 - val_loss: 0.0100 - val_acc: 0.9976\n",
            "Epoch 72/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0183 - acc: 0.9950 - val_loss: 0.0065 - val_acc: 0.9983\n",
            "Epoch 73/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0201 - acc: 0.9954 - val_loss: 0.0065 - val_acc: 0.9979\n",
            "Epoch 74/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0178 - acc: 0.9956 - val_loss: 0.0081 - val_acc: 0.9980\n",
            "Epoch 75/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0067 - val_acc: 0.9983\n",
            "Epoch 76/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.0075 - val_acc: 0.9977\n",
            "Epoch 77/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0179 - acc: 0.9953 - val_loss: 0.0072 - val_acc: 0.9981\n",
            "Epoch 78/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0214 - acc: 0.9951 - val_loss: 0.0089 - val_acc: 0.9980\n",
            "Epoch 79/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0173 - acc: 0.9956 - val_loss: 0.0073 - val_acc: 0.9982\n",
            "Epoch 80/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0060 - val_acc: 0.9984\n",
            "Epoch 81/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0191 - acc: 0.9956 - val_loss: 0.0064 - val_acc: 0.9982\n",
            "Epoch 82/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0176 - acc: 0.9951 - val_loss: 0.0060 - val_acc: 0.9977\n",
            "Epoch 83/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0199 - acc: 0.9946 - val_loss: 0.0077 - val_acc: 0.9983\n",
            "Epoch 84/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0172 - acc: 0.9959 - val_loss: 0.0080 - val_acc: 0.9977\n",
            "Epoch 85/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0145 - acc: 0.9962 - val_loss: 0.0094 - val_acc: 0.9975\n",
            "Epoch 86/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0096 - val_acc: 0.9976\n",
            "Epoch 87/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0153 - acc: 0.9962 - val_loss: 0.0074 - val_acc: 0.9981\n",
            "Epoch 88/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.0067 - val_acc: 0.9982\n",
            "Epoch 89/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0194 - acc: 0.9952 - val_loss: 0.0094 - val_acc: 0.9980\n",
            "Epoch 90/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0173 - acc: 0.9956 - val_loss: 0.0062 - val_acc: 0.9983\n",
            "Epoch 91/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0175 - acc: 0.9957 - val_loss: 0.0085 - val_acc: 0.9977\n",
            "Epoch 92/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.0086 - val_acc: 0.9982\n",
            "Epoch 93/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0073 - val_acc: 0.9983\n",
            "Epoch 94/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0149 - acc: 0.9959 - val_loss: 0.0114 - val_acc: 0.9973\n",
            "Epoch 95/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0170 - val_acc: 0.9962\n",
            "Epoch 96/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0239 - acc: 0.9951 - val_loss: 0.0114 - val_acc: 0.9973\n",
            "Epoch 97/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0271 - acc: 0.9950 - val_loss: 0.0078 - val_acc: 0.9982\n",
            "Epoch 98/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.0071 - val_acc: 0.9988\n",
            "Epoch 99/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0175 - acc: 0.9954 - val_loss: 0.0050 - val_acc: 0.9988\n",
            "Epoch 100/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0183 - acc: 0.9959 - val_loss: 0.0068 - val_acc: 0.9979\n",
            "Epoch 101/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0069 - val_acc: 0.9981\n",
            "Epoch 102/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0136 - acc: 0.9962 - val_loss: 0.0106 - val_acc: 0.9980\n",
            "Epoch 103/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0180 - acc: 0.9953 - val_loss: 0.0077 - val_acc: 0.9979\n",
            "Epoch 104/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0162 - acc: 0.9959 - val_loss: 0.0082 - val_acc: 0.9979\n",
            "Epoch 105/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0236 - acc: 0.9942 - val_loss: 0.0121 - val_acc: 0.9972\n",
            "Epoch 106/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0214 - acc: 0.9952 - val_loss: 0.0077 - val_acc: 0.9979\n",
            "Epoch 107/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0256 - acc: 0.9942 - val_loss: 0.0110 - val_acc: 0.9973\n",
            "Epoch 108/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0170 - acc: 0.9955 - val_loss: 0.0078 - val_acc: 0.9977\n",
            "Epoch 109/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0196 - acc: 0.9949 - val_loss: 0.0080 - val_acc: 0.9978\n",
            "Epoch 110/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0162 - acc: 0.9964 - val_loss: 0.0070 - val_acc: 0.9978\n",
            "Epoch 111/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0111 - val_acc: 0.9975\n",
            "Epoch 112/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.0091 - val_acc: 0.9977\n",
            "Epoch 113/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0208 - acc: 0.9954 - val_loss: 0.0089 - val_acc: 0.9979\n",
            "Epoch 114/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0174 - acc: 0.9958 - val_loss: 0.0085 - val_acc: 0.9977\n",
            "Epoch 115/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0254 - acc: 0.9942 - val_loss: 0.0089 - val_acc: 0.9975\n",
            "Epoch 116/150\n",
            "200/200 [==============================] - 10s 53ms/step - loss: 0.0155 - acc: 0.9959 - val_loss: 0.0079 - val_acc: 0.9979\n",
            "Epoch 117/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0165 - acc: 0.9961 - val_loss: 0.0087 - val_acc: 0.9981\n",
            "Epoch 118/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0204 - acc: 0.9961 - val_loss: 0.0114 - val_acc: 0.9972\n",
            "Epoch 119/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0165 - acc: 0.9960 - val_loss: 0.0105 - val_acc: 0.9978\n",
            "Epoch 120/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0190 - acc: 0.9959 - val_loss: 0.0075 - val_acc: 0.9981\n",
            "Epoch 121/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0180 - acc: 0.9957 - val_loss: 0.0115 - val_acc: 0.9974\n",
            "Epoch 122/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0172 - acc: 0.9958 - val_loss: 0.0085 - val_acc: 0.9980\n",
            "Epoch 123/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0066 - val_acc: 0.9980\n",
            "Epoch 124/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0250 - acc: 0.9945 - val_loss: 0.0083 - val_acc: 0.9982\n",
            "Epoch 125/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0180 - acc: 0.9956 - val_loss: 0.0079 - val_acc: 0.9976\n",
            "Epoch 126/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0095 - val_acc: 0.9974\n",
            "Epoch 127/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0172 - acc: 0.9956 - val_loss: 0.0050 - val_acc: 0.9984\n",
            "Epoch 128/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0191 - acc: 0.9958 - val_loss: 0.0083 - val_acc: 0.9982\n",
            "Epoch 129/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0228 - acc: 0.9951 - val_loss: 0.0114 - val_acc: 0.9976\n",
            "Epoch 130/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0200 - acc: 0.9950 - val_loss: 0.0128 - val_acc: 0.9976\n",
            "Epoch 131/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0198 - acc: 0.9953 - val_loss: 0.0131 - val_acc: 0.9974\n",
            "Epoch 132/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0231 - acc: 0.9946 - val_loss: 0.0107 - val_acc: 0.9978\n",
            "Epoch 133/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.0084 - val_acc: 0.9980\n",
            "Epoch 134/150\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0274 - acc: 0.9945 - val_loss: 0.0081 - val_acc: 0.9983\n",
            "Epoch 135/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0103 - val_acc: 0.9979\n",
            "Epoch 136/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0249 - acc: 0.9949 - val_loss: 0.0081 - val_acc: 0.9981\n",
            "Epoch 137/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0262 - acc: 0.9948 - val_loss: 0.0056 - val_acc: 0.9984\n",
            "Epoch 138/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0194 - acc: 0.9957 - val_loss: 0.0076 - val_acc: 0.9984\n",
            "Epoch 139/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0066 - val_acc: 0.9982\n",
            "Epoch 140/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0241 - acc: 0.9949 - val_loss: 0.0100 - val_acc: 0.9975\n",
            "Epoch 141/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0171 - acc: 0.9959 - val_loss: 0.0106 - val_acc: 0.9978\n",
            "Epoch 142/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0211 - acc: 0.9953 - val_loss: 0.0081 - val_acc: 0.9978\n",
            "Epoch 143/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0154 - acc: 0.9964 - val_loss: 0.0090 - val_acc: 0.9981\n",
            "Epoch 144/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0141 - acc: 0.9968 - val_loss: 0.0091 - val_acc: 0.9978\n",
            "Epoch 145/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0206 - acc: 0.9955 - val_loss: 0.0068 - val_acc: 0.9983\n",
            "Epoch 146/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0179 - acc: 0.9961 - val_loss: 0.0103 - val_acc: 0.9973\n",
            "Epoch 147/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0216 - acc: 0.9953 - val_loss: 0.0084 - val_acc: 0.9971\n",
            "Epoch 148/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0231 - acc: 0.9944 - val_loss: 0.0141 - val_acc: 0.9966\n",
            "Epoch 149/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.0080 - val_acc: 0.9982\n",
            "Epoch 150/150\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0206 - acc: 0.9950 - val_loss: 0.0083 - val_acc: 0.9979\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0103 - acc: 0.9977\n",
            "\n",
            "Test Loss : 0.0103 Test Accuracy : 0.9977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4oMhTJUp5vk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}